# üìö Documentaci√≥n General del Proyecto ECG

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura del Proyecto](#arquitectura-del-proyecto)
3. [Pipeline de Datos](#pipeline-de-datos)
4. [Modelos de Clasificaci√≥n Supervisada](#modelos-de-clasificaci√≥n-supervisada)
5. [Modelos de Detecci√≥n de Anomal√≠as](#modelos-de-detecci√≥n-de-anomal√≠as)
6. [Utilidades y Herramientas](#utilidades-y-herramientas)
7. [Gu√≠a de Uso R√°pida](#gu√≠a-de-uso-r√°pida)
8. [Estructura de Archivos](#estructura-de-archivos)
9. [Requisitos y Configuraci√≥n](#requisitos-y-configuraci√≥n)
10. [Troubleshooting](#troubleshooting)

---

## üéØ Introducci√≥n

Este proyecto implementa un sistema completo de an√°lisis de se√±ales ECG (electrocardiogramas) utilizando t√©cnicas de aprendizaje profundo. El objetivo principal es desarrollar modelos capaces de:

1. **Clasificaci√≥n Supervisada**: Clasificar ECG como **NORMAL** (0) o **AN√ìMALO** (1) usando etiquetas de entrenamiento
2. **Detecci√≥n de Anomal√≠as**: Detectar ECG an√≥malos mediante autoencoders entrenados solo con ejemplos normales

### Datasets Utilizados

- **PTB-XL**: Dataset p√∫blico de ECG con 21,799 registros etiquetados con c√≥digos SCP
- **MIMIC-IV-ECG**: Subset de MIMIC-IV con reportes de diagn√≥stico de ECG

### Caracter√≠sticas Principales

- ‚úÖ Procesamiento robusto de se√±ales ECG (filtrado, normalizaci√≥n, resampleo)
- ‚úÖ M√∫ltiples arquitecturas de modelos (CNN, LSTM, Transformer, Autoencoders)
- ‚úÖ Integraci√≥n con MLflow para tracking de experimentos
- ‚úÖ Orquestaci√≥n con Prefect 2.x
- ‚úÖ Soporte para GPU (RTX 5080 compatible)
- ‚úÖ Pipeline completo desde datos crudos hasta modelos entrenados

---

## üèóÔ∏è Arquitectura del Proyecto

### Flujo General del Proyecto

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATOS CRUDOS                                 ‚îÇ
‚îÇ  PTB-XL + MIMIC-IV-ECG (archivos .hea, .dat, CSV)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PIPELINE DE PREPROCESAMIENTO                        ‚îÇ
‚îÇ  ‚Ä¢ Etiquetado (NORMAL vs AN√ìMALO)                               ‚îÇ
‚îÇ  ‚Ä¢ Selecci√≥n de leads (II, V1, V5)                              ‚îÇ
‚îÇ  ‚Ä¢ Filtrado (notch 50Hz, bandpass 0.5-40Hz)                     ‚îÇ
‚îÇ  ‚Ä¢ Normalizaci√≥n (Min-Max)                                       ‚îÇ
‚îÇ  ‚Ä¢ Resampleo (10 seg @ 500Hz ‚Üí 5000 muestras)                   ‚îÇ
‚îÇ  ‚Ä¢ Control de calidad                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì                                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DATOS SUPERVISADOS   ‚îÇ          ‚îÇ DATOS NO SUPERVISADOS ‚îÇ
‚îÇ  (Clasificaci√≥n)      ‚îÇ          ‚îÇ (Detecci√≥n Anomal√≠as) ‚îÇ
‚îÇ                       ‚îÇ          ‚îÇ                       ‚îÇ
‚îÇ  ‚Ä¢ Train: Normales +  ‚îÇ          ‚îÇ  ‚Ä¢ Train: Solo        ‚îÇ
‚îÇ    An√≥malos           ‚îÇ          ‚îÇ    normales           ‚îÇ
‚îÇ  ‚Ä¢ Val/Test: Mezcla   ‚îÇ          ‚îÇ  ‚Ä¢ Val/Test: Mezcla   ‚îÇ
‚îÇ  ‚Ä¢ Balanceado 50/50   ‚îÇ          ‚îÇ  ‚Ä¢ Sin balancear      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì                                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOWNSAMPLING (Opcional)                       ‚îÇ
‚îÇ  500Hz (5000 muestras) ‚Üí 200Hz (2000 muestras)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì                                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ENTRENAMIENTO DE MODELOS                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  CLASIFICACI√ìN SUPERVISADA:        DETECCI√ìN DE ANOMAL√çAS:     ‚îÇ
‚îÇ  ‚Ä¢ CNN1D                           ‚Ä¢ CNN1D Autoencoder         ‚îÇ
‚îÇ  ‚Ä¢ CNN1D + LSTM                    ‚Ä¢ CNN1D + LSTM Autoencoder  ‚îÇ
‚îÇ  ‚Ä¢ CNN1D + Transformer             ‚Ä¢ LSTM Autoencoder          ‚îÇ
‚îÇ  ‚Ä¢ LSTM                            ‚Ä¢ Selecci√≥n de umbral        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì                                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EVALUACI√ìN Y M√âTRICAS                         ‚îÇ
‚îÇ  ‚Ä¢ Accuracy, Precision, Recall, F1                              ‚îÇ
‚îÇ  ‚Ä¢ Matrices de confusi√≥n                                         ‚îÇ
‚îÇ  ‚Ä¢ Curvas de entrenamiento                                       ‚îÇ
‚îÇ  ‚Ä¢ MLflow tracking                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principales

1. **M√≥dulos de Procesamiento**:
   - `supervised_ecg_pipeline.py`: Pipeline completo para datos supervisados
   - `ecg_preprocessing.py`: Funciones de preprocesamiento reutilizables
   - `evaluation_threshold_tuning.py`: Evaluaci√≥n y b√∫squeda de umbrales

2. **Notebooks de Construcci√≥n de Datos**:
   - `build_supervised_ecg_dataset.ipynb`: Crea dataset supervisado
   - `build_unsupervised_ecg_dataset.ipynb`: Crea dataset no supervisado

3. **Notebooks de Downsampling**:
   - `downsample_supervised_data.ipynb`: Reduce frecuencia de datos supervisados
   - `downsample_unsupervised_data.ipynb`: Reduce frecuencia de datos no supervisados

4. **Notebooks de Modelos**:
   - Clasificaci√≥n: `cnn1d_*`, `cnn1d_lstm_*`, `cnn1d_transformer_*`, `lstm_*`
   - Anomal√≠as: `cnn1d_autoencoder_*`, `cnn1d_lstm_autoencoder_*`, `lstm_autoencoder_*`

---

## üìä Pipeline de Datos

### 1. Pipeline de Datos Supervisados

**Archivo principal**: `build_supervised_ecg_dataset.ipynb` / `build_supervised_ecg_dataset.py`

**Prop√≥sito**: Crear un dataset binario balanceado (NORMAL vs AN√ìMALO) para entrenamiento supervisado.

**Proceso**:

1. **Procesamiento PTB-XL**:
   - Lee registros desde archivos `.hea` y `.dat`
   - Etiqueta usando c√≥digos SCP (NORM=normal, IMI/ISC/LVH/etc=an√≥malo)
   - Filtra por calidad de se√±al

2. **Procesamiento MIMIC-IV-ECG**:
   - Lee registros desde archivos `.hea` y `.dat`
   - Etiqueta usando reportes de texto (patrones regex)
   - Filtra por calidad de se√±al

3. **Preprocesamiento de Se√±ales**:
   - Selecci√≥n de leads: **II, V1, V5** (con mapeo autom√°tico de variantes)
   - Filtrado:
     - Notch 50/60 Hz (configurable)
     - Bandpass 0.5-40 Hz (Butterworth orden 4)
   - Normalizaci√≥n: Min-Max a [0,1] por lead
   - Resampleo: A 500 Hz y 10 segundos (5000 muestras)

4. **Control de Calidad**:
   - Detecci√≥n de se√±ales planas
   - Detecci√≥n de saturaci√≥n
   - Detecci√≥n de discontinuidades
   - Verificaci√≥n de ratio de NaN
   - Verificaci√≥n de duraci√≥n m√≠nima

5. **Balanceo y Splits**:
   - Balanceo: Downsampling estratificado a la clase minoritaria
   - Splits: Train (70%) / Val (15%) / Test (15%) estratificados
   - Cross-validation: 10 folds estratificados sobre train

**Salida**:
```
data/Datos_supervisados/
‚îú‚îÄ‚îÄ numpy/
‚îÇ   ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy
‚îÇ   ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy
‚îÇ   ‚îî‚îÄ‚îÄ X_test.npy, y_test.npy
‚îú‚îÄ‚îÄ tensors/ (opcional, para PyTorch)
‚îÇ   ‚îú‚îÄ‚îÄ X_train.pt, y_train.pt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tensors_200hz/ (si se aplica downsampling)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metadata/
    ‚îú‚îÄ‚îÄ master_labels.csv
    ‚îú‚îÄ‚îÄ master_labels_full.csv
    ‚îú‚îÄ‚îÄ folds_train_indices.npy
    ‚îî‚îÄ‚îÄ folds_val_indices.npy
```

**Documentaci√≥n detallada**: Ver `Documentacion Datos Supervisados.md`

### 2. Pipeline de Datos No Supervisados

**Archivo principal**: `build_unsupervised_ecg_dataset.ipynb`

**Prop√≥sito**: Crear un dataset para entrenamiento de autoencoders (solo normales en train).

**Proceso**:

1. **Carga desde datos supervisados**: Reutiliza los datos ya procesados del pipeline supervisado
2. **Separaci√≥n especial**:
   - **Train**: Solo ECG normales (label == 0) - para entrenar el autoencoder
   - **Val/Test**: Mezcla de normales y an√≥malos (con labels) - para evaluaci√≥n
3. **Sin balanceo**: Mantiene la distribuci√≥n natural de los datos

**Salida**:
```
data/Datos_no_supervisados/
‚îú‚îÄ‚îÄ numpy/
‚îÇ   ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy  (solo normales)
‚îÇ   ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy
‚îÇ   ‚îî‚îÄ‚îÄ X_test.npy, y_test.npy
‚îî‚îÄ‚îÄ tensors_200hz/ (si se aplica downsampling)
    ‚îî‚îÄ‚îÄ ...
```

### 3. Downsampling

**Archivos**: `downsample_supervised_data.ipynb`, `downsample_unsupervised_data.ipynb`

**Prop√≥sito**: Reducir la frecuencia de muestreo de 500Hz a 200Hz para:
- Reducir el tama√±o de archivos (~2.5x)
- Acelerar el entrenamiento
- Mantener el preprocesado original

**Proceso**:
- Usa `scipy.signal.resample` con filtrado anti-aliasing autom√°tico
- Convierte 5000 muestras ‚Üí 2000 muestras (mantiene 10 segundos)
- Guarda en carpetas separadas (`numpy_200hz/`, `tensors_200hz/`)

---

## üß† Modelos de Clasificaci√≥n Supervisada

Todos los modelos de clasificaci√≥n supervisada comparten:
- **Input**: Datos desde `Datos_supervisados/tensors_200hz/` (archivos `.pt`)
- **Output**: Modelo entrenado + m√©tricas en MLflow
- **Etiquetas**: 0 = NORMAL, 1 = AN√ìMALO
- **Evaluaci√≥n**: Accuracy, Precision, Recall, F1, matrices de confusi√≥n

### 1. CNN1D (`cnn1d_classification_supervised.ipynb`)

**Arquitectura**: CNN1D pura para extracci√≥n de caracter√≠sticas locales.

**Caracter√≠sticas**:
- M√∫ltiples capas convolucionales 1D
- Pooling para reducci√≥n dimensional
- Capas fully connected al final
- Optimizado para capturar patrones locales en se√±ales temporales

**Uso recomendado**: Baseline r√°pido, bueno para comparaci√≥n.

### 2. CNN1D + LSTM (`cnn1d_lstm_classification_supervised.ipynb`)

**Arquitectura**: H√≠brida - CNN1D para caracter√≠sticas locales + LSTM para dependencias temporales.

**Caracter√≠sticas**:
- CNN1D extrae caracter√≠sticas locales
- LSTM captura dependencias temporales largas
- Combina lo mejor de ambas arquitecturas

**Uso recomendado**: **Recomendado para clasificaci√≥n** - balance entre rendimiento y complejidad.

### 3. CNN1D + Transformer (`cnn1d_transformer_classification_supervised.ipynb`)

**Arquitectura**: CNN1D + Transformer para atenci√≥n global.

**Caracter√≠sticas**:
- CNN1D para caracter√≠sticas locales
- Transformer con self-attention para relaciones globales
- Captura dependencias complejas en toda la se√±al

**Uso recomendado**: Cuando se necesita el mejor rendimiento posible (m√°s lento de entrenar).

### 4. LSTM (`lstm_classification_supervised.ipynb`)

**Arquitectura**: LSTM puro para secuencias temporales.

**Caracter√≠sticas**:
- M√∫ltiples capas LSTM
- Captura dependencias temporales largas
- Sin convoluciones

**Uso recomendado**: Comparaci√≥n con arquitecturas h√≠bridas.

---

## üîç Modelos de Detecci√≥n de Anomal√≠as

Todos los modelos de detecci√≥n de anomal√≠as comparten:
- **Entrenamiento**: Solo con ejemplos normales (no supervisado)
- **Input**: Datos desde `Datos_no_supervisados/tensors_200hz/`
- **Detecci√≥n**: Basada en error de reconstrucci√≥n
- **Umbral**: Selecci√≥n autom√°tica o manual del umbral √≥ptimo

### 1. CNN1D Autoencoder (`cnn1d_autoencoder_anomaly_detection.ipynb`)

**Arquitectura**: Encoder-decoder CNN1D puro.

**Caracter√≠sticas**:
- Encoder: Capas convolucionales que comprimen la se√±al
- Decoder: Capas de transposici√≥n convolucional o upsampling que reconstruyen
- Entrenamiento: Minimiza error de reconstrucci√≥n en normales
- Detecci√≥n: ECG con error alto ‚Üí an√≥malo

**Uso recomendado**: Baseline r√°pido para detecci√≥n de anomal√≠as.

### 2. CNN1D + LSTM Autoencoder (`cnn1d_lstm_autoencoder_anomaly_detection.ipynb`)

**Arquitectura**: H√≠brida - CNN1D + LSTM en encoder y decoder.

**Caracter√≠sticas**:
- Combina capacidades de CNN y LSTM
- Mejor captura de patrones temporales complejos
- Reconstrucci√≥n m√°s precisa

**Uso recomendado**: **Recomendado para detecci√≥n de anomal√≠as** - mejor balance rendimiento/complejidad.

### 3. LSTM Autoencoder (`lstm_autoencoder_pipeline.ipynb`)

**Arquitectura**: LSTM puro en encoder y decoder.

**Caracter√≠sticas**:
- Encoder LSTM comprime la secuencia
- Decoder LSTM reconstruye
- Enfocado en dependencias temporales

**Uso recomendado**: Comparaci√≥n con arquitecturas h√≠bridas.

### Selecci√≥n de Umbral

**Archivo**: `evaluation_threshold_tuning.py`

**M√©todos**:
1. **Autom√°tico (recomendado)**: `find_optimal_threshold()` prueba varios percentiles y selecciona el mejor seg√∫n F2-score
2. **Manual**: Define un umbral fijo basado en estad√≠sticas
3. **Basado en percentiles**: `threshold = np.percentile(errors, 95)`

**L√≥gica**:
- Si `error_reconstrucci√≥n > umbral` ‚Üí ECG es **AN√ìMALO** (clase 1)
- Si `error_reconstrucci√≥n <= umbral` ‚Üí ECG es **NORMAL** (clase 0)

---

## üõ†Ô∏è Utilidades y Herramientas

### Scripts de Utilidad

1. **`cleanup_splits.py`**: Limpia archivos de splits antiguos
2. **`create_splits_disk.py`**: Crea splits guardando directamente en disco (eficiente en memoria)
3. **`evaluation_threshold_tuning.py`**: Funciones para evaluaci√≥n y b√∫squeda de umbrales

### Integraci√≥n con MLflow

Todos los notebooks de entrenamiento integran MLflow para:
- Tracking de hiperpar√°metros
- Logging de m√©tricas durante entrenamiento
- Guardado de modelos
- Comparaci√≥n de experimentos

**Ubicaci√≥n de runs**: `Books/mlruns/`

### Orquestaci√≥n con Prefect

Los notebooks principales usan Prefect 2.x para:
- Orquestaci√≥n del flujo de entrenamiento
- Manejo de errores y reintentos
- Logging estructurado

---

## üöÄ Gu√≠a de Uso R√°pida

### Flujo Completo Recomendado

#### Paso 1: Preparar Datos Supervisados

```bash
cd Books
# Opci√≥n 1: Ejecutar notebook
jupyter notebook build_supervised_ecg_dataset.ipynb

# Opci√≥n 2: Ejecutar script
python build_supervised_ecg_dataset.py
```

**Tiempo estimado**: 1-2 horas (depende del tama√±o del dataset)

#### Paso 2: (Opcional) Downsampling a 200Hz

```bash
jupyter notebook downsample_supervised_data.ipynb
```

**Tiempo estimado**: 30-60 minutos

#### Paso 3: Preparar Datos No Supervisados

```bash
jupyter notebook build_unsupervised_ecg_dataset.ipynb
```

**Tiempo estimado**: 10-20 minutos

#### Paso 4: (Opcional) Downsampling Datos No Supervisados

```bash
jupyter notebook downsample_unsupervised_data.ipynb
```

**Tiempo estimado**: 30-60 minutos

#### Paso 5: Entrenar Modelos

**Clasificaci√≥n Supervisada** (elige uno):
```bash
# Recomendado: CNN1D + LSTM
jupyter notebook cnn1d_lstm_classification_supervised.ipynb

# Otras opciones:
jupyter notebook cnn1d_classification_supervised.ipynb
jupyter notebook cnn1d_transformer_classification_supervised.ipynb
jupyter notebook lstm_classification_supervised.ipynb
```

**Detecci√≥n de Anomal√≠as** (elige uno):
```bash
# Recomendado: CNN1D + LSTM Autoencoder
jupyter notebook cnn1d_lstm_autoencoder_anomaly_detection.ipynb

# Otras opciones:
jupyter notebook cnn1d_autoencoder_anomaly_detection.ipynb
jupyter notebook lstm_autoencoder_pipeline.ipynb
```

**Tiempo estimado por modelo**: 2-4 horas (depende de GPU y tama√±o de datos)

### Configuraci√≥n Inicial (Primera Vez)

1. **Setup CUDA (Windows)**:
   - Ejecuta la celda "Setup CUDA y Dependencias" en cualquier notebook
   - Esto configura las DLLs de CUDA para PyTorch
   - **IMPORTANTE**: Reinicia el kernel despu√©s de ejecutar esta celda

2. **Configurar Rutas**:
   - Ajusta `DATA_DIR` en cada notebook seg√∫n tu estructura de carpetas
   - Debe apuntar a `Datos_supervisados/tensors_200hz` o `Datos_no_supervisados/tensors_200hz`

3. **Verificar GPU**:
   - Los notebooks detectan autom√°ticamente si hay GPU disponible
   - Si no hay GPU, usar√°n CPU (m√°s lento)

### Ejecuci√≥n R√°pida de un Modelo

1. Abre el notebook deseado
2. Ejecuta la celda de **Setup CUDA** (si es primera vez)
3. Configura `DATA_DIR` en la secci√≥n de configuraci√≥n
4. Ejecuta todas las celdas en orden
5. Revisa resultados en MLflow UI: `mlflow ui` en terminal

---

## üìÅ Estructura de Archivos

```
Books/
‚îú‚îÄ‚îÄ üìÑ DOCUMENTACION_GENERAL.md          # Este archivo
‚îú‚îÄ‚îÄ üìÑ Documentacion Datos Supervisados.md  # Documentaci√≥n detallada del pipeline
‚îÇ
‚îú‚îÄ‚îÄ üîß M√≥dulos Python
‚îÇ   ‚îú‚îÄ‚îÄ supervised_ecg_pipeline.py       # Pipeline principal supervisado
‚îÇ   ‚îú‚îÄ‚îÄ supervised_ecg_pipeline_fast.py  # Versi√≥n paralela optimizada
‚îÇ   ‚îú‚îÄ‚îÄ ecg_preprocessing.py             # Funciones de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_threshold_tuning.py   # Evaluaci√≥n y umbrales
‚îÇ   ‚îú‚îÄ‚îÄ build_supervised_ecg_dataset.py # Script ejecutable pipeline
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_splits.py               # Utilidad limpieza
‚îÇ   ‚îî‚îÄ‚îÄ create_splits_disk.py            # Creaci√≥n eficiente de splits
‚îÇ
‚îú‚îÄ‚îÄ üìä Notebooks de Construcci√≥n de Datos
‚îÇ   ‚îú‚îÄ‚îÄ build_supervised_ecg_dataset.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ build_unsupervised_ecg_dataset.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üîΩ Notebooks de Downsampling
‚îÇ   ‚îú‚îÄ‚îÄ downsample_supervised_data.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ downsample_unsupervised_data.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üß† Notebooks de Clasificaci√≥n Supervisada
‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_classification_supervised.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_lstm_classification_supervised.ipynb      ‚≠ê Recomendado
‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_transformer_classification_supervised.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ lstm_classification_supervised.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üîç Notebooks de Detecci√≥n de Anomal√≠as
‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_autoencoder_anomaly_detection.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_lstm_autoencoder_anomaly_detection.ipynb  ‚≠ê Recomendado
‚îÇ   ‚îî‚îÄ‚îÄ lstm_autoencoder_pipeline.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Modelos Guardados
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_ecg_v1.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cnn1d_lstm_ecg_v1.pt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cnn_transformer_ecg_v1.pt
‚îÇ   ‚îî‚îÄ‚îÄ sagemaker_models/  # Modelos para AWS SageMaker
‚îÇ
‚îú‚îÄ‚îÄ üìà MLflow Tracking
‚îÇ   ‚îî‚îÄ‚îÄ mlruns/  # Runs de experimentos
‚îÇ
‚îî‚îÄ‚îÄ üì§ Outputs
    ‚îî‚îÄ‚îÄ outputs/  # Gr√°ficos, matrices de confusi√≥n, etc.
```

### Estructura de Datos Generados

```
data/
‚îú‚îÄ‚îÄ Datos_supervisados/
‚îÇ   ‚îú‚îÄ‚îÄ numpy/              # Arrays numpy (500Hz)
‚îÇ   ‚îú‚îÄ‚îÄ tensors/            # Tensores PyTorch (500Hz)
‚îÇ   ‚îú‚îÄ‚îÄ numpy_200hz/        # Arrays numpy (200Hz)
‚îÇ   ‚îú‚îÄ‚îÄ tensors_200hz/      # Tensores PyTorch (200Hz) ‚≠ê Usado por modelos
‚îÇ   ‚îî‚îÄ‚îÄ metadata/           # Metadatos, labels, folds
‚îÇ
‚îî‚îÄ‚îÄ Datos_no_supervisados/
    ‚îú‚îÄ‚îÄ numpy/              # Arrays numpy (500Hz)
    ‚îú‚îÄ‚îÄ numpy_200hz/        # Arrays numpy (200Hz)
    ‚îî‚îÄ‚îÄ tensors_200hz/      # Tensores PyTorch (200Hz) ‚≠ê Usado por modelos
```

---

## ‚öôÔ∏è Requisitos y Configuraci√≥n

### Requisitos de Hardware

- **GPU**: Recomendado (RTX 5080 compatible, CUDA 12.8)
- **RAM**: M√≠nimo 16GB, recomendado 32GB+ para datasets grandes
- **Disco**: ~50-100GB libres para datasets procesados

### Requisitos de Software

- **Python**: 3.11+
- **PyTorch**: Nightly build con CUDA 12.8 (instalado autom√°ticamente en notebooks)
- **Librer√≠as principales**:
  - `torch`, `torchvision`, `torchaudio`
  - `mlflow>=2.16`
  - `prefect>=3`
  - `scikit-learn`
  - `numpy`, `pandas`, `matplotlib`, `seaborn`
  - `wfdb` (para leer archivos PTB-XL/MIMIC)
  - `scipy`

### Configuraci√≥n de Entorno

Los notebooks instalan autom√°ticamente las dependencias necesarias. Para instalaci√≥n manual:

```bash
pip install mlflow>=2.16 prefect>=3 scikit-learn matplotlib pandas numpy seaborn ipywidgets wfdb scipy

# PyTorch (para RTX 5080 / CUDA 12.8)
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```

### Configuraci√≥n de Rutas

Aseg√∫rate de que las rutas en los m√≥dulos Python apunten correctamente:

```python
# En supervised_ecg_pipeline.py
PROJECT_ROOT = Path(__file__).resolve().parent.parent
PTB_ROOT = PROJECT_ROOT / "ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3"
MIMIC_ROOT = PROJECT_ROOT / "mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0"
```

---

## üîß Troubleshooting

### Problemas Comunes

#### 1. Error de DLLs CUDA en Windows

**S√≠ntoma**: `OSError: [WinError 126] No se puede encontrar el m√≥dulo especificado`

**Soluci√≥n**:
1. Ejecuta la celda "Setup CUDA y Dependencias" en el notebook
2. **Reinicia el kernel de Jupyter** (Kernel ‚Üí Restart Kernel)
3. Ejecuta la celda de nuevo

#### 2. Out of Memory (OOM)

**S√≠ntoma**: `RuntimeError: CUDA out of memory`

**Soluciones**:
- Reduce `batch_size` en la configuraci√≥n del notebook
- Usa datos downsampled (200Hz en lugar de 500Hz)
- Procesa en chunks m√°s peque√±os
- Cierra otros programas que usen GPU

#### 3. Datos No Encontrados

**S√≠ntoma**: `FileNotFoundError` al cargar datos

**Soluci√≥n**:
- Verifica que `DATA_DIR` apunta correctamente
- Aseg√∫rate de haber ejecutado el pipeline de construcci√≥n de datos primero
- Verifica que los archivos `.pt` existen en `tensors_200hz/`

#### 4. MLflow No Inicia

**S√≠ntoma**: Errores al inicializar MLflow

**Soluci√≥n**:
- Verifica que `mlflow>=2.16` est√° instalado
- Aseg√∫rate de tener permisos de escritura en `Books/mlruns/`
- Intenta ejecutar `mlflow ui` manualmente para verificar

#### 5. Prefect No Funciona

**S√≠ntoma**: Errores con Prefect flows

**Soluci√≥n**:
- Verifica que `prefect>=3` est√° instalado
- Algunos notebooks pueden funcionar sin Prefect (comenta las secciones de Prefect)

### Verificaci√≥n de Setup

Ejecuta este c√≥digo para verificar tu configuraci√≥n:

```python
import torch
import sys
from pathlib import Path

print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"CUDA version: {torch.version.cuda}")

# Verificar rutas
project_root = Path.cwd().parent
print(f"\nProject root: {project_root}")
print(f"PTB-XL existe: {(project_root / 'ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3').exists()}")
print(f"MIMIC existe: {(project_root / 'mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0').exists()}")
```

---

## üìù Notas Adicionales

### Mejores Pr√°cticas

1. **Siempre ejecuta el pipeline de datos primero** antes de entrenar modelos
2. **Usa downsampling a 200Hz** para acelerar entrenamiento sin perder mucho rendimiento
3. **Guarda modelos regularmente** - los notebooks guardan autom√°ticamente en `models/`
4. **Revisa MLflow** para comparar experimentos y encontrar mejores hiperpar√°metros
5. **Usa GPU** siempre que sea posible - el entrenamiento es mucho m√°s r√°pido

### Comparaci√≥n de Modelos

| Modelo | Velocidad | Rendimiento | Complejidad | Recomendado Para |
|--------|-----------|-------------|--------------|------------------|
| CNN1D | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Baja | Baseline r√°pido |
| CNN1D+LSTM | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Media | **Uso general** |
| CNN1D+Transformer | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Alta | M√°ximo rendimiento |
| LSTM | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Media | Comparaci√≥n |

### Siguientes Pasos

1. **Hiperparameter Tuning**: Usa MLflow para optimizar hiperpar√°metros
2. **Ensemble Methods**: Combina m√∫ltiples modelos para mejor rendimiento
3. **Transfer Learning**: Usa modelos pre-entrenados si est√°n disponibles
4. **Deployment**: Exporta modelos para producci√≥n (ver `sagemaker_models/`)

---

## üìö Referencias y Documentaci√≥n Adicional

- **Documentaci√≥n detallada del pipeline supervisado**: `Documentacion Datos Supervisados.md`
- **MLflow Documentation**: https://mlflow.org/docs/latest/index.html
- **Prefect Documentation**: https://docs.prefect.io/
- **PyTorch Documentation**: https://pytorch.org/docs/stable/index.html

---

**√öltima actualizaci√≥n**: 2025-01-XX
**Versi√≥n**: 1.0

