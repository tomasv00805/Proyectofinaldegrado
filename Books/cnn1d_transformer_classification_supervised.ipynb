{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ«€ CNN1D + Transformer para ClasificaciÃ³n Binaria Supervisada de ECG\n",
        "\n",
        "Este notebook implementa un **CNN1D + Transformer Encoder** para clasificaciÃ³n binaria supervisada (ECG normal vs anÃ³malo).\n",
        "\n",
        "**CaracterÃ­sticas principales:**\n",
        "- Arquitectura hÃ­brida: CNN1D para extracciÃ³n de caracterÃ­sticas locales + Transformer Encoder para dependencias temporales con atenciÃ³n\n",
        "- Entrenamiento supervisado con etiquetas (0=normal, 1=anÃ³malo)\n",
        "- Datos preprocesados desde `Datos_supervisados/tensors_200hz` (archivos .pt)\n",
        "- IntegraciÃ³n con MLflow para tracking de experimentos\n",
        "- OrquestaciÃ³n con Prefect 2.x\n",
        "- Soporte automÃ¡tico para GPU (RTX 5080 compatible)\n",
        "\n",
        "> âš ï¸ **IMPORTANTE EN WINDOWS:** Ejecuta la celda de **Setup DLLs CUDA** (celda 2) **ANTES** de la celda de imports. Esto es necesario para que PyTorch pueda cargar las DLLs de CUDA correctamente.\n",
        "\n",
        "> â–¶ï¸ **Instrucciones:** \n",
        "> 1. Ejecuta la celda de **Setup DLLs CUDA** primero\n",
        "> 2. Configura los parÃ¡metros en la secciÃ³n de **CONFIGURACIÃ“N GENERAL**\n",
        "> 3. Ajusta la ruta `DATA_DIR` a tu carpeta de datos (debe apuntar a `Datos_supervisados/tensors_200hz`)\n",
        "> 4. Ejecuta todas las demÃ¡s celdas en orden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ Ãndice\n",
        "\n",
        "1. **Setup CUDA y dependencias** - ConfiguraciÃ³n de DLLs y librerÃ­as\n",
        "2. **ConfiguraciÃ³n general** - Imports, semillas, dispositivo, hiperparÃ¡metros\n",
        "3. **Carga y preparaciÃ³n de datos** - Funciones para cargar desde `tensors_200hz`\n",
        "4. **DefiniciÃ³n del modelo CNN1D + Transformer** - Arquitectura hÃ­brida\n",
        "5. **Funciones de entrenamiento y evaluaciÃ³n** - Loops de entrenamiento y validaciÃ³n\n",
        "6. **IntegraciÃ³n con MLflow** - ConfiguraciÃ³n y logging\n",
        "7. **OrquestaciÃ³n con Prefect** - Flujo principal con Prefect\n",
        "8. **EjecuciÃ³n del flujo completo** - Celda final para ejecutar todo\n",
        "9. **Guardado de modelo** - Exportar modelo estÃ¡ndar y para AWS SageMaker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. âš™ï¸ Setup CUDA y Dependencias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: c:\\Python311\\python.exe\n",
            "Working dir: S:\\Proyecto final\\Books\n",
            "DLL directories aÃ±adidos:\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp\n",
            "â³ Instalando mlflow>=2.16 ...\n",
            "â³ Instalando prefect>=3 ...\n",
            "â³ Instalando scikit-learn ...\n",
            "âœ” matplotlib ya instalado\n",
            "âœ” pandas ya instalado\n",
            "âœ” numpy ya instalado\n",
            "âœ” seaborn ya instalado\n",
            "\n",
            "Torch info:\n",
            "  - torch_version: 2.10.0.dev20251121+cu128\n",
            "  - cuda_version: 12.8\n",
            "  - cuda_available: True\n",
            "GPU detectada: NVIDIA GeForce RTX 5080 | SM 120\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ðŸ”§ Setup RTX 5080 â€” dependencias + CUDA DLL\n",
        "# Ejecuta una sola vez (o tras actualizar drivers/librerÃ­as)\n",
        "# ========================================\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from textwrap import dedent\n",
        "\n",
        "print(f\"Python: {sys.executable}\")\n",
        "print(f\"Working dir: {Path.cwd().resolve()}\")\n",
        "\n",
        "# Rutas candidatas para DLLs de CUDA\n",
        "CUDA_CANDIDATES = [\n",
        "    os.environ.get(\"CUDA_PATH\"),\n",
        "    os.environ.get(\"CUDA_PATH_V12_8\"),\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\",\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\",\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp\",\n",
        "    r\"C:\\Program Files\\NVIDIA\\CUDNN\",\n",
        "]\n",
        "\n",
        "# AÃ±adir rutas DLL en Windows (necesario antes de importar torch)\n",
        "added = []\n",
        "if hasattr(os, \"add_dll_directory\"):\n",
        "    for candidate in CUDA_CANDIDATES:\n",
        "        if not candidate:\n",
        "            continue\n",
        "        path = Path(candidate)\n",
        "        if path.is_dir():\n",
        "            try:\n",
        "                os.add_dll_directory(str(path))\n",
        "                added.append(str(path))\n",
        "            except (FileNotFoundError, OSError):\n",
        "                pass\n",
        "\n",
        "if added:\n",
        "    print(\"DLL directories aÃ±adidos:\")\n",
        "    for path in added:\n",
        "        print(f\"  - {path}\")\n",
        "\n",
        "# Instalar dependencias base si no estÃ¡n instaladas\n",
        "BASE_PACKAGES = [\n",
        "    \"mlflow>=2.16\",\n",
        "    \"prefect>=3\",\n",
        "    \"scikit-learn\",\n",
        "    \"matplotlib\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"seaborn\",\n",
        "]\n",
        "\n",
        "def pip_install(spec: str) -> None:\n",
        "    module_name = spec.split(\"==\")[0].split(\"[\")[0].replace(\"-\", \"_\")\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        print(f\"âœ” {spec} ya instalado\")\n",
        "    except Exception:\n",
        "        print(f\"â³ Instalando {spec} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", spec])\n",
        "\n",
        "for pkg in BASE_PACKAGES:\n",
        "    pip_install(pkg)\n",
        "\n",
        "# Comando para instalar PyTorch nightly con CUDA 12.8 (para RTX 5080)\n",
        "TORCH_INSTALL_CMD = [\n",
        "    sys.executable,\n",
        "    \"-m\",\n",
        "    \"pip\",\n",
        "    \"install\",\n",
        "    \"--upgrade\",\n",
        "    \"--pre\",\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"torchaudio\",\n",
        "    \"--index-url\",\n",
        "    \"https://download.pytorch.org/whl/nightly/cu128\",\n",
        "]\n",
        "\n",
        "def ensure_torch_cuda() -> \"tuple[object | None, dict]\":\n",
        "    \"\"\"Importa torch, o instala la nightly cu128 si hace falta.\"\"\"\n",
        "    info: dict[str, str | float | bool] = {}\n",
        "    try:\n",
        "        import torch  # type: ignore\n",
        "        info[\"torch_version\"] = getattr(torch, \"__version__\", \"desconocida\")\n",
        "        info[\"cuda_version\"] = getattr(getattr(torch, \"version\", object()), \"cuda\", \"desconocida\")\n",
        "        info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "        if \"cu128\" not in info[\"torch_version\"] and not str(info[\"cuda_version\"]).startswith(\"12.8\"):\n",
        "            raise RuntimeError(\n",
        "                f\"Build {info['torch_version']} no es cu128. Se reinstalarÃ¡ la nightly para RTX 5080.\"\n",
        "            )\n",
        "        return torch, info\n",
        "    except Exception as err:\n",
        "        print(\"âš ï¸ Torch no usable todavÃ­a:\", err)\n",
        "        print(\"   Desinstalando PyTorch corrupto...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
        "        print(\"   Instalando nightly cu128 desde PyTorch (puede tardar).\")\n",
        "        subprocess.check_call(TORCH_INSTALL_CMD)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"âš ï¸ IMPORTANTE: PyTorch fue reinstalado.\")\n",
        "        print(\"   DEBES REINICIAR EL KERNEL DE JUPYTER ahora:\")\n",
        "        print(\"   Kernel â†’ Restart Kernel\")\n",
        "        print(\"   Luego ejecuta esta celda de nuevo.\")\n",
        "        print(\"=\"*60)\n",
        "        import importlib\n",
        "        import time\n",
        "        time.sleep(2)\n",
        "        importlib.invalidate_caches()\n",
        "        try:\n",
        "            import torch  # type: ignore\n",
        "            info[\"torch_version\"] = getattr(torch, \"__version__\", \"desconocida\")\n",
        "            info[\"cuda_version\"] = getattr(getattr(torch, \"version\", object()), \"cuda\", \"desconocida\")\n",
        "            info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "            return torch, info\n",
        "        except Exception as e2:\n",
        "            print(f\"\\nâŒ No se pudo importar PyTorch despuÃ©s de reinstalar: {e2}\")\n",
        "            print(\"   Por favor, REINICIA EL KERNEL y ejecuta esta celda de nuevo.\")\n",
        "            raise RuntimeError(\"Reinicia el kernel de Jupyter y ejecuta esta celda de nuevo.\") from e2\n",
        "\n",
        "# Intentar importar/instalar PyTorch\n",
        "torch, torch_info = ensure_torch_cuda()\n",
        "\n",
        "print(\"\\nTorch info:\")\n",
        "for k, v in torch_info.items():\n",
        "    print(f\"  - {k}: {v}\")\n",
        "\n",
        "if torch_info.get(\"cuda_available\"):\n",
        "    try:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        cc = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU detectada: {gpu_name} | SM {cc.major}{cc.minor}\")\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ CUDA disponible pero no se pudo consultar GPU:\", e)\n",
        "else:\n",
        "    print(dedent(\n",
        "        \"\"\"\n",
        "        âš ï¸ CUDA sigue inactiva. Revisa drivers / reinicia kernel tras la instalaciÃ³n.\n",
        "        Si el problema continÃºa, ejecuta manualmente:\n",
        "          pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
        "        \"\"\"\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Todos los imports completados\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Imports y dependencias\n",
        "# ========================================\n",
        "# âš ï¸ IMPORTANTE: Ejecuta la celda anterior (Setup DLLs) antes de esta celda\n",
        "# torch ya estÃ¡ importado en la celda anterior\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch ya estÃ¡ importado en la celda anterior, solo importamos los submÃ³dulos\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        ")\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from prefect import task, flow\n",
        "from prefect.tasks import NO_CACHE\n",
        "\n",
        "# Instalar seaborn si no estÃ¡ disponible (para las visualizaciones de validaciÃ³n)\n",
        "try:\n",
        "    import seaborn as sns\n",
        "except ImportError:\n",
        "    print(\"â³ Instalando seaborn...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"])\n",
        "    import seaborn as sns\n",
        "    print(\"âœ“ seaborn instalado\")\n",
        "\n",
        "print(\"âœ“ Todos los imports completados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. âš™ï¸ ConfiguraciÃ³n General\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ ConfiguraciÃ³n cargada:\n",
            "{\n",
            "  \"DATA_DIR\": \"..\\\\data\\\\Datos_supervisados\\\\tensors_200hz\",\n",
            "  \"EXPERIMENT_NAME\": \"ecg_cnn_transformer_supervisado\",\n",
            "  \"RUN_NAME\": \"cnn_transformer_ecg_v1\",\n",
            "  \"OUTPUT_DIR\": \"outputs\",\n",
            "  \"N_CHANNELS\": 3,\n",
            "  \"SEQ_LEN\": 2000,\n",
            "  \"out_channels_list\": [\n",
            "    32,\n",
            "    64,\n",
            "    128\n",
            "  ],\n",
            "  \"kernel_sizes\": [\n",
            "    7,\n",
            "    5,\n",
            "    3\n",
            "  ],\n",
            "  \"pool_sizes\": [\n",
            "    2,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"USE_BATCHNORM\": true,\n",
            "  \"CNN_ACTIVATION\": \"relu\",\n",
            "  \"D_MODEL\": 256,\n",
            "  \"NHEAD\": 4,\n",
            "  \"NUM_ENCODER_LAYERS\": 3,\n",
            "  \"DIM_FEEDFORWARD\": 512,\n",
            "  \"TRANSFORMER_DROPOUT\": 0.1,\n",
            "  \"USE_POS_ENCODING\": true,\n",
            "  \"FC_UNITS\": 128,\n",
            "  \"BATCH_SIZE\": 128,\n",
            "  \"LEARNING_RATE\": 0.0003,\n",
            "  \"NUM_EPOCHS\": 50,\n",
            "  \"WEIGHT_DECAY\": 1e-05,\n",
            "  \"GRADIENT_ACCUMULATION_STEPS\": 1,\n",
            "  \"USE_SCHEDULER\": true,\n",
            "  \"WARMUP_STEPS\": 500,\n",
            "  \"SCHEDULER_PATIENCE\": 5,\n",
            "  \"SCHEDULER_FACTOR\": 0.5,\n",
            "  \"SCHEDULER_MIN_LR\": 1e-06,\n",
            "  \"SCHEDULER_MODE\": \"max\",\n",
            "  \"CLIP_GRAD_NORM\": 1.0,\n",
            "  \"SEED\": 42,\n",
            "  \"USE_CUDA\": true,\n",
            "  \"ENABLE_CUDNN_BENCHMARK\": true,\n",
            "  \"MLFLOW_TRACKING_URI\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# CONFIGURACIÃ“N GENERAL\n",
        "# ========================================\n",
        "\n",
        "# --- Rutas y nombres ---\n",
        "DATA_DIR = Path(\"../data/Datos_supervisados/tensors_200hz\")  # TODO: Ajustar ruta si es necesario\n",
        "EXPERIMENT_NAME = \"ecg_cnn_transformer_supervisado\"    # Nombre del experimento en MLflow\n",
        "RUN_NAME = \"cnn_transformer_ecg_v1\"          # Nombre del run en MLflow\n",
        "OUTPUT_DIR = Path(\"./outputs\")                 # Directorio para guardar artefactos\n",
        "\n",
        "# --- Datos de entrada ---\n",
        "N_CHANNELS = 3          # derivaciones de ECG (3 canales)\n",
        "SEQ_LEN = 2000          # TODO: timesteps por ejemplo (ej: 10 s a 200 Hz => 2000)\n",
        "\n",
        "# --- Arquitectura CNN 1D ---\n",
        "# Cada entrada en estas listas define una capa Conv1d:\n",
        "# - out_channels_list[i]: filtros de la capa i\n",
        "# - kernel_sizes[i]: tamaÃ±o de kernel para la capa i\n",
        "# - pool_sizes[i]: tamaÃ±o del MaxPool1d posterior (si se usa)\n",
        "out_channels_list = [32, 64, 128]   # TODO: ajustar cantidad de filtros por capa\n",
        "kernel_sizes = [7, 5, 3]           # TODO: ajustar tamaÃ±os de kernel\n",
        "pool_sizes = [2, 2, 2]             # TODO: ajustar factor de pooling por capa (o None si no se usa)\n",
        "USE_BATCHNORM = True                # aplicar BatchNorm1d despuÃ©s de cada conv\n",
        "CNN_ACTIVATION = \"relu\"             # usar ReLU\n",
        "\n",
        "# --- Arquitectura TRANSFORMER ---\n",
        "# d_model serÃ¡ la dimensiÃ³n de caracterÃ­sticas por timestep luego del bloque CNN\n",
        "D_MODEL = 256                        # dimensiÃ³n del espacio de representaciÃ³n para el Transformer\n",
        "NHEAD = 4                           # nÃºmero de cabezas de atenciÃ³n\n",
        "NUM_ENCODER_LAYERS = 3              # cantidad de capas TransformerEncoder\n",
        "DIM_FEEDFORWARD = 512               # dimensiÃ³n de la capa feedforward interna\n",
        "TRANSFORMER_DROPOUT = 0.1           # dropout dentro del Transformer\n",
        "USE_POS_ENCODING = True             # aplicar codificaciÃ³n posicional senoidal\n",
        "\n",
        "# --- Capa totalmente conectada ---\n",
        "FC_UNITS = 128                       # tamaÃ±o de la capa lineal antes de la salida\n",
        "\n",
        "# --- Entrenamiento ---\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 3e-4\n",
        "NUM_EPOCHS = 50\n",
        "WEIGHT_DECAY = 1e-5                 # regularizaciÃ³n L2 (0.0 si no se quiere)\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "WARMUP_STEPS = 500                 # pasos de warmup para el learning rate\n",
        "USE_SCHEDULER = True\n",
        "SCHEDULER_PATIENCE = 5\n",
        "SCHEDULER_FACTOR = 0.5\n",
        "SCHEDULER_MIN_LR = 1e-6\n",
        "SCHEDULER_MODE = 'max'  # Monitorear val_f1_macro (maximizar)\n",
        "CLIP_GRAD_NORM = 1.0\n",
        "\n",
        "# --- Otros ---\n",
        "SEED = 42\n",
        "USE_CUDA = True                     # si hay GPU disponible, usarla\n",
        "ENABLE_CUDNN_BENCHMARK = True\n",
        "\n",
        "# --- MLflow ---\n",
        "MLFLOW_TRACKING_URI = None  # None = usa el directorio local (sqlite:///mlflow.db)\n",
        "\n",
        "# Crear directorio de salida\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Diccionario de configuraciÃ³n (para pasar a funciones)\n",
        "CONFIG = {\n",
        "    \"DATA_DIR\": DATA_DIR,\n",
        "    \"EXPERIMENT_NAME\": EXPERIMENT_NAME,\n",
        "    \"RUN_NAME\": RUN_NAME,\n",
        "    \"OUTPUT_DIR\": OUTPUT_DIR,\n",
        "    \"N_CHANNELS\": N_CHANNELS,\n",
        "    \"SEQ_LEN\": SEQ_LEN,\n",
        "    \"out_channels_list\": out_channels_list,\n",
        "    \"kernel_sizes\": kernel_sizes,\n",
        "    \"pool_sizes\": pool_sizes,\n",
        "    \"USE_BATCHNORM\": USE_BATCHNORM,\n",
        "    \"CNN_ACTIVATION\": CNN_ACTIVATION,\n",
        "    \"D_MODEL\": D_MODEL,\n",
        "    \"NHEAD\": NHEAD,\n",
        "    \"NUM_ENCODER_LAYERS\": NUM_ENCODER_LAYERS,\n",
        "    \"DIM_FEEDFORWARD\": DIM_FEEDFORWARD,\n",
        "    \"TRANSFORMER_DROPOUT\": TRANSFORMER_DROPOUT,\n",
        "    \"USE_POS_ENCODING\": USE_POS_ENCODING,\n",
        "    \"FC_UNITS\": FC_UNITS,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"LEARNING_RATE\": LEARNING_RATE,\n",
        "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
        "    \"WEIGHT_DECAY\": WEIGHT_DECAY,\n",
        "    \"GRADIENT_ACCUMULATION_STEPS\": GRADIENT_ACCUMULATION_STEPS,\n",
        "    \"USE_SCHEDULER\": USE_SCHEDULER,\n",
        "    \"WARMUP_STEPS\": WARMUP_STEPS,\n",
        "    \"SCHEDULER_PATIENCE\": SCHEDULER_PATIENCE,\n",
        "    \"SCHEDULER_FACTOR\": SCHEDULER_FACTOR,\n",
        "    \"SCHEDULER_MIN_LR\": SCHEDULER_MIN_LR,\n",
        "    \"SCHEDULER_MODE\": SCHEDULER_MODE,\n",
        "    \"CLIP_GRAD_NORM\": CLIP_GRAD_NORM,\n",
        "    \"SEED\": SEED,\n",
        "    \"USE_CUDA\": USE_CUDA,\n",
        "    \"ENABLE_CUDNN_BENCHMARK\": ENABLE_CUDNN_BENCHMARK,\n",
        "    \"MLFLOW_TRACKING_URI\": MLFLOW_TRACKING_URI,\n",
        "}\n",
        "\n",
        "print(\"âœ“ ConfiguraciÃ³n cargada:\")\n",
        "print(json.dumps({k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()}, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ cuDNN Benchmark: Habilitado\n",
            "âœ“ Semilla fijada: 42\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ConfiguraciÃ³n de semillas aleatorias y optimizaciones GPU\n",
        "# ========================================\n",
        "def set_seed_everywhere(seed: int = 42, enable_cudnn_benchmark: bool = True) -> None:\n",
        "    \"\"\"Fija semillas para reproducibilidad y optimiza GPU.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.benchmark = enable_cudnn_benchmark\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"âœ“ cuDNN Benchmark: {'Habilitado' if enable_cudnn_benchmark else 'Deshabilitado'}\")\n",
        "\n",
        "set_seed_everywhere(SEED, enable_cudnn_benchmark=CONFIG.get(\"ENABLE_CUDNN_BENCHMARK\", True))\n",
        "print(f\"âœ“ Semilla fijada: {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ GPU detectada: NVIDIA GeForce RTX 5080\n",
            "  CUDA Version: 12.8\n",
            "  PyTorch Version: 2.10.0.dev20251121+cu128\n",
            "Dispositivo seleccionado: cuda\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ConfiguraciÃ³n de dispositivo (GPU/CPU)\n",
        "# ========================================\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"Detecta y configura el dispositivo (GPU si estÃ¡ disponible).\"\"\"\n",
        "    if USE_CUDA and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"âœ“ GPU detectada: {gpu_name}\")\n",
        "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"  PyTorch Version: {torch.__version__}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"âš  GPU no disponible, usando CPU\")\n",
        "    return device\n",
        "\n",
        "DEVICE = get_device()\n",
        "print(f\"Dispositivo seleccionado: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. ðŸ“‚ Carga y PreparaciÃ³n de Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n para cargar datos desde tensors_200hz (archivos .pt)\n",
        "# ========================================\n",
        "def load_tensor_data(\n",
        "    data_dir: Path,\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Carga los datos desde archivos .pt en tensors_200hz.\n",
        "    \n",
        "    Args:\n",
        "        data_dir: Ruta a la carpeta tensors_200hz\n",
        "        \n",
        "    Returns:\n",
        "        Tuple con (X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"ðŸ“‚ CARGANDO DATOS DESDE tensors_200hz\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Directorio: {data_dir.resolve()}\")\n",
        "    \n",
        "    # Cargar tensors\n",
        "    print(\"\\nâ³ Cargando tensors desde disco...\")\n",
        "    X_train = torch.load(data_dir / \"X_train.pt\", map_location='cpu')\n",
        "    y_train = torch.load(data_dir / \"y_train.pt\", map_location='cpu')\n",
        "    X_val = torch.load(data_dir / \"X_val.pt\", map_location='cpu')\n",
        "    y_val = torch.load(data_dir / \"y_val.pt\", map_location='cpu')\n",
        "    X_test = torch.load(data_dir / \"X_test.pt\", map_location='cpu')\n",
        "    y_test = torch.load(data_dir / \"y_test.pt\", map_location='cpu')\n",
        "    \n",
        "    # Verificar formas\n",
        "    print(f\"\\nâœ“ Datos cargados:\")\n",
        "    print(f\"  X_train: {X_train.shape} | y_train: {y_train.shape} (normales: {(y_train==0).sum().item()}, anÃ³malos: {(y_train==1).sum().item()})\")\n",
        "    print(f\"  X_val:   {X_val.shape} | y_val:   {y_val.shape} (normales: {(y_val==0).sum().item()}, anÃ³malos: {(y_val==1).sum().item()})\")\n",
        "    print(f\"  X_test:  {X_test.shape} | y_test:  {y_test.shape} (normales: {(y_test==0).sum().item()}, anÃ³malos: {(y_test==1).sum().item()})\")\n",
        "    \n",
        "    # Verificar que las features coincidan con CONFIG\n",
        "    if X_train.shape[-1] != CONFIG[\"N_CHANNELS\"]:\n",
        "        print(f\"âš ï¸ ADVERTENCIA: X_train tiene {X_train.shape[-1]} canales, pero N_CHANNELS={CONFIG['N_CHANNELS']}\")\n",
        "        print(f\"   Ajustando N_CHANNELS a {X_train.shape[-1]}\")\n",
        "        CONFIG[\"N_CHANNELS\"] = X_train.shape[-1]\n",
        "    \n",
        "    # Verificar SEQ_LEN\n",
        "    if len(X_train.shape) >= 2 and X_train.shape[1] != CONFIG[\"SEQ_LEN\"]:\n",
        "        print(f\"âš ï¸ ADVERTENCIA: X_train tiene {X_train.shape[1]} timesteps, pero SEQ_LEN={CONFIG['SEQ_LEN']}\")\n",
        "        print(f\"   Ajustando SEQ_LEN a {X_train.shape[1]}\")\n",
        "        CONFIG[\"SEQ_LEN\"] = X_train.shape[1]\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "\n",
        "def create_dataloaders_from_tensors(\n",
        "    X_train: torch.Tensor,\n",
        "    y_train: torch.Tensor,\n",
        "    X_val: torch.Tensor,\n",
        "    y_val: torch.Tensor,\n",
        "    X_test: torch.Tensor,\n",
        "    y_test: torch.Tensor,\n",
        "    batch_size: int,\n",
        "    shuffle_train: bool = True,\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Crea DataLoaders desde tensors.\n",
        "    \n",
        "    Returns:\n",
        "        Tuple con (train_loader, val_loader, test_loader)\n",
        "    \"\"\"\n",
        "    # Crear datasets\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    val_dataset = TensorDataset(X_val, y_val)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    \n",
        "    # Crear dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_train,\n",
        "        num_workers=0,  # 0 para Windows\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nâœ“ DataLoaders creados:\")\n",
        "    print(f\"  Train: {len(train_loader)} batches ({len(train_dataset)} muestras)\")\n",
        "    print(f\"  Val:   {len(val_loader)} batches ({len(val_dataset)} muestras)\")\n",
        "    print(f\"  Test:  {len(test_loader)} batches ({len(test_dataset)} muestras)\")\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Clase para CodificaciÃ³n Posicional Senoidal\n",
        "# ========================================\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    CodificaciÃ³n posicional senoidal para Transformer.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Crear la matriz de codificaciÃ³n posicional\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)  # (max_len, 1, d_model)\n",
        "        \n",
        "        # Registrar como buffer (no es un parÃ¡metro entrenable)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor de forma (seq_len, batch, d_model)\n",
        "        Returns:\n",
        "            Tensor con codificaciÃ³n posicional aÃ±adida\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Clase CNN1D + Transformer para ClasificaciÃ³n Binaria\n",
        "# ========================================\n",
        "class CNN1D_TransformerClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN1D + Transformer Encoder para clasificaciÃ³n binaria de series temporales (ECG normal vs anÃ³malo).\n",
        "    \n",
        "    Arquitectura:\n",
        "    - Bloque CNN1D: ExtracciÃ³n de caracterÃ­sticas locales\n",
        "    - Transformer Encoder: Captura de dependencias temporales con atenciÃ³n\n",
        "    - Capa fully connected\n",
        "    - Salida binaria (sigmoid)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        n_channels: int,\n",
        "        seq_len: int,\n",
        "        out_channels_list: List[int],\n",
        "        kernel_sizes: List[int],\n",
        "        pool_sizes: List[int],\n",
        "        use_batchnorm: bool = True,\n",
        "        cnn_activation: str = \"relu\",\n",
        "        d_model: int = 64,\n",
        "        nhead: int = 4,\n",
        "        num_encoder_layers: int = 2,\n",
        "        dim_feedforward: int = 128,\n",
        "        transformer_dropout: float = 0.1,\n",
        "        use_pos_encoding: bool = True,\n",
        "        fc_units: int = 32,\n",
        "    ):\n",
        "        super(CNN1D_TransformerClassifier, self).__init__()\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.seq_len = seq_len\n",
        "        self.out_channels_list = out_channels_list\n",
        "        self.num_cnn_layers = len(out_channels_list)\n",
        "        self.d_model = d_model\n",
        "        self.use_pos_encoding = use_pos_encoding\n",
        "        \n",
        "        # ========================================\n",
        "        # Bloque CNN 1D\n",
        "        # ========================================\n",
        "        cnn_layers = []\n",
        "        in_channels = n_channels\n",
        "        \n",
        "        for i in range(self.num_cnn_layers):\n",
        "            # Conv1d\n",
        "            cnn_layers.append(\n",
        "                nn.Conv1d(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels_list[i],\n",
        "                    kernel_size=kernel_sizes[i],\n",
        "                    padding=(kernel_sizes[i] - 1) // 2,  # padding 'same'\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            # BatchNorm (si estÃ¡ habilitado)\n",
        "            if use_batchnorm:\n",
        "                cnn_layers.append(nn.BatchNorm1d(out_channels_list[i]))\n",
        "            \n",
        "            # ActivaciÃ³n\n",
        "            if cnn_activation.lower() == \"relu\":\n",
        "                cnn_layers.append(nn.ReLU())\n",
        "            elif cnn_activation.lower() == \"leakyrelu\":\n",
        "                cnn_layers.append(nn.LeakyReLU(0.1))\n",
        "            else:\n",
        "                raise ValueError(f\"ActivaciÃ³n {cnn_activation} no soportada\")\n",
        "            \n",
        "            # MaxPool (si estÃ¡ definido)\n",
        "            if pool_sizes[i] is not None and pool_sizes[i] > 1:\n",
        "                cnn_layers.append(nn.MaxPool1d(kernel_size=pool_sizes[i]))\n",
        "            \n",
        "            in_channels = out_channels_list[i]\n",
        "        \n",
        "        self.cnn = nn.Sequential(*cnn_layers)\n",
        "        \n",
        "        # Calcular tamaÃ±o de salida de CNN despuÃ©s del pooling\n",
        "        # Hacemos un forward dummy para determinar el tamaÃ±o de salida\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, n_channels, seq_len)\n",
        "            cnn_output = self.cnn(dummy_input)\n",
        "            # cnn_output shape: (batch, out_channels, seq_len_reduced)\n",
        "            self.cnn_output_seq_len = cnn_output.shape[2]\n",
        "            self.cnn_output_channels = cnn_output.shape[1]\n",
        "        \n",
        "        # ProyecciÃ³n lineal para ajustar la dimensiÃ³n a d_model\n",
        "        # Si cnn_output_channels != d_model, necesitamos proyectar\n",
        "        if self.cnn_output_channels != d_model:\n",
        "            self.cnn_projection = nn.Linear(self.cnn_output_channels, d_model)\n",
        "        else:\n",
        "            self.cnn_projection = nn.Identity()\n",
        "        \n",
        "        # ========================================\n",
        "        # Transformer Encoder\n",
        "        # ========================================\n",
        "        # La entrada al Transformer es (seq_len, batch, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=transformer_dropout,\n",
        "            activation='relu',\n",
        "            batch_first=False,  # (seq_len, batch, features) para positional encoding\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_encoder_layers,\n",
        "        )\n",
        "        \n",
        "        # CodificaciÃ³n posicional\n",
        "        if use_pos_encoding:\n",
        "            self.pos_encoder = PositionalEncoding(d_model, max_len=seq_len, dropout=transformer_dropout)\n",
        "        else:\n",
        "            self.pos_encoder = None\n",
        "        \n",
        "        # ========================================\n",
        "        # Capas Fully Connected\n",
        "        # ========================================\n",
        "        # Pooling global para obtener representaciÃ³n de la secuencia completa\n",
        "        # Usamos el Ãºltimo timestep del encoder o average pooling\n",
        "        self.fc1 = nn.Linear(d_model, fc_units)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout_fc = nn.Dropout(transformer_dropout)\n",
        "        \n",
        "        # Capa de salida (binaria)\n",
        "        self.fc2 = nn.Linear(fc_units, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "        \n",
        "        Args:\n",
        "            x: Tensor de forma (batch_size, seq_len, n_channels) o (batch_size, n_channels, seq_len)\n",
        "        \n",
        "        Returns:\n",
        "            Tensor de forma (batch_size,) con probabilidades\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        # Asegurar que x tiene forma (batch_size, n_channels, seq_len) para Conv1d\n",
        "        if len(x.shape) == 3 and x.shape[1] == self.seq_len and x.shape[2] == self.n_channels:\n",
        "            # Forma (batch, seq_len, channels) -> transponer a (batch, channels, seq_len)\n",
        "            x = x.transpose(1, 2)\n",
        "        # Si ya estÃ¡ en forma (batch, channels, seq_len), no hacer nada\n",
        "        \n",
        "        # CNN1D: (batch, channels, seq_len) -> (batch, out_channels, seq_len_reduced)\n",
        "        cnn_out = self.cnn(x)\n",
        "        \n",
        "        # Transponer para preparar para Transformer: (batch, out_channels, seq_len_reduced) \n",
        "        # -> (batch, seq_len_reduced, out_channels)\n",
        "        cnn_out = cnn_out.transpose(1, 2)  # (batch, seq_len_reduced, out_channels)\n",
        "        \n",
        "        # Proyectar a d_model si es necesario\n",
        "        cnn_out = self.cnn_projection(cnn_out)  # (batch, seq_len_reduced, d_model)\n",
        "        \n",
        "        # Preparar para Transformer: (batch, seq_len, d_model) -> (seq_len, batch, d_model)\n",
        "        transformer_input = cnn_out.transpose(0, 1)  # (seq_len_reduced, batch, d_model)\n",
        "        \n",
        "        # Aplicar codificaciÃ³n posicional si estÃ¡ habilitada\n",
        "        if self.pos_encoder is not None:\n",
        "            transformer_input = self.pos_encoder(transformer_input)\n",
        "        \n",
        "        # Transformer Encoder: (seq_len, batch, d_model) -> (seq_len, batch, d_model)\n",
        "        transformer_output = self.transformer_encoder(transformer_input)\n",
        "        \n",
        "        # Usar el Ãºltimo timestep o promedio global\n",
        "        # OpciÃ³n 1: Ãšltimo timestep (mÃ¡s comÃºn en clasificaciÃ³n)\n",
        "        last_timestep = transformer_output[-1]  # (batch, d_model)\n",
        "        \n",
        "        # OpciÃ³n 2: Average pooling (comentado, usar si prefieres)\n",
        "        # last_timestep = transformer_output.mean(dim=0)  # (batch, d_model)\n",
        "        \n",
        "        # Fully connected\n",
        "        out = self.fc1(last_timestep)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout_fc(out)\n",
        "        \n",
        "        # Salida binaria\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        \n",
        "        return out.squeeze(-1)  # (batch_size,)\n",
        "    \n",
        "    def predict_proba(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Devuelve probabilidades (mismo que forward).\"\"\"\n",
        "        return self.forward(x)\n",
        "    \n",
        "    def predict(self, x: torch.Tensor, threshold: float = 0.5) -> torch.Tensor:\n",
        "        \"\"\"Devuelve predicciones binarias.\"\"\"\n",
        "        proba = self.forward(x)\n",
        "        return (proba > threshold).long()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Instanciar modelo\n",
        "# ========================================\n",
        "def create_model(config: Dict) -> CNN1D_TransformerClassifier:\n",
        "    \"\"\"Crea e instancia el modelo CNN1D + Transformer.\"\"\"\n",
        "    model = CNN1D_TransformerClassifier(\n",
        "        n_channels=config[\"N_CHANNELS\"],\n",
        "        seq_len=config[\"SEQ_LEN\"],\n",
        "        out_channels_list=config[\"out_channels_list\"],\n",
        "        kernel_sizes=config[\"kernel_sizes\"],\n",
        "        pool_sizes=config[\"pool_sizes\"],\n",
        "        use_batchnorm=config[\"USE_BATCHNORM\"],\n",
        "        cnn_activation=config[\"CNN_ACTIVATION\"],\n",
        "        d_model=config[\"D_MODEL\"],\n",
        "        nhead=config[\"NHEAD\"],\n",
        "        num_encoder_layers=config[\"NUM_ENCODER_LAYERS\"],\n",
        "        dim_feedforward=config[\"DIM_FEEDFORWARD\"],\n",
        "        transformer_dropout=config[\"TRANSFORMER_DROPOUT\"],\n",
        "        use_pos_encoding=config[\"USE_POS_ENCODING\"],\n",
        "        fc_units=config[\"FC_UNITS\"],\n",
        "    )\n",
        "    \n",
        "    # Contar parÃ¡metros\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    print(f\"âœ“ Modelo creado:\")\n",
        "    print(f\"  ParÃ¡metros totales: {total_params:,} ({total_params / 1e6:.2f}M)\")\n",
        "    print(f\"  ParÃ¡metros entrenables: {trainable_params:,}\")\n",
        "    print(f\"  CNN output shape: (batch, {model.cnn_output_channels}, {model.cnn_output_seq_len})\")\n",
        "    print(f\"  Transformer input size: {model.d_model}\")\n",
        "    print(f\"  Transformer encoder layers: {config['NUM_ENCODER_LAYERS']}\")\n",
        "    print(f\"  Attention heads: {config['NHEAD']}\")\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. ðŸ‹ï¸ Funciones de Entrenamiento y EvaluaciÃ³n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n de entrenamiento por Ã©poca\n",
        "# ========================================\n",
        "def train_one_epoch(\n",
        "    model: CNN1D_TransformerClassifier,\n",
        "    train_loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        "    gradient_accumulation_steps: int = 1,\n",
        "    clip_grad_norm: Optional[float] = None,\n",
        "    warmup_scheduler: Optional[optim.lr_scheduler.LambdaLR] = None,\n",
        "    global_step: int = 0,\n",
        ") -> Tuple[float, float, int]:\n",
        "    \"\"\"\n",
        "    Entrena el modelo por una Ã©poca.\n",
        "    \n",
        "    Returns:\n",
        "        Tupla con (loss_promedio, accuracy_promedio, nÃºmero_de_pasos)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    steps = 0\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for batch_idx, (batch_x, batch_y) in enumerate(train_loader):\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        batch_y = batch_y.to(device, non_blocking=True).float()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        \n",
        "        # Normalizar pÃ©rdida si usas gradient accumulation\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping (antes de optimizer.step)\n",
        "        if clip_grad_norm is not None and clip_grad_norm > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
        "        \n",
        "        # Actualizar pesos solo cada N pasos (gradient accumulation)\n",
        "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Actualizar warmup scheduler si existe\n",
        "            if warmup_scheduler is not None:\n",
        "                warmup_scheduler.step()\n",
        "            \n",
        "            steps += 1\n",
        "        \n",
        "        # Acumular mÃ©tricas\n",
        "        total_loss += loss.item() * batch_x.size(0) * gradient_accumulation_steps\n",
        "        predictions = (outputs > 0.5).long()\n",
        "        correct += (predictions == batch_y.long()).sum().item()\n",
        "        total += batch_x.size(0)\n",
        "    \n",
        "    # Actualizar si quedan gradientes pendientes\n",
        "    if (batch_idx + 1) % gradient_accumulation_steps != 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if warmup_scheduler is not None:\n",
        "            warmup_scheduler.step()\n",
        "        steps += 1\n",
        "    \n",
        "    avg_loss = total_loss / total if total > 0 else 0.0\n",
        "    avg_accuracy = correct / total if total > 0 else 0.0\n",
        "    \n",
        "    return avg_loss, avg_accuracy, steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n de evaluaciÃ³n\n",
        "# ========================================\n",
        "def evaluate(\n",
        "    model: CNN1D_TransformerClassifier,\n",
        "    dataloader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> Tuple[float, float, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    EvalÃºa el modelo en un dataloader.\n",
        "    \n",
        "    Returns:\n",
        "        Tupla con (loss, accuracy, y_true, y_pred)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in dataloader:\n",
        "            batch_x = batch_x.to(device, non_blocking=True)\n",
        "            batch_y = batch_y.to(device, non_blocking=True).float()\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            \n",
        "            # Acumular mÃ©tricas\n",
        "            total_loss += loss.item() * batch_x.size(0)\n",
        "            predictions = (outputs > 0.5).long()\n",
        "            correct += (predictions == batch_y.long()).sum().item()\n",
        "            total += batch_x.size(0)\n",
        "            \n",
        "            # Guardar predicciones y etiquetas\n",
        "            all_preds.append(predictions.cpu().numpy())\n",
        "            all_labels.append(batch_y.long().cpu().numpy())\n",
        "    \n",
        "    avg_loss = total_loss / total if total > 0 else 0.0\n",
        "    avg_accuracy = correct / total if total > 0 else 0.0\n",
        "    \n",
        "    y_true = np.concatenate(all_labels)\n",
        "    y_pred = np.concatenate(all_preds)\n",
        "    \n",
        "    return avg_loss, avg_accuracy, y_true, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n para calcular mÃ©tricas completas\n",
        "# ========================================\n",
        "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula mÃ©tricas completas de clasificaciÃ³n.\n",
        "    \n",
        "    Returns:\n",
        "        Diccionario con todas las mÃ©tricas\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    \n",
        "    # Calcular mÃ©tricas por clase usando classification_report\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"normal\", \"anomalo\"],\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    \n",
        "    # MÃ©tricas para clase normal (0)\n",
        "    metrics_normal = report.get(\"normal\", {})\n",
        "    precision_normal = metrics_normal.get(\"precision\", 0.0)\n",
        "    recall_normal = metrics_normal.get(\"recall\", 0.0)\n",
        "    f1_normal = metrics_normal.get(\"f1-score\", 0.0)\n",
        "    \n",
        "    # MÃ©tricas para clase anÃ³mala (1)\n",
        "    metrics_anom = report.get(\"anomalo\", {})\n",
        "    precision_anom = metrics_anom.get(\"precision\", 0.0)\n",
        "    recall_anom = metrics_anom.get(\"recall\", 0.0)\n",
        "    f1_anom = metrics_anom.get(\"f1-score\", 0.0)\n",
        "    \n",
        "    # MÃ©tricas generales (macro avg)\n",
        "    macro_avg = report.get(\"macro avg\", {})\n",
        "    precision_macro = macro_avg.get(\"precision\", 0.0)\n",
        "    recall_macro = macro_avg.get(\"recall\", 0.0)\n",
        "    f1_macro = macro_avg.get(\"f1-score\", 0.0)\n",
        "    \n",
        "    # Matriz de confusiÃ³n\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / max(1, tn + fp)  # TNR\n",
        "    sensitivity = tp / max(1, tp + fn)   # TPR (recall de clase anÃ³mala)\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"specificity\": specificity,\n",
        "        \"sensitivity\": sensitivity,\n",
        "        \"precision_normal\": precision_normal,\n",
        "        \"recall_normal\": recall_normal,\n",
        "        \"f1_normal\": f1_normal,\n",
        "        \"precision_anom\": precision_anom,\n",
        "        \"recall_anom\": recall_anom,\n",
        "        \"f1_anom\": f1_anom,\n",
        "        \"precision_macro\": precision_macro,\n",
        "        \"recall_macro\": recall_macro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"confusion_matrix\": cm,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. ðŸ“Š IntegraciÃ³n con MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ConfiguraciÃ³n de MLflow\n",
        "# ========================================\n",
        "def setup_mlflow(config: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Configura MLflow y crea/obtiene el experimento.\n",
        "    \n",
        "    Returns:\n",
        "        ID del experimento\n",
        "    \"\"\"\n",
        "    # Configurar tracking URI\n",
        "    if config.get(\"MLFLOW_TRACKING_URI\") is not None:\n",
        "        mlflow.set_tracking_uri(config[\"MLFLOW_TRACKING_URI\"])\n",
        "    else:\n",
        "        # Usar sqlite en el directorio padre\n",
        "        PARENT_DIR = Path.cwd().parent.resolve()\n",
        "        TRACKING_DB = (PARENT_DIR / \"mlflow.db\").resolve()\n",
        "        mlflow.set_tracking_uri(f\"sqlite:///{TRACKING_DB.as_posix()}\")\n",
        "        print(f\"âœ“ MLflow tracking URI: sqlite:///{TRACKING_DB.as_posix()}\")\n",
        "    \n",
        "    # Crear o obtener experimento\n",
        "    experiment_name = config[\"EXPERIMENT_NAME\"]\n",
        "    \n",
        "    try:\n",
        "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "        if experiment is None:\n",
        "            # Crear directorio de artefactos\n",
        "            PARENT_DIR = Path.cwd().parent.resolve()\n",
        "            ARTIFACT_ROOT = (PARENT_DIR / \"mlflow_artifacts\").resolve()\n",
        "            ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "            experiment_id = mlflow.create_experiment(experiment_name, artifact_location=ARTIFACT_ROOT.as_uri())\n",
        "            print(f\"âœ“ Experimento MLflow creado: {experiment_name} (ID: {experiment_id})\")\n",
        "            print(f\"  Artifact root: {ARTIFACT_ROOT.as_uri()}\")\n",
        "        else:\n",
        "            experiment_id = experiment.experiment_id\n",
        "            print(f\"âœ“ Experimento MLflow existente: {experiment_name} (ID: {experiment_id})\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Error al configurar MLflow: {e}\")\n",
        "        experiment_id = mlflow.set_experiment(experiment_name)\n",
        "    \n",
        "    return experiment_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n para guardar matriz de confusiÃ³n como artefacto\n",
        "# ========================================\n",
        "def save_confusion_matrix(\n",
        "    cm: np.ndarray,\n",
        "    output_dir: Path,\n",
        "    tag: str,\n",
        ") -> Tuple[Path, Path]:\n",
        "    \"\"\"\n",
        "    Guarda la matriz de confusiÃ³n como PNG y CSV.\n",
        "    \n",
        "    Returns:\n",
        "        Tupla con rutas (png_path, csv_path)\n",
        "    \"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Guardar como CSV\n",
        "    csv_path = output_dir / f\"confusion_matrix_{tag}.csv\"\n",
        "    df_cm = pd.DataFrame(cm, index=[\"Normal\", \"AnÃ³malo\"], columns=[\"Normal\", \"AnÃ³malo\"])\n",
        "    df_cm.to_csv(csv_path)\n",
        "    \n",
        "    # Guardar como PNG\n",
        "    png_path = output_dir / f\"confusion_matrix_{tag}.png\"\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    \n",
        "    # Etiquetas\n",
        "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]))\n",
        "    ax.set_xticklabels([\"Normal\", \"AnÃ³malo\"])\n",
        "    ax.set_yticklabels([\"Normal\", \"AnÃ³malo\"])\n",
        "    ax.set_xlabel(\"PredicciÃ³n\")\n",
        "    ax.set_ylabel(\"Real\")\n",
        "    ax.set_title(f\"Matriz de ConfusiÃ³n - {tag.upper()}\")\n",
        "    \n",
        "    # AÃ±adir valores en las celdas\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(\n",
        "                j, i, f\"{cm[i, j]}\",\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\"\n",
        "            )\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(png_path, dpi=150)\n",
        "    plt.close()\n",
        "    \n",
        "    return png_path, csv_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n para guardar grÃ¡ficos de curvas de entrenamiento\n",
        "# ========================================\n",
        "def save_training_curves(\n",
        "    train_losses: List[float],\n",
        "    train_accuracies: List[float],\n",
        "    val_losses: List[float],\n",
        "    val_f1_scores: List[float],\n",
        "    output_dir: Path,\n",
        "    learning_rates: Optional[List[float]] = None,\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Guarda grÃ¡ficos de curvas de entrenamiento.\n",
        "    \n",
        "    Returns:\n",
        "        Ruta del archivo PNG guardado\n",
        "    \"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Usar 2x3 si hay learning rates, sino 2x2\n",
        "    if learning_rates:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    \n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    \n",
        "    # Loss\n",
        "    axes[0, 0].plot(epochs, train_losses, label=\"Train Loss\", color=\"blue\")\n",
        "    axes[0, 0].plot(epochs, val_losses, label=\"Val Loss\", color=\"red\")\n",
        "    axes[0, 0].set_xlabel(\"Ã‰poca\")\n",
        "    axes[0, 0].set_ylabel(\"Loss (BCE)\")\n",
        "    axes[0, 0].set_title(\"Loss de Entrenamiento y ValidaciÃ³n\")\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    axes[0, 0].legend()\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[0, 1].plot(epochs, train_accuracies, label=\"Train Accuracy\", color=\"blue\")\n",
        "    axes[0, 1].set_xlabel(\"Ã‰poca\")\n",
        "    axes[0, 1].set_ylabel(\"Accuracy\")\n",
        "    axes[0, 1].set_title(\"Accuracy de Entrenamiento\")\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    axes[0, 1].legend()\n",
        "    \n",
        "    # F1 Score en validaciÃ³n\n",
        "    if val_f1_scores:\n",
        "        axes[1, 0].plot(epochs, val_f1_scores, label=\"Val F1 (macro)\", color=\"red\")\n",
        "        axes[1, 0].set_xlabel(\"Ã‰poca\")\n",
        "        axes[1, 0].set_ylabel(\"F1-Score\")\n",
        "        axes[1, 0].set_title(\"F1-Score en ValidaciÃ³n\")\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        axes[1, 0].legend()\n",
        "    \n",
        "    # Learning Rate (si estÃ¡ disponible)\n",
        "    if learning_rates:\n",
        "        axes[0, 2].plot(epochs, learning_rates, label=\"Learning Rate\", color=\"green\")\n",
        "        axes[0, 2].set_xlabel(\"Ã‰poca\")\n",
        "        axes[0, 2].set_ylabel(\"Learning Rate\")\n",
        "        axes[0, 2].set_title(\"Learning Rate durante Entrenamiento\")\n",
        "        axes[0, 2].set_yscale('log')\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "        axes[0, 2].legend()\n",
        "        \n",
        "        axes[1, 1].plot(epochs, train_accuracies, label=\"Train Accuracy\", color=\"blue\", alpha=0.7)\n",
        "        axes[1, 1].set_xlabel(\"Ã‰poca\")\n",
        "        axes[1, 1].set_ylabel(\"Accuracy\")\n",
        "        axes[1, 1].set_title(\"Train Accuracy\")\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        axes[1, 1].legend()\n",
        "        \n",
        "        axes[1, 2].plot(epochs, train_losses, label=\"Train Loss\", color=\"blue\", alpha=0.7)\n",
        "        axes[1, 2].plot(epochs, val_losses, label=\"Val Loss\", color=\"red\", alpha=0.7)\n",
        "        axes[1, 2].set_xlabel(\"Ã‰poca\")\n",
        "        axes[1, 2].set_ylabel(\"Loss\")\n",
        "        axes[1, 2].set_title(\"Train vs Val Loss\")\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "        axes[1, 2].legend()\n",
        "    else:\n",
        "        axes[1, 1].plot(epochs, train_accuracies, label=\"Train Accuracy\", color=\"blue\", alpha=0.7)\n",
        "        axes[1, 1].set_xlabel(\"Ã‰poca\")\n",
        "        axes[1, 1].set_ylabel(\"Accuracy\")\n",
        "        axes[1, 1].set_title(\"Accuracy de Entrenamiento\")\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        axes[1, 1].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    png_path = output_dir / \"training_curves.png\"\n",
        "    plt.savefig(png_path, dpi=150)\n",
        "    plt.close()\n",
        "    \n",
        "    return png_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. ðŸª„ OrquestaciÃ³n con Prefect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Tarea Prefect: Cargar datos\n",
        "# ========================================\n",
        "@task(name=\"load_data\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_load_data(config: Dict):\n",
        "    \"\"\"Tarea Prefect para cargar datos desde tensors_200hz.\"\"\"\n",
        "    print(\"ðŸ“‚ Cargando datos...\")\n",
        "    # Cargar tensors desde disco\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = load_tensor_data(\n",
        "        config[\"DATA_DIR\"]\n",
        "    )\n",
        "    \n",
        "    # Crear dataloaders\n",
        "    train_loader, val_loader, test_loader = create_dataloaders_from_tensors(\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "        batch_size=config[\"BATCH_SIZE\"],\n",
        "        shuffle_train=True,\n",
        "    )\n",
        "    \n",
        "    # Convertir y_val e y_test a numpy para mÃ©tricas\n",
        "    y_val_np = y_val.numpy()\n",
        "    y_test_np = y_test.numpy()\n",
        "    \n",
        "    print(\"âœ“ Datos cargados y preparados\")\n",
        "    return train_loader, val_loader, test_loader, y_val_np, y_test_np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Tarea Prefect: Entrenar modelo\n",
        "# ========================================\n",
        "@task(name=\"train_model\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_train_model(\n",
        "    model: CNN1D_TransformerClassifier,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    y_val: np.ndarray,\n",
        "    config: Dict,\n",
        "    device: torch.device,\n",
        "    experiment_id: str,\n",
        "):\n",
        "    \"\"\"Tarea Prefect para entrenar el modelo.\"\"\"\n",
        "    print(\"ðŸ‹ï¸ Iniciando entrenamiento...\")\n",
        "    print(f\"  ðŸ“Š Verificando DataLoaders...\")\n",
        "    print(f\"    Train: {len(train_loader)} batches ({len(train_loader.dataset)} muestras)\")\n",
        "    print(f\"    Val: {len(val_loader)} batches ({len(val_loader.dataset)} muestras)\")\n",
        "    print(f\"    Device: {device}\")\n",
        "    \n",
        "    # Mover modelo a dispositivo\n",
        "    print(f\"  ðŸ”„ Moviendo modelo a {device}...\")\n",
        "    model = model.to(device)\n",
        "    print(f\"  âœ“ Modelo en {device}\")\n",
        "    \n",
        "    # Optimizador y criterio\n",
        "    print(f\"  ðŸ”„ Inicializando optimizador y criterio...\")\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config[\"LEARNING_RATE\"],\n",
        "        weight_decay=config[\"WEIGHT_DECAY\"],\n",
        "    )\n",
        "    criterion = nn.BCELoss()\n",
        "    print(f\"  âœ“ Optimizador y criterio listos\")\n",
        "    \n",
        "    # Learning Rate Scheduler con Warmup\n",
        "    warmup_steps = config.get(\"WARMUP_STEPS\", 0)\n",
        "    warmup_scheduler = None\n",
        "    scheduler = None\n",
        "    \n",
        "    if warmup_steps > 0:\n",
        "        # Crear funciÃ³n lambda para warmup linear\n",
        "        def warmup_lambda(step: int) -> float:\n",
        "            if step < warmup_steps:\n",
        "                return float(step) / float(max(1, warmup_steps))\n",
        "            return 1.0\n",
        "        \n",
        "        warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lambda)\n",
        "        print(f\"âœ“ Warmup Scheduler configurado: {warmup_steps} pasos\")\n",
        "    \n",
        "    if config.get(\"USE_SCHEDULER\", False):\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode=config.get(\"SCHEDULER_MODE\", \"max\"),\n",
        "            factor=config.get(\"SCHEDULER_FACTOR\", 0.5),\n",
        "            patience=config.get(\"SCHEDULER_PATIENCE\", 5),\n",
        "            min_lr=config.get(\"SCHEDULER_MIN_LR\", 1e-6),\n",
        "        )\n",
        "        print(f\"âœ“ Learning Rate Scheduler (ReduceLROnPlateau) configurado\")\n",
        "    \n",
        "    # Gradient clipping\n",
        "    clip_grad_norm = config.get(\"CLIP_GRAD_NORM\", None)\n",
        "    if clip_grad_norm is not None and clip_grad_norm > 0:\n",
        "        print(f\"âœ“ Gradient Clipping habilitado: {clip_grad_norm}\")\n",
        "    \n",
        "    # Listas para tracking\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_f1_scores = []\n",
        "    learning_rates = []\n",
        "    best_f1 = 0.0\n",
        "    best_model_state = None\n",
        "    global_step = 0  # Contador global de pasos para warmup\n",
        "    \n",
        "    # Iniciar run de MLflow\n",
        "    print(f\"  ðŸ”„ Iniciando run de MLflow...\")\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=config[\"RUN_NAME\"]):\n",
        "        print(f\"  âœ“ Run de MLflow iniciado\")\n",
        "        # Log hiperparÃ¡metros\n",
        "        print(f\"  ðŸ”„ Loggeando hiperparÃ¡metros en MLflow...\")\n",
        "        mlflow.log_params({\n",
        "            \"n_channels\": config[\"N_CHANNELS\"],\n",
        "            \"seq_len\": config[\"SEQ_LEN\"],\n",
        "            \"cnn_out_channels\": str(config[\"out_channels_list\"]),\n",
        "            \"cnn_kernel_sizes\": str(config[\"kernel_sizes\"]),\n",
        "            \"cnn_pool_sizes\": str(config[\"pool_sizes\"]),\n",
        "            \"cnn_use_batchnorm\": config[\"USE_BATCHNORM\"],\n",
        "            \"cnn_activation\": config[\"CNN_ACTIVATION\"],\n",
        "            \"d_model\": config[\"D_MODEL\"],\n",
        "            \"nhead\": config[\"NHEAD\"],\n",
        "            \"num_encoder_layers\": config[\"NUM_ENCODER_LAYERS\"],\n",
        "            \"dim_feedforward\": config[\"DIM_FEEDFORWARD\"],\n",
        "            \"transformer_dropout\": config[\"TRANSFORMER_DROPOUT\"],\n",
        "            \"use_pos_encoding\": config[\"USE_POS_ENCODING\"],\n",
        "            \"fc_units\": config[\"FC_UNITS\"],\n",
        "            \"batch_size\": config[\"BATCH_SIZE\"],\n",
        "            \"learning_rate\": config[\"LEARNING_RATE\"],\n",
        "            \"num_epochs\": config[\"NUM_EPOCHS\"],\n",
        "            \"weight_decay\": config[\"WEIGHT_DECAY\"],\n",
        "            \"gradient_accumulation_steps\": config.get(\"GRADIENT_ACCUMULATION_STEPS\", 1),\n",
        "            \"warmup_steps\": config.get(\"WARMUP_STEPS\", 0),\n",
        "            \"use_scheduler\": config.get(\"USE_SCHEDULER\", False),\n",
        "            \"scheduler_patience\": config.get(\"SCHEDULER_PATIENCE\", 5),\n",
        "            \"scheduler_factor\": config.get(\"SCHEDULER_FACTOR\", 0.5),\n",
        "            \"clip_grad_norm\": config.get(\"CLIP_GRAD_NORM\", None),\n",
        "            \"cudnn_benchmark\": config.get(\"ENABLE_CUDNN_BENCHMARK\", True),\n",
        "            \"seed\": config[\"SEED\"],\n",
        "        })\n",
        "        print(f\"  âœ“ HiperparÃ¡metros loggeados\")\n",
        "        \n",
        "        # Loop de entrenamiento\n",
        "        print(f\"\\nðŸš€ Iniciando loop de entrenamiento ({config['NUM_EPOCHS']} Ã©pocas)...\\n\")\n",
        "        for epoch in range(1, config[\"NUM_EPOCHS\"] + 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"ðŸ“… Ã‰POCA {epoch}/{config['NUM_EPOCHS']}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            # Entrenar\n",
        "            print(f\"  ðŸ‹ï¸ Entrenando...\")\n",
        "            train_loss, train_acc, steps_taken = train_one_epoch(\n",
        "                model, train_loader, optimizer, criterion, device,\n",
        "                gradient_accumulation_steps=config.get(\"GRADIENT_ACCUMULATION_STEPS\", 1),\n",
        "                clip_grad_norm=clip_grad_norm,\n",
        "                warmup_scheduler=warmup_scheduler,\n",
        "                global_step=global_step,\n",
        "            )\n",
        "            global_step += steps_taken  # Actualizar contador global de pasos\n",
        "            train_losses.append(train_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            print(f\"  âœ“ Entrenamiento completado: Loss={train_loss:.4f}, Acc={train_acc:.4f} | Pasos: {global_step}\")\n",
        "            \n",
        "            # Validar\n",
        "            print(f\"  ðŸ“Š Validando...\")\n",
        "            val_loss, val_acc, y_val_true, y_val_pred = evaluate(\n",
        "                model, val_loader, criterion, device\n",
        "            )\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"  âœ“ ValidaciÃ³n completada: Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
        "            \n",
        "            # Calcular mÃ©tricas de validaciÃ³n\n",
        "            val_metrics = compute_metrics(y_val_true, y_val_pred)\n",
        "            val_f1 = val_metrics[\"f1_macro\"]\n",
        "            val_f1_scores.append(val_f1)\n",
        "            \n",
        "            # Actualizar Learning Rate Scheduler\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            learning_rates.append(current_lr)\n",
        "            \n",
        "            if scheduler is not None:\n",
        "                scheduler.step(val_f1)\n",
        "                new_lr = optimizer.param_groups[0]['lr']\n",
        "                if new_lr < current_lr:\n",
        "                    print(f\"  â¬‡ï¸ Learning Rate reducido: {current_lr:.6f} â†’ {new_lr:.6f}\")\n",
        "            \n",
        "            # Log mÃ©tricas en MLflow\n",
        "            mlflow.log_metrics({\n",
        "                \"train_loss\": train_loss,\n",
        "                \"train_accuracy\": train_acc,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "                \"val_f1_macro\": val_f1,\n",
        "                \"val_f1_normal\": val_metrics[\"f1_normal\"],\n",
        "                \"val_f1_anom\": val_metrics[\"f1_anom\"],\n",
        "                \"val_precision_macro\": val_metrics[\"precision_macro\"],\n",
        "                \"val_recall_macro\": val_metrics[\"recall_macro\"],\n",
        "                \"learning_rate\": current_lr,\n",
        "            }, step=epoch)\n",
        "            \n",
        "            # Guardar mejor modelo\n",
        "            if val_f1 > best_f1:\n",
        "                best_f1 = val_f1\n",
        "                best_model_state = model.state_dict().copy()\n",
        "            \n",
        "            # Print progreso\n",
        "            if epoch % 5 == 0 or epoch == 1:\n",
        "                print(\n",
        "                    f\"Epoch {epoch:03d}/{config['NUM_EPOCHS']} | \"\n",
        "                    f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "                    f\"Val Loss: {val_loss:.4f} | Val Acc: {val_metrics['accuracy']:.4f} | \"\n",
        "                    f\"Val F1: {val_f1:.4f} | LR: {current_lr:.6f}\"\n",
        "                )\n",
        "        \n",
        "        # Cargar mejor modelo\n",
        "        if best_model_state is not None:\n",
        "            model.load_state_dict(best_model_state)\n",
        "        \n",
        "        # Guardar curvas de entrenamiento\n",
        "        curves_path = save_training_curves(\n",
        "            train_losses, train_accuracies, val_losses, val_f1_scores, config[\"OUTPUT_DIR\"],\n",
        "            learning_rates=learning_rates if learning_rates else None,\n",
        "        )\n",
        "        mlflow.log_artifact(str(curves_path))\n",
        "        \n",
        "        # Guardar matriz de confusiÃ³n de validaciÃ³n\n",
        "        val_metrics_final = compute_metrics(y_val_true, y_val_pred)\n",
        "        cm_val_path, _ = save_confusion_matrix(\n",
        "            val_metrics_final[\"confusion_matrix\"], config[\"OUTPUT_DIR\"], \"val\"\n",
        "        )\n",
        "        mlflow.log_artifact(str(cm_val_path))\n",
        "        \n",
        "        # Guardar modelo\n",
        "        mlflow.pytorch.log_model(model, \"model\")\n",
        "        \n",
        "        print(f\"âœ“ Entrenamiento completado. Mejor F1 (macro): {best_f1:.4f}\")\n",
        "    \n",
        "    return model, train_losses, train_accuracies, val_losses, val_f1_scores, best_f1, learning_rates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Tarea Prefect: Evaluar en test\n",
        "# ========================================\n",
        "@task(name=\"evaluate_test\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_evaluate_test(\n",
        "    model: CNN1D_TransformerClassifier,\n",
        "    test_loader: DataLoader,\n",
        "    y_test: np.ndarray,\n",
        "    device: torch.device,\n",
        "    config: Dict,\n",
        "    experiment_id: str,\n",
        "):\n",
        "    \"\"\"Tarea Prefect para evaluar en test.\"\"\"\n",
        "    print(\"ðŸ“Š Evaluando en conjunto de test...\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    # Evaluar\n",
        "    test_loss, test_acc, y_test_true, y_test_pred = evaluate(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "    \n",
        "    # Calcular mÃ©tricas completas\n",
        "    test_metrics = compute_metrics(y_test_true, y_test_pred)\n",
        "    test_metrics[\"loss\"] = test_loss\n",
        "    test_metrics[\"accuracy\"] = test_acc\n",
        "    \n",
        "    # Log en MLflow\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=config[\"RUN_NAME\"]):\n",
        "        mlflow.log_metrics({\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_accuracy\": test_metrics[\"accuracy\"],\n",
        "            \"test_f1_macro\": test_metrics[\"f1_macro\"],\n",
        "            \"test_f1_normal\": test_metrics[\"f1_normal\"],\n",
        "            \"test_f1_anom\": test_metrics[\"f1_anom\"],\n",
        "            \"test_precision_macro\": test_metrics[\"precision_macro\"],\n",
        "            \"test_recall_macro\": test_metrics[\"recall_macro\"],\n",
        "            \"test_specificity\": test_metrics[\"specificity\"],\n",
        "            \"test_sensitivity\": test_metrics[\"sensitivity\"],\n",
        "        })\n",
        "        \n",
        "        # Guardar matriz de confusiÃ³n de test\n",
        "        cm_test_path, _ = save_confusion_matrix(\n",
        "            test_metrics[\"confusion_matrix\"], config[\"OUTPUT_DIR\"], \"test\"\n",
        "        )\n",
        "        mlflow.log_artifact(str(cm_test_path))\n",
        "    \n",
        "    print(\"âœ“ EvaluaciÃ³n en test completada:\")\n",
        "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision (normal): {test_metrics['precision_normal']:.4f} | Recall: {test_metrics['recall_normal']:.4f} | F1: {test_metrics['f1_normal']:.4f}\")\n",
        "    print(f\"  Precision (anÃ³malo): {test_metrics['precision_anom']:.4f} | Recall: {test_metrics['recall_anom']:.4f} | F1: {test_metrics['f1_anom']:.4f}\")\n",
        "    print(f\"  F1 Macro: {test_metrics['f1_macro']:.4f}\")\n",
        "    \n",
        "    return test_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Flujo principal de Prefect\n",
        "# ========================================\n",
        "@flow(name=\"cnn_transformer_classification_training_flow\", log_prints=True)\n",
        "def cnn_transformer_classification_training_flow(config: Dict = None):\n",
        "    \"\"\"\n",
        "    Flujo principal de Prefect que orquesta todo el proceso:\n",
        "    1. Carga y preparaciÃ³n de datos\n",
        "    2. CreaciÃ³n del modelo\n",
        "    3. Entrenamiento\n",
        "    4. EvaluaciÃ³n en test\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = CONFIG\n",
        "    \n",
        "    print(\"ðŸš€ Iniciando flujo de entrenamiento CNN1D + Transformer ClasificaciÃ³n...\")\n",
        "    print(f\"Experimento MLflow: {config['EXPERIMENT_NAME']}\")\n",
        "    \n",
        "    # Configurar MLflow\n",
        "    experiment_id = setup_mlflow(config)\n",
        "    \n",
        "    # Cargar y preparar datos\n",
        "    dataloaders = task_load_data(config)\n",
        "    train_loader, val_loader, test_loader, y_val, y_test = dataloaders\n",
        "    \n",
        "    # Crear modelo\n",
        "    print(\"ðŸ§  Creando modelo...\")\n",
        "    model = create_model(config)\n",
        "    \n",
        "    # Entrenar\n",
        "    model, train_losses, train_accs, val_losses, val_f1_scores, best_f1, learning_rates = task_train_model(\n",
        "        model, train_loader, val_loader, y_val, config, DEVICE, experiment_id\n",
        "    )\n",
        "    \n",
        "    # Evaluar en test\n",
        "    test_metrics = task_evaluate_test(\n",
        "        model, test_loader, y_test, DEVICE, config, experiment_id\n",
        "    )\n",
        "    \n",
        "    # Guardar modelo estÃ¡ndar con su nombre correspondiente\n",
        "    print(\"\\nðŸ’¾ Guardando modelo estÃ¡ndar...\")\n",
        "    print(\"=\"*60)\n",
        "    model_path, state_dict_path, metadata_path = save_model_standard(\n",
        "        model=model,\n",
        "        config=config,\n",
        "        output_dir=Path(\"./models\"),\n",
        "        run_name=config[\"RUN_NAME\"],\n",
        "        include_metadata=True\n",
        "    )\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âœ… FLUJO COMPLETADO\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Mejor F1 en validaciÃ³n: {best_f1:.4f}\")\n",
        "    print(f\"F1 en test: {test_metrics['f1_macro']:.4f}\")\n",
        "    print(f\"\\nâœ“ Modelo guardado en: ./models/{config['RUN_NAME']}.pt\")\n",
        "    print(f\"\\nRevisa MLflow para ver todos los artefactos y mÃ©tricas.\")\n",
        "    \n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"test_metrics\": test_metrics,\n",
        "        \"best_f1\": best_f1,\n",
        "        \"model_path\": model_path,\n",
        "        \"state_dict_path\": state_dict_path,\n",
        "        \"metadata_path\": metadata_path,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. ðŸš€ EjecuciÃ³n del Flujo Completo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-24 19:42:51 INFO  [prefect.flow_runs] Beginning flow run 'prompt-squid' for flow 'cnn_transformer_classification_training_flow'\n",
            "2025-11-24 19:42:52 INFO  [prefect.flow_runs] ðŸš€ Iniciando flujo de entrenamiento CNN1D + Transformer ClasificaciÃ³n...\n",
            "2025-11-24 19:42:52 INFO  [prefect.flow_runs] Experimento MLflow: ecg_cnn_transformer_supervisado\n",
            "2025-11-24 19:42:52 INFO  [prefect.flow_runs] âœ“ MLflow tracking URI: sqlite:///S:/Proyecto final/mlflow.db\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-24 19:42:52 INFO  [prefect.flow_runs] âœ“ Experimento MLflow existente: ecg_cnn_transformer_supervisado (ID: 6)\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] ðŸ“‚ Cargando datos...\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] ðŸ“‚ CARGANDO DATOS DESDE tensors_200hz\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] Directorio: S:\\Proyecto final\\data\\Datos_supervisados\\tensors_200hz\n",
            "2025-11-24 19:42:52 INFO  [prefect.task_runs] \n",
            "â³ Cargando tensors desde disco...\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs] \n",
            "âœ“ Datos cargados:\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   X_train: torch.Size([270668, 2000, 3]) | y_train: torch.Size([270668]) (normales: 135334, anÃ³malos: 135334)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   X_val:   torch.Size([58001, 2000, 3]) | y_val:   torch.Size([58001]) (normales: 29000, anÃ³malos: 29001)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   X_test:  torch.Size([58001, 2000, 3]) | y_test:  torch.Size([58001]) (normales: 29001, anÃ³malos: 29000)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs] \n",
            "âœ“ DataLoaders creados:\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   Train: 2115 batches (270668 muestras)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   Val:   454 batches (58001 muestras)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs]   Test:  454 batches (58001 muestras)\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs] âœ“ Datos cargados y preparados\n",
            "2025-11-24 19:42:58 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-24 19:42:58 INFO  [prefect.flow_runs] ðŸ§  Creando modelo...\n",
            "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_42392\\3445343300.py:106: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  self.transformer_encoder = nn.TransformerEncoder(\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs] âœ“ Modelo creado:\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   ParÃ¡metros totales: 1,683,521 (1.68M)\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   ParÃ¡metros entrenables: 1,683,521\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   CNN output shape: (batch, 128, 250)\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   Transformer input size: 256\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   Transformer encoder layers: 3\n",
            "2025-11-24 19:42:59 INFO  [prefect.flow_runs]   Attention heads: 4\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] ðŸ‹ï¸ Iniciando entrenamiento...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ“Š Verificando DataLoaders...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]     Train: 2115 batches (270668 muestras)\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]     Val: 454 batches (58001 muestras)\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]     Device: cuda\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ”„ Moviendo modelo a cuda...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   âœ“ Modelo en cuda\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ”„ Inicializando optimizador y criterio...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   âœ“ Optimizador y criterio listos\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] âœ“ Warmup Scheduler configurado: 500 pasos\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] âœ“ Learning Rate Scheduler (ReduceLROnPlateau) configurado\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] âœ“ Gradient Clipping habilitado: 1.0\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ”„ Iniciando run de MLflow...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   âœ“ Run de MLflow iniciado\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ”„ Loggeando hiperparÃ¡metros en MLflow...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   âœ“ HiperparÃ¡metros loggeados\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] \n",
            "ðŸš€ Iniciando loop de entrenamiento (50 Ã©pocas)...\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 1/50\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:42:59 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:44:26 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.4635, Acc=0.7777 | Pasos: 2115\n",
            "2025-11-24 19:44:26 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.4214, Acc=0.8040\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs] Epoch 001/50 | Train Loss: 0.4635 | Train Acc: 0.7777 | Val Loss: 0.4214 | Val Acc: 0.8040 | Val F1: 0.8039 | LR: 0.000300\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 2/50\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:44:31 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:45:57 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3937, Acc=0.8214 | Pasos: 4230\n",
            "2025-11-24 19:45:57 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:46:03 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3772, Acc=0.8319\n",
            "2025-11-24 19:46:03 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:46:03 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 3/50\n",
            "2025-11-24 19:46:03 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:46:03 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:47:29 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3697, Acc=0.8350 | Pasos: 6345\n",
            "2025-11-24 19:47:29 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:47:35 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3772, Acc=0.8344\n",
            "2025-11-24 19:47:35 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:47:35 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 4/50\n",
            "2025-11-24 19:47:35 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:47:35 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:49:01 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3589, Acc=0.8400 | Pasos: 8460\n",
            "2025-11-24 19:49:01 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:49:06 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3502, Acc=0.8464\n",
            "2025-11-24 19:49:06 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:49:06 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 5/50\n",
            "2025-11-24 19:49:06 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:49:06 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:50:33 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3516, Acc=0.8447 | Pasos: 10575\n",
            "2025-11-24 19:50:33 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3583, Acc=0.8452\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs] Epoch 005/50 | Train Loss: 0.3516 | Train Acc: 0.8447 | Val Loss: 0.3583 | Val Acc: 0.8452 | Val F1: 0.8450 | LR: 0.000300\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 6/50\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:50:38 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:52:04 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3461, Acc=0.8472 | Pasos: 12690\n",
            "2025-11-24 19:52:04 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:52:10 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3460, Acc=0.8460\n",
            "2025-11-24 19:52:10 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:52:10 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 7/50\n",
            "2025-11-24 19:52:10 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:52:10 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:53:36 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3409, Acc=0.8490 | Pasos: 14805\n",
            "2025-11-24 19:53:36 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:53:41 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3738, Acc=0.8373\n",
            "2025-11-24 19:53:41 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:53:41 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 8/50\n",
            "2025-11-24 19:53:41 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:53:41 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:55:07 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3374, Acc=0.8516 | Pasos: 16920\n",
            "2025-11-24 19:55:07 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:55:13 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3322, Acc=0.8536\n",
            "2025-11-24 19:55:13 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:55:13 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 9/50\n",
            "2025-11-24 19:55:13 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:55:13 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:56:39 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3331, Acc=0.8533 | Pasos: 19035\n",
            "2025-11-24 19:56:39 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:56:44 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3573, Acc=0.8414\n",
            "2025-11-24 19:56:44 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:56:44 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 10/50\n",
            "2025-11-24 19:56:44 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:56:44 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:58:10 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3302, Acc=0.8553 | Pasos: 21150\n",
            "2025-11-24 19:58:10 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3381, Acc=0.8520\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs] Epoch 010/50 | Train Loss: 0.3302 | Train Acc: 0.8553 | Val Loss: 0.3381 | Val Acc: 0.8520 | Val F1: 0.8516 | LR: 0.000300\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 11/50\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:58:16 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 19:59:42 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3280, Acc=0.8561 | Pasos: 23265\n",
            "2025-11-24 19:59:42 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 19:59:47 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3368, Acc=0.8522\n",
            "2025-11-24 19:59:47 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 19:59:47 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 12/50\n",
            "2025-11-24 19:59:47 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 19:59:47 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:01:13 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3254, Acc=0.8573 | Pasos: 25380\n",
            "2025-11-24 20:01:13 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:01:19 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3294, Acc=0.8547\n",
            "2025-11-24 20:01:19 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:01:19 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 13/50\n",
            "2025-11-24 20:01:19 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:01:19 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:02:45 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3240, Acc=0.8583 | Pasos: 27495\n",
            "2025-11-24 20:02:45 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:02:50 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3375, Acc=0.8535\n",
            "2025-11-24 20:02:50 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:02:50 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 14/50\n",
            "2025-11-24 20:02:50 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:02:50 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:04:17 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3213, Acc=0.8586 | Pasos: 29610\n",
            "2025-11-24 20:04:17 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:04:22 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3253, Acc=0.8573\n",
            "2025-11-24 20:04:22 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:04:22 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 15/50\n",
            "2025-11-24 20:04:22 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:04:22 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:05:48 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3190, Acc=0.8602 | Pasos: 31725\n",
            "2025-11-24 20:05:48 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3393, Acc=0.8507\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs] Epoch 015/50 | Train Loss: 0.3190 | Train Acc: 0.8602 | Val Loss: 0.3393 | Val Acc: 0.8507 | Val F1: 0.8499 | LR: 0.000300\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 16/50\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:05:53 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:07:20 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3155, Acc=0.8618 | Pasos: 33840\n",
            "2025-11-24 20:07:20 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:07:25 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3331, Acc=0.8544\n",
            "2025-11-24 20:07:25 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:07:25 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 17/50\n",
            "2025-11-24 20:07:25 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:07:25 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:08:51 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3141, Acc=0.8624 | Pasos: 35955\n",
            "2025-11-24 20:08:51 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:08:56 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3284, Acc=0.8581\n",
            "2025-11-24 20:08:56 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:08:56 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 18/50\n",
            "2025-11-24 20:08:56 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:08:56 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:10:23 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3131, Acc=0.8631 | Pasos: 38070\n",
            "2025-11-24 20:10:23 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:10:28 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3260, Acc=0.8574\n",
            "2025-11-24 20:10:28 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:10:28 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 19/50\n",
            "2025-11-24 20:10:28 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:10:28 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:11:54 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3099, Acc=0.8644 | Pasos: 40185\n",
            "2025-11-24 20:11:54 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:11:59 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3289, Acc=0.8564\n",
            "2025-11-24 20:11:59 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:11:59 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 20/50\n",
            "2025-11-24 20:11:59 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:11:59 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:13:26 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3092, Acc=0.8656 | Pasos: 42300\n",
            "2025-11-24 20:13:26 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3321, Acc=0.8551\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs] Epoch 020/50 | Train Loss: 0.3092 | Train Acc: 0.8656 | Val Loss: 0.3321 | Val Acc: 0.8551 | Val F1: 0.8547 | LR: 0.000300\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 21/50\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:13:31 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:14:57 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3069, Acc=0.8664 | Pasos: 44415\n",
            "2025-11-24 20:14:57 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:15:03 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3227, Acc=0.8592\n",
            "2025-11-24 20:15:03 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:15:03 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 22/50\n",
            "2025-11-24 20:15:03 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:15:03 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:16:29 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3057, Acc=0.8671 | Pasos: 46530\n",
            "2025-11-24 20:16:29 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:16:34 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3271, Acc=0.8540\n",
            "2025-11-24 20:16:34 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:16:34 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 23/50\n",
            "2025-11-24 20:16:34 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:16:34 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:18:00 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3039, Acc=0.8679 | Pasos: 48645\n",
            "2025-11-24 20:18:00 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:18:06 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3223, Acc=0.8583\n",
            "2025-11-24 20:18:06 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:18:06 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 24/50\n",
            "2025-11-24 20:18:06 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:18:06 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:19:32 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3021, Acc=0.8685 | Pasos: 50760\n",
            "2025-11-24 20:19:32 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:19:37 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3295, Acc=0.8571\n",
            "2025-11-24 20:19:37 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:19:37 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 25/50\n",
            "2025-11-24 20:19:37 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:19:37 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:21:03 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.3000, Acc=0.8692 | Pasos: 52875\n",
            "2025-11-24 20:21:03 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3224, Acc=0.8615\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs] Epoch 025/50 | Train Loss: 0.3000 | Train Acc: 0.8692 | Val Loss: 0.3224 | Val Acc: 0.8615 | Val F1: 0.8613 | LR: 0.000300\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 26/50\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:21:09 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:22:35 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2994, Acc=0.8701 | Pasos: 54990\n",
            "2025-11-24 20:22:35 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:22:40 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3270, Acc=0.8562\n",
            "2025-11-24 20:22:40 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:22:40 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 27/50\n",
            "2025-11-24 20:22:40 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:22:40 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:24:07 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2972, Acc=0.8713 | Pasos: 57105\n",
            "2025-11-24 20:24:07 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:24:12 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3197, Acc=0.8580\n",
            "2025-11-24 20:24:12 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:24:12 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 28/50\n",
            "2025-11-24 20:24:12 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:24:12 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:25:38 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2958, Acc=0.8713 | Pasos: 59220\n",
            "2025-11-24 20:25:38 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:25:43 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3282, Acc=0.8617\n",
            "2025-11-24 20:25:43 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:25:43 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 29/50\n",
            "2025-11-24 20:25:43 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:25:43 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:27:10 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2942, Acc=0.8723 | Pasos: 61335\n",
            "2025-11-24 20:27:10 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:27:15 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3338, Acc=0.8570\n",
            "2025-11-24 20:27:15 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:27:15 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 30/50\n",
            "2025-11-24 20:27:15 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:27:15 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:28:41 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2928, Acc=0.8729 | Pasos: 63450\n",
            "2025-11-24 20:28:41 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3292, Acc=0.8590\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs] Epoch 030/50 | Train Loss: 0.2928 | Train Acc: 0.8729 | Val Loss: 0.3292 | Val Acc: 0.8590 | Val F1: 0.8586 | LR: 0.000300\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 31/50\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:28:46 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:30:13 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2917, Acc=0.8736 | Pasos: 65565\n",
            "2025-11-24 20:30:13 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:30:18 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3350, Acc=0.8565\n",
            "2025-11-24 20:30:18 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:30:18 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 32/50\n",
            "2025-11-24 20:30:18 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:30:18 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:31:44 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2899, Acc=0.8744 | Pasos: 67680\n",
            "2025-11-24 20:31:44 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:31:50 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3277, Acc=0.8563\n",
            "2025-11-24 20:31:50 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:31:50 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 33/50\n",
            "2025-11-24 20:31:50 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:31:50 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:33:16 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2877, Acc=0.8757 | Pasos: 69795\n",
            "2025-11-24 20:33:16 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:33:21 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3277, Acc=0.8605\n",
            "2025-11-24 20:33:21 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:33:21 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 34/50\n",
            "2025-11-24 20:33:21 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:33:21 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:34:47 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2861, Acc=0.8763 | Pasos: 71910\n",
            "2025-11-24 20:34:47 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3250, Acc=0.8605\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs]   â¬‡ï¸ Learning Rate reducido: 0.000300 â†’ 0.000150\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 35/50\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:34:53 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:36:19 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2861, Acc=0.8764 | Pasos: 74025\n",
            "2025-11-24 20:36:19 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3282, Acc=0.8594\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs] Epoch 035/50 | Train Loss: 0.2861 | Train Acc: 0.8764 | Val Loss: 0.3282 | Val Acc: 0.8594 | Val F1: 0.8592 | LR: 0.000300\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 36/50\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:36:24 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:37:51 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2846, Acc=0.8770 | Pasos: 76140\n",
            "2025-11-24 20:37:51 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:37:56 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3308, Acc=0.8584\n",
            "2025-11-24 20:37:56 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:37:56 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 37/50\n",
            "2025-11-24 20:37:56 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:37:56 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:39:22 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2829, Acc=0.8780 | Pasos: 78255\n",
            "2025-11-24 20:39:22 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:39:27 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3213, Acc=0.8603\n",
            "2025-11-24 20:39:27 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:39:27 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 38/50\n",
            "2025-11-24 20:39:27 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:39:27 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:40:54 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2818, Acc=0.8789 | Pasos: 80370\n",
            "2025-11-24 20:40:54 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:40:59 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3304, Acc=0.8555\n",
            "2025-11-24 20:40:59 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:40:59 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 39/50\n",
            "2025-11-24 20:40:59 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:40:59 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:42:25 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2792, Acc=0.8798 | Pasos: 82485\n",
            "2025-11-24 20:42:25 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:42:30 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3256, Acc=0.8599\n",
            "2025-11-24 20:42:30 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:42:30 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 40/50\n",
            "2025-11-24 20:42:30 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:42:30 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:43:57 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2786, Acc=0.8797 | Pasos: 84600\n",
            "2025-11-24 20:43:57 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3265, Acc=0.8602\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs]   â¬‡ï¸ Learning Rate reducido: 0.000300 â†’ 0.000150\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs] Epoch 040/50 | Train Loss: 0.2786 | Train Acc: 0.8797 | Val Loss: 0.3265 | Val Acc: 0.8602 | Val F1: 0.8597 | LR: 0.000300\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 41/50\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:44:02 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:45:28 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2770, Acc=0.8808 | Pasos: 86715\n",
            "2025-11-24 20:45:28 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:45:33 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3407, Acc=0.8552\n",
            "2025-11-24 20:45:33 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:45:33 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 42/50\n",
            "2025-11-24 20:45:33 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:45:33 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:47:00 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2761, Acc=0.8812 | Pasos: 88830\n",
            "2025-11-24 20:47:00 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:47:05 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3291, Acc=0.8596\n",
            "2025-11-24 20:47:05 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:47:05 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 43/50\n",
            "2025-11-24 20:47:05 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:47:05 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:48:31 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2751, Acc=0.8814 | Pasos: 90945\n",
            "2025-11-24 20:48:31 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:48:36 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3285, Acc=0.8581\n",
            "2025-11-24 20:48:36 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:48:36 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 44/50\n",
            "2025-11-24 20:48:36 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:48:36 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:50:03 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2728, Acc=0.8832 | Pasos: 93060\n",
            "2025-11-24 20:50:03 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:50:08 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3318, Acc=0.8591\n",
            "2025-11-24 20:50:08 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:50:08 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 45/50\n",
            "2025-11-24 20:50:08 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:50:08 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:51:34 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2711, Acc=0.8835 | Pasos: 95175\n",
            "2025-11-24 20:51:34 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3242, Acc=0.8583\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs] Epoch 045/50 | Train Loss: 0.2711 | Train Acc: 0.8835 | Val Loss: 0.3242 | Val Acc: 0.8583 | Val F1: 0.8582 | LR: 0.000300\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 46/50\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:51:39 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:53:06 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2706, Acc=0.8839 | Pasos: 97290\n",
            "2025-11-24 20:53:06 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3340, Acc=0.8569\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs]   â¬‡ï¸ Learning Rate reducido: 0.000300 â†’ 0.000150\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 47/50\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:53:11 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:54:37 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2680, Acc=0.8847 | Pasos: 99405\n",
            "2025-11-24 20:54:37 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:54:43 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3334, Acc=0.8579\n",
            "2025-11-24 20:54:43 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:54:43 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 48/50\n",
            "2025-11-24 20:54:43 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:54:43 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:56:09 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2669, Acc=0.8860 | Pasos: 101520\n",
            "2025-11-24 20:56:09 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:56:14 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3312, Acc=0.8590\n",
            "2025-11-24 20:56:14 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:56:14 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 49/50\n",
            "2025-11-24 20:56:14 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:56:14 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:57:40 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2658, Acc=0.8859 | Pasos: 103635\n",
            "2025-11-24 20:57:40 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:57:46 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3418, Acc=0.8592\n",
            "2025-11-24 20:57:46 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-24 20:57:46 INFO  [prefect.task_runs] ðŸ“… Ã‰POCA 50/50\n",
            "2025-11-24 20:57:46 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-24 20:57:46 INFO  [prefect.task_runs]   ðŸ‹ï¸ Entrenando...\n",
            "2025-11-24 20:59:12 INFO  [prefect.task_runs]   âœ“ Entrenamiento completado: Loss=0.2654, Acc=0.8868 | Pasos: 105750\n",
            "2025-11-24 20:59:12 INFO  [prefect.task_runs]   ðŸ“Š Validando...\n",
            "2025-11-24 20:59:17 INFO  [prefect.task_runs]   âœ“ ValidaciÃ³n completada: Loss=0.3431, Acc=0.8595\n",
            "2025-11-24 20:59:17 INFO  [prefect.task_runs] Epoch 050/50 | Train Loss: 0.2654 | Train Acc: 0.8868 | Val Loss: 0.3431 | Val Acc: 0.8595 | Val F1: 0.8592 | LR: 0.000300\n",
            "2025/11/24 20:59:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/24 20:59:18 WARNING mlflow.utils.requirements_utils: Found torch version (2.10.0.dev20251121+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.10.0.dev20251121' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/11/24 20:59:26 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\tomas\\AppData\\Local\\Temp\\tmpo3epi3e1\\model\\data, flavor: pytorch). Fall back to return ['torch==2.10.0.dev20251121', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
            "2025/11/24 20:59:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2025-11-24 20:59:26 INFO  [prefect.task_runs] âœ“ Entrenamiento completado. Mejor F1 (macro): 0.8615\n",
            "2025-11-24 20:59:26 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-24 20:59:26 INFO  [prefect.task_runs] ðŸ“Š Evaluando en conjunto de test...\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs] âœ“ EvaluaciÃ³n en test completada:\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs]   Accuracy: 0.8595\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs]   Precision (normal): 0.8320 | Recall: 0.9010 | F1: 0.8651\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs]   Precision (anÃ³malo): 0.8920 | Recall: 0.8180 | F1: 0.8534\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs]   F1 Macro: 0.8593\n",
            "2025-11-24 20:59:32 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] \n",
            "ðŸ’¾ Guardando modelo estÃ¡ndar...\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] ============================================================\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] âœ“ Modelo completo guardado: models\\cnn_transformer_ecg_v1.pt\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] âœ“ State dict guardado: models\\cnn_transformer_ecg_v1_state_dict.pt\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] âœ“ Metadatos guardados: models\\cnn_transformer_ecg_v1_metadata.json\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] ============================================================\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] \n",
            "============================================================\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] âœ… FLUJO COMPLETADO\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] ============================================================\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] Mejor F1 en validaciÃ³n: 0.8615\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] F1 en test: 0.8593\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] \n",
            "âœ“ Modelo guardado en: ./models/cnn_transformer_ecg_v1.pt\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] \n",
            "Revisa MLflow para ver todos los artefactos y mÃ©tricas.\n",
            "2025-11-24 20:59:32 INFO  [prefect.flow_runs] Finished in state Completed()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "âœ… PROCESO FINALIZADO EXITOSAMENTE\n",
            "============================================================\n",
            "âœ“ Modelo entrenado y guardado\n",
            "âœ“ MÃ©tricas registradas en MLflow\n",
            "âœ“ Artefactos guardados en: outputs\n",
            "\n",
            "ðŸ“Š Revisa MLflow para ver todas las mÃ©tricas y grÃ¡ficos del entrenamiento.\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Ejecutar el flujo completo\n",
        "# ========================================\n",
        "# NOTA: En Jupyter Notebook, puedes ejecutar esta celda directamente\n",
        "# El flujo completo incluye: carga de datos, creaciÃ³n del modelo, entrenamiento y evaluaciÃ³n\n",
        "\n",
        "results = cnn_transformer_classification_training_flow(CONFIG)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… PROCESO FINALIZADO EXITOSAMENTE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ“ Modelo entrenado y guardado\")\n",
        "print(f\"âœ“ MÃ©tricas registradas en MLflow\")\n",
        "print(f\"âœ“ Artefactos guardados en: {CONFIG['OUTPUT_DIR']}\")\n",
        "print(\"\\nðŸ“Š Revisa MLflow para ver todas las mÃ©tricas y grÃ¡ficos del entrenamiento.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 9. ðŸ’¾ Guardado de Modelo\n",
        "\n",
        "DespuÃ©s de entrenar, puedes guardar el modelo en diferentes formatos:\n",
        "1. **Modelo estÃ¡ndar** - Para uso local o despliegue personalizado\n",
        "2. **Modelo para AWS SageMaker** - Formato listo para desplegar en SageMaker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# FunciÃ³n para guardar modelo estÃ¡ndar\n",
        "# ========================================\n",
        "def save_model_standard(\n",
        "    model: CNN1D_TransformerClassifier,\n",
        "    config: Dict,\n",
        "    output_dir: Path,\n",
        "    run_name: str = None,\n",
        "    include_metadata: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Guarda el modelo completo y metadatos en formato estÃ¡ndar.\n",
        "    \n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        config: Diccionario de configuraciÃ³n\n",
        "        output_dir: Directorio donde guardar\n",
        "        run_name: Nombre del run (para el archivo)\n",
        "        include_metadata: Si True, guarda tambiÃ©n config.json\n",
        "        \n",
        "    Returns:\n",
        "        Tuple con (model_path, state_dict_path, metadata_path)\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    \n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    if run_name is None:\n",
        "        run_name = config.get(\"RUN_NAME\", \"cnn_transformer_model\")\n",
        "    \n",
        "    # 1. Guardar modelo completo (.pt) con state_dict y config\n",
        "    model_path = output_dir / f\"{run_name}.pt\"\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'model_config': {\n",
        "            'n_channels': config['N_CHANNELS'],\n",
        "            'seq_len': config['SEQ_LEN'],\n",
        "            'out_channels_list': config['out_channels_list'],\n",
        "            'kernel_sizes': config['kernel_sizes'],\n",
        "            'pool_sizes': config['pool_sizes'],\n",
        "            'use_batchnorm': config['USE_BATCHNORM'],\n",
        "            'cnn_activation': config['CNN_ACTIVATION'],\n",
        "            'd_model': config['D_MODEL'],\n",
        "            'nhead': config['NHEAD'],\n",
        "            'num_encoder_layers': config['NUM_ENCODER_LAYERS'],\n",
        "            'dim_feedforward': config['DIM_FEEDFORWARD'],\n",
        "            'transformer_dropout': config['TRANSFORMER_DROPOUT'],\n",
        "            'use_pos_encoding': config['USE_POS_ENCODING'],\n",
        "            'fc_units': config['FC_UNITS'],\n",
        "        },\n",
        "        'training_config': {\n",
        "            'batch_size': config['BATCH_SIZE'],\n",
        "            'learning_rate': config['LEARNING_RATE'],\n",
        "            'num_epochs': config['NUM_EPOCHS'],\n",
        "            'weight_decay': config['WEIGHT_DECAY'],\n",
        "        }\n",
        "    }, model_path)\n",
        "    print(f\"âœ“ Modelo completo guardado: {model_path}\")\n",
        "    \n",
        "    # 2. Guardar solo el state dict (mÃ¡s liviano)\n",
        "    state_dict_path = output_dir / f\"{run_name}_state_dict.pt\"\n",
        "    torch.save(model.state_dict(), state_dict_path)\n",
        "    print(f\"âœ“ State dict guardado: {state_dict_path}\")\n",
        "    \n",
        "    # 3. Guardar metadatos como JSON (opcional)\n",
        "    metadata_path = None\n",
        "    if include_metadata:\n",
        "        metadata = {\n",
        "            'model_type': 'CNN1D_Transformer_Classifier',\n",
        "            'run_name': run_name,\n",
        "            'experiment_name': config.get('EXPERIMENT_NAME', ''),\n",
        "            'date': str(datetime.now()),\n",
        "            'model_config': {\n",
        "                'n_channels': config['N_CHANNELS'],\n",
        "                'seq_len': config['SEQ_LEN'],\n",
        "                'out_channels_list': config['out_channels_list'],\n",
        "                'kernel_sizes': config['kernel_sizes'],\n",
        "                'pool_sizes': config['pool_sizes'],\n",
        "                'use_batchnorm': config['USE_BATCHNORM'],\n",
        "                'cnn_activation': config['CNN_ACTIVATION'],\n",
        "                'd_model': config['D_MODEL'],\n",
        "                'nhead': config['NHEAD'],\n",
        "                'num_encoder_layers': config['NUM_ENCODER_LAYERS'],\n",
        "                'dim_feedforward': config['DIM_FEEDFORWARD'],\n",
        "                'transformer_dropout': config['TRANSFORMER_DROPOUT'],\n",
        "                'use_pos_encoding': config['USE_POS_ENCODING'],\n",
        "                'fc_units': config['FC_UNITS'],\n",
        "            },\n",
        "            'training_config': {\n",
        "                'batch_size': config['BATCH_SIZE'],\n",
        "                'learning_rate': config['LEARNING_RATE'],\n",
        "                'num_epochs': config['NUM_EPOCHS'],\n",
        "            }\n",
        "        }\n",
        "        metadata_path = output_dir / f\"{run_name}_metadata.json\"\n",
        "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"âœ“ Metadatos guardados: {metadata_path}\")\n",
        "    \n",
        "    return model_path, state_dict_path, metadata_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## âœ… Resumen del Notebook\n",
        "\n",
        "Este notebook implementa un **CNN1D + Transformer Encoder** para clasificaciÃ³n binaria supervisada de seÃ±ales ECG.\n",
        "\n",
        "**CaracterÃ­sticas principales:**\n",
        "- âœ… Arquitectura hÃ­brida: CNN1D para caracterÃ­sticas locales + Transformer Encoder para dependencias temporales\n",
        "- âœ… CodificaciÃ³n posicional senoidal\n",
        "- âœ… Entrenamiento supervisado con etiquetas (0=normal, 1=anÃ³malo)\n",
        "- âœ… IntegraciÃ³n completa con MLflow para tracking de experimentos\n",
        "- âœ… OrquestaciÃ³n con Prefect 2.x\n",
        "- âœ… Soporte para GPU (CUDA)\n",
        "\n",
        "**Instrucciones de uso:**\n",
        "1. Ejecuta la celda de **Setup CUDA** primero\n",
        "2. Configura los parÃ¡metros en la secciÃ³n de **CONFIGURACIÃ“N GENERAL**\n",
        "3. Ajusta la ruta `DATA_DIR` a tu carpeta de datos (`Datos_supervisados/tensors_200hz`)\n",
        "4. Ejecuta todas las celdas en orden\n",
        "5. El modelo entrenado se guardarÃ¡ automÃ¡ticamente y se registrarÃ¡ en MLflow\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
