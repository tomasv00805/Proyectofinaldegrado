{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü´Ä 1D CNN Autoencoder (PTB-XL 500 Hz II/V1/V5) + MLflow + Prefect\n",
        "\n",
        "Este notebook entrena y eval√∫a un **Autoencoder 1D CNN** sobre las derivaciones **II, V1 y V5** de PTB‚ÄëXL (500 Hz), con:\n",
        "- **MLflow** para registrar *experimentos*, *par√°metros*, *m√©tricas* y *artefactos*.\n",
        "- **Prefect** para orquestar el *pipeline* (tareas / procesos).\n",
        "- M√©tricas de reconstrucci√≥n: **EMA (MAE)**, **EMC (MSE)**, **RMSE** y **R¬≤**.\n",
        "- Matriz de confusi√≥n sobre detecci√≥n por **umbral de error de reconstrucci√≥n** (*an√≥malo si error > umbral*), con **TP/FP/TN/FN**.\n",
        "\n",
        "> **Nota:** Ajusta los par√°metros en la secci√≥n **Config**. Concretamente: rutas de datos, *batch size*, *learning rate*, *√©pocas*, *umbral*, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß∞ Celda 0 ‚Äî Dependencias (instalaci√≥n r√°pida)\n",
        "\n",
        "- Instala **mlflow** y **prefect** si no estuvieran presentes.\n",
        "- Tambi√©n instala `scikit-learn` (para m√©tricas) y `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel Python: c:\\Python311\\python.exe\n",
            "DLL dirs a√±adidos: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin; C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp; c:\\Python311\\Lib\\site-packages\\torch\\lib\n",
            "‚úî mlflow ya instalado\n",
            "‚è≥ Instalando prefect>=3 ...\n",
            "‚úî matplotlib ya instalado\n",
            "‚è≥ Instalando scikit-learn ...\n",
            "‚úî pandas ya instalado\n",
            "‚úî numpy ya instalado\n",
            "‚ö†Ô∏è No se pudo inicializar PyTorch (DLL error).\n",
            "   Rutas DLL a√±adidas en esta sesi√≥n:\n",
            "    - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\n",
            "    - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp\n",
            "    - c:\\Python311\\Lib\\site-packages\\torch\\lib\n",
            "   A√±ad√≠ rutas CUDA conocidas via os.add_dll_directory, pero si persiste:\n",
            "   1) Revisa que CUDA 12.8 est√© instalado en 'C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.8'.\n",
            "   2) Aseg√∫rate de tener el Microsoft Visual C++ 2022 Redistributable (x64) instalado.\n",
            "   3) Reinicia el kernel tras instalar/ajustar drivers.\n",
            "   Error original: [WinError 1114] Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL). Error loading \"c:\\Python311\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.\n",
            "\n",
            "Listo. Si te pide reiniciar el kernel, hazlo y contin√∫a.\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# üß∞ CELDA 0 ‚Äî INSTALACIONES\n",
        "# ========================================\n",
        "# Ejecuta una sola vez (o cuando falte algo). Si ya lo tienes, puedes omitirla.\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(f\"Kernel Python: {sys.executable}\")\n",
        "\n",
        "_added_dll_dirs: list[str] = []\n",
        "\n",
        "if hasattr(os, \"add_dll_directory\"):\n",
        "    _cuda_env_keys = [\n",
        "        \"CUDA_PATH\",\n",
        "        \"CUDA_PATH_V12_8\",\n",
        "        \"CUDA_PATH_V12_9\",\n",
        "        \"CUDA_PATH_V13_0\",\n",
        "    ]\n",
        "    dll_candidates: list[str] = []\n",
        "    for key in _cuda_env_keys:\n",
        "        base = os.environ.get(key)\n",
        "        if base:\n",
        "            dll_candidates.extend([\n",
        "                os.path.join(base, \"bin\"),\n",
        "                os.path.join(base, \"libnvvp\"),\n",
        "            ])\n",
        "    cudnn_root = os.environ.get(\"CUDNN_PATH\") or os.environ.get(\"CUDNN_ROOT\")\n",
        "    if cudnn_root:\n",
        "        dll_candidates.append(os.path.join(cudnn_root, \"bin\"))\n",
        "    # Algunas instalaciones dejan CUDA en el directorio est√°ndar aunque la variable no exista\n",
        "    default_cuda_root = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\"\n",
        "    default_cuda = os.path.join(default_cuda_root, \"v12.8\")\n",
        "    if os.path.isdir(default_cuda_root) and not os.path.isdir(default_cuda):\n",
        "        # si hay otra versi√≥n (por ejemplo v12.9), la a√±adimos tambi√©n\n",
        "        for entry in sorted(os.listdir(default_cuda_root)):\n",
        "            candidate = os.path.join(default_cuda_root, entry)\n",
        "            if os.path.isdir(candidate):\n",
        "                dll_candidates.extend([\n",
        "                    os.path.join(candidate, \"bin\"),\n",
        "                    os.path.join(candidate, \"libnvvp\"),\n",
        "                ])\n",
        "    if os.path.isdir(default_cuda):\n",
        "        dll_candidates.extend([\n",
        "            os.path.join(default_cuda, \"bin\"),\n",
        "            os.path.join(default_cuda, \"libnvvp\"),\n",
        "        ])\n",
        "\n",
        "    # cuDNN en rutas t√≠picas\n",
        "    cudnn_search_roots = [\n",
        "        r\"C:\\Program Files\\NVIDIA\\CUDNN\",\n",
        "        r\"C:\\Program Files\\NVIDIA\\CUDNN\\v9.1\",\n",
        "        r\"C:\\tools\\cuda\",\n",
        "    ]\n",
        "    for root in cudnn_search_roots:\n",
        "        if os.path.isdir(root):\n",
        "            for entry in os.listdir(root):\n",
        "                candidate = os.path.join(root, entry, \"bin\") if not entry.lower().endswith(\"bin\") else os.path.join(root, entry)\n",
        "                if os.path.isdir(candidate):\n",
        "                    dll_candidates.append(candidate)\n",
        "            # si el propio root tiene bin directo\n",
        "            bin_dir = os.path.join(root, \"bin\")\n",
        "            if os.path.isdir(bin_dir):\n",
        "                dll_candidates.append(bin_dir)\n",
        "\n",
        "    # A√±adimos expl√≠citamente la carpeta de libs de PyTorch\n",
        "    torch_lib_dir = os.path.join(os.path.dirname(sys.executable), \"Lib\", \"site-packages\", \"torch\", \"lib\")\n",
        "    dll_candidates.append(torch_lib_dir)\n",
        "\n",
        "    unique_candidates = []\n",
        "    seen = set()\n",
        "    for path in dll_candidates:\n",
        "        if path and path not in seen:\n",
        "            unique_candidates.append(path)\n",
        "            seen.add(path)\n",
        "\n",
        "    for path in unique_candidates:\n",
        "        if os.path.isdir(path):\n",
        "            try:\n",
        "                os.add_dll_directory(path)\n",
        "                _added_dll_dirs.append(path)\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "    if _added_dll_dirs:\n",
        "        os.environ[\"PATH\"] = os.pathsep.join(_added_dll_dirs + [os.environ.get(\"PATH\", \"\")])\n",
        "        print(\"DLL dirs a√±adidos:\", \"; \".join(_added_dll_dirs))\n",
        "\n",
        "\n",
        "def pip_install(pkg: str) -> None:\n",
        "    try:\n",
        "        __import__(pkg.split(\"==\")[0].split(\"[\")[0].replace(\"-\", \"_\"))\n",
        "        print(f\"‚úî {pkg} ya instalado\")\n",
        "    except Exception:\n",
        "        print(f\"‚è≥ Instalando {pkg} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
        "\n",
        "\n",
        "BASE_PACKAGES = [\n",
        "    \"mlflow\",\n",
        "    \"prefect>=3\",\n",
        "    \"matplotlib\",\n",
        "    \"scikit-learn\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "]\n",
        "\n",
        "for pkg in BASE_PACKAGES:\n",
        "    pip_install(pkg)\n",
        "\n",
        "\n",
        "def check_torch_build() -> None:\n",
        "    try:\n",
        "        import torch\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è PyTorch no est√° instalado.\")\n",
        "        print(\"   Para RTX 5080 instala el nightly cu128:\")\n",
        "        print(\"   pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\")\n",
        "        return\n",
        "    except OSError as err:\n",
        "        print(\"‚ö†Ô∏è No se pudo inicializar PyTorch (DLL error).\")\n",
        "        if _added_dll_dirs:\n",
        "            print(\"   Rutas DLL a√±adidas en esta sesi√≥n:\")\n",
        "            for p in _added_dll_dirs:\n",
        "                print(\"    -\", p)\n",
        "        print(\"   A√±ad√≠ rutas CUDA conocidas via os.add_dll_directory, pero si persiste:\")\n",
        "        print(\"   1) Revisa que CUDA 12.8 est√© instalado en 'C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.8'.\")\n",
        "        print(\"   2) Aseg√∫rate de tener el Microsoft Visual C++ 2022 Redistributable (x64) instalado.\")\n",
        "        print(\"   3) Reinicia el kernel tras instalar/ajustar drivers.\")\n",
        "        print(\"   Error original:\", err)\n",
        "        return\n",
        "\n",
        "    version = getattr(torch, \"__version__\", \"desconocida\")\n",
        "    cuda_tag = getattr(getattr(torch, \"version\", object()), \"cuda\", \"desconocida\")\n",
        "    print(f\"torch={version} | torch.version.cuda={cuda_tag}\")\n",
        "\n",
        "    if \"cu128\" not in version and not str(cuda_tag).startswith(\"12.8\"):\n",
        "        print(\"‚ö†Ô∏è Esta build no es CUDA 12.8 nightly. Para la RTX 5080 usa el comando:\")\n",
        "        print(\"   pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\")\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"‚ö†Ô∏è torch.cuda.is_available() -> False. Revisa drivers / reinicia kernel tras instalar el nightly cu128.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        sm = f\"sm_{props.major}{props.minor}\"\n",
        "        print(f\"GPU detectada: {props.name} ({sm})\")\n",
        "        if props.major < 12:\n",
        "            print(\"‚ö†Ô∏è La GPU detectada no es Blackwell (sm_120). Ajusta TORCH_CUDA_ARCH_LIST seg√∫n tu hardware.\")\n",
        "    except Exception as err:\n",
        "        print(\"‚ö†Ô∏è Error al consultar la GPU:\", err)\n",
        "        print(\"   Tras reinstalar PyTorch nightly, reinicia el kernel del notebook.\")\n",
        "\n",
        "\n",
        "check_torch_build()\n",
        "print(\"\\nListo. Si te pide reiniciar el kernel, hazlo y contin√∫a.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Celda 1 ‚Äî Imports y **Config** (ajusta aqu√≠)\n",
        "\n",
        "- Ajusta `OUTPUT_ROOT` para apuntar a la carpeta creada en la extracci√≥n (**X_norm_mm.dat**, etc.).  \n",
        "- Ajusta **hiperpar√°metros de entrenamiento** (`EPOCHS`, `BATCH_SIZE`, `LR`, etc.)  \n",
        "- Ajusta **arquitectura** del autoencoder en `MODEL_CFG` (n¬∫ filtros, *kernel sizes*, *act.*).\n",
        "- Ajusta **MLflow** (`MLFLOW_TRACKING_URI`, `EXPERIMENT_NAME`). Por defecto usa carpeta local `./mlruns`.\n",
        "- Define la **estrategia de umbral** para detecci√≥n (por percentil o Œº+K¬∑œÉ)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 1114] Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL). Error loading \"c:\\Python311\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple, Dict\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnn\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\torch\\__init__.py:282\u001b[39m\n\u001b[32m    278\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    280\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\torch\\__init__.py:265\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    261\u001b[39m     err = ctypes.WinError(last_error)\n\u001b[32m    262\u001b[39m     err.strerror += (\n\u001b[32m    263\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    264\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    267\u001b[39m     is_loaded = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mOSError\u001b[39m: [WinError 1114] Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL). Error loading \"c:\\Python311\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# ‚öôÔ∏è CELDA 1 ‚Äî IMPORTS + CONFIGURACI√ìN\n",
        "# ========================================\n",
        "\n",
        "from pathlib import Path\n",
        "import os, json, math, time, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import mlflow\n",
        "from mlflow import pytorch as mlflow_pytorch\n",
        "\n",
        "from prefect import task, flow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, classification_report\n",
        "\n",
        "# ---------- RUTAS DE DATOS ----------\n",
        "OUTPUT_ROOT = Path(\"../data/ptbxl_500hz_iv1v5\")\n",
        "X_NORM_MM_DAT = OUTPUT_ROOT / \"X_norm_mm.dat\"\n",
        "X_NORM_RAW_DAT = OUTPUT_ROOT / \"X_norm_raw.dat\"\n",
        "X_NORM_FILT_DAT = OUTPUT_ROOT / \"X_norm_filt.dat\"\n",
        "X_ANOM_MM_NPY = OUTPUT_ROOT / \"X_anom_mm.npy\"\n",
        "DIMS_JSON     = OUTPUT_ROOT / \"dims.json\"\n",
        "SPLITS_DIR = OUTPUT_ROOT / \"splits\"\n",
        "IDX_NORM_TRAIN = SPLITS_DIR / \"idx_norm_train.npy\"\n",
        "IDX_NORM_VAL   = SPLITS_DIR / \"idx_norm_val.npy\"\n",
        "IDX_NORM_TEST  = SPLITS_DIR / \"idx_norm_test.npy\"\n",
        "IDX_ANOM_TRAIN = SPLITS_DIR / \"idx_anom_train.npy\"\n",
        "IDX_ANOM_VAL   = SPLITS_DIR / \"idx_anom_val.npy\"\n",
        "IDX_ANOM_TEST  = SPLITS_DIR / \"idx_anom_test.npy\"\n",
        "\n",
        "# ---------- HIPERPAR√ÅMETROS (aj√∫stalos) ----------\n",
        "SEED       = 42\n",
        "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCHS     = 25\n",
        "BATCH_SIZE = 64\n",
        "LR         = 3e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# ---------- ARQUITECTURA AUTOENCODER (aj√∫stala) ----------\n",
        "MODEL_CFG = dict(\n",
        "    in_channels=3,\n",
        "    base_filters=32,\n",
        "    leak=0.1,\n",
        "    kernels=[11, 7, 9, 11],\n",
        ")\n",
        "\n",
        "LOSS_FN = \"mse\"\n",
        "CLIP_GRAD = None\n",
        "\n",
        "# ---------- MLFLOW ----------\n",
        "MLFLOW_TRACKING_URI = \"file:./mlruns\"\n",
        "EXPERIMENT_NAME     = \"ptbxl_ae_1dcnn_iv1v5\"\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "# ---------- UMBRAL DETECCI√ìN ----------\n",
        "THRESHOLD_BY_PERCENTILE = 98.0\n",
        "USE_MEAN_STD = False\n",
        "K_STD = 3.0\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def open_memmap_known_TC(path: Path, T: int, C: int, mode=\"r\", dtype=np.float32):\n",
        "    assert path.exists(), f\"No encuentro {path}\"\n",
        "    bytes_total = os.path.getsize(path)\n",
        "    if bytes_total % 4 != 0:\n",
        "        raise RuntimeError(f\"{path} no es m√∫ltiplo de 4 bytes (float32).\")\n",
        "    n_float32 = bytes_total // 4\n",
        "    if n_float32 % (T*C) != 0:\n",
        "        raise RuntimeError(f\"Tama√±o inconsistente: n_float32 % (T*C) != 0\")\n",
        "    N = n_float32 // (T*C)\n",
        "    return np.memmap(path, dtype=dtype, mode=mode, shape=(N, T, C))\n",
        "\n",
        "set_seed(SEED)\n",
        "with open(DIMS_JSON) as f:\n",
        "    dims = json.load(f)\n",
        "T = int(dims[\"T\"]); C = int(dims[\"C\"])\n",
        "assert C == 3, f\"Esperaba 3 derivaciones, C={C}\"\n",
        "print(f\"Dispositivo: {DEVICE} | T={T}, C={C}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "71cbde1a",
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 1114] Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL). Error loading \"c:\\Python311\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.__version__)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.is_available())\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\torch\\__init__.py:282\u001b[39m\n\u001b[32m    278\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    280\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\torch\\__init__.py:265\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    261\u001b[39m     err = ctypes.WinError(last_error)\n\u001b[32m    262\u001b[39m     err.strerror += (\n\u001b[32m    263\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    264\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    267\u001b[39m     is_loaded = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mOSError\u001b[39m: [WinError 1114] Error en una rutina de inicializaci√≥n de biblioteca de v√≠nculos din√°micos (DLL). Error loading \"c:\\Python311\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088c34d9",
      "metadata": {},
      "source": [
        "## üß© Celda 1b ‚Äî Configuraci√≥n f√°cil (1 solo lugar)\n",
        "\n",
        "- Cambia par√°metros aqu√≠ o crea un archivo `../config/ae1d_config.json` para sobreescribir.\n",
        "- Se imprime un resumen claro de lo aplicado.\n",
        "- Todo queda registrado en MLflow v√≠a `params.json` (ya implementado).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d631bf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ‚öôÔ∏è CELDA 1b ‚Äî CONFIG F√ÅCIL (dict + JSON override)\n",
        "# ========================================\n",
        "from copy import deepcopy\n",
        "\n",
        "CONFIG_PATH = Path(\"../config/ae1d_config.json\")\n",
        "\n",
        "DEFAULT_CONFIG = {\n",
        "    \"data\": {\n",
        "        \"output_root\": str((Path(\"../data/ptbxl_500hz_iv1v5\")).resolve()),\n",
        "        \"dims\": {\"T\": None, \"C\": 3},  # T se toma de dims.json\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"seed\": 42,\n",
        "        \"device\": \"auto\",  # \"auto\" -> cuda si disponible, sino cpu\n",
        "        \"epochs\": 25,\n",
        "        \"batch_size\": 64,\n",
        "        \"lr\": 3e-4,\n",
        "        \"weight_decay\": 1e-5,\n",
        "        \"clip_grad\": None,\n",
        "        \"loss_fn\": \"mse\",\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"in_channels\": 3,\n",
        "        \"base_filters\": 32,\n",
        "        \"leak\": 0.1,\n",
        "        \"kernels\": [11, 7, 9, 11],\n",
        "    },\n",
        "    \"threshold\": {\n",
        "        \"use_mean_std\": False,\n",
        "        \"k_std\": 3.0,\n",
        "        \"percentile\": 98.0,\n",
        "    },\n",
        "    \"mlflow\": {\n",
        "        \"experiment_name\": \"ptbxl_ae_1dcnn_iv1v5\",\n",
        "        \"tracking_uri\": None,  # usa el que se fija m√°s abajo (sqlite del padre)\n",
        "    },\n",
        "}\n",
        "\n",
        "def deep_update(base: dict, upd: dict) -> dict:\n",
        "    out = deepcopy(base)\n",
        "    for k, v in (upd or {}).items():\n",
        "        if isinstance(v, dict) and isinstance(out.get(k), dict):\n",
        "            out[k] = deep_update(out[k], v)\n",
        "        else:\n",
        "            out[k] = v\n",
        "    return out\n",
        "\n",
        "\n",
        "def load_user_config(path: Path | None) -> dict | None:\n",
        "    if path and path.exists():\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è No se pudo leer config JSON:\", e)\n",
        "    return None\n",
        "\n",
        "\n",
        "def apply_config(cfg: dict):\n",
        "    # Data\n",
        "    global OUTPUT_ROOT, X_NORM_MM_DAT, X_NORM_RAW_DAT, X_NORM_FILT_DAT, X_ANOM_MM_NPY, DIMS_JSON, SPLITS_DIR\n",
        "    OUTPUT_ROOT = Path(cfg[\"data\"][\"output_root\"]).resolve()\n",
        "    X_NORM_MM_DAT = OUTPUT_ROOT / \"X_norm_mm.dat\"\n",
        "    X_NORM_RAW_DAT = OUTPUT_ROOT / \"X_norm_raw.dat\"\n",
        "    X_NORM_FILT_DAT = OUTPUT_ROOT / \"X_norm_filt.dat\"\n",
        "    X_ANOM_MM_NPY = OUTPUT_ROOT / \"X_anom_mm.npy\"\n",
        "    DIMS_JSON     = OUTPUT_ROOT / \"dims.json\"\n",
        "    SPLITS_DIR    = OUTPUT_ROOT / \"splits\"\n",
        "\n",
        "    # Training\n",
        "    global SEED, DEVICE, EPOCHS, BATCH_SIZE, LR, WEIGHT_DECAY, CLIP_GRAD, LOSS_FN\n",
        "    SEED        = int(cfg[\"training\"][\"seed\"])\n",
        "    if cfg[\"training\"][\"device\"] == \"auto\":\n",
        "        DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    else:\n",
        "        DEVICE = str(cfg[\"training\"][\"device\"]).lower()\n",
        "    EPOCHS      = int(cfg[\"training\"][\"epochs\"])\n",
        "    BATCH_SIZE  = int(cfg[\"training\"][\"batch_size\"])\n",
        "    LR          = float(cfg[\"training\"][\"lr\"])\n",
        "    WEIGHT_DECAY= float(cfg[\"training\"][\"weight_decay\"])\n",
        "    CLIP_GRAD   = cfg[\"training\"][\"clip_grad\"]\n",
        "    LOSS_FN     = str(cfg[\"training\"][\"loss_fn\"]).lower()\n",
        "\n",
        "    # Model\n",
        "    global MODEL_CFG\n",
        "    MODEL_CFG = {\n",
        "        \"in_channels\": int(cfg[\"model\"][\"in_channels\"]),\n",
        "        \"base_filters\": int(cfg[\"model\"][\"base_filters\"]),\n",
        "        \"leak\": float(cfg[\"model\"][\"leak\"]),\n",
        "        \"kernels\": list(cfg[\"model\"][\"kernels\"]),\n",
        "    }\n",
        "\n",
        "    # Threshold\n",
        "    global USE_MEAN_STD, K_STD, THRESHOLD_BY_PERCENTILE\n",
        "    USE_MEAN_STD = bool(cfg[\"threshold\"][\"use_mean_std\"])\n",
        "    K_STD = float(cfg[\"threshold\"][\"k_std\"])\n",
        "    THRESHOLD_BY_PERCENTILE = float(cfg[\"threshold\"][\"percentile\"])\n",
        "\n",
        "    # MLflow (solo nombre si se quisiera usar mlruns local)\n",
        "    global EXPERIMENT_NAME\n",
        "    EXPERIMENT_NAME = str(cfg[\"mlflow\"][\"experiment_name\"]) \n",
        "\n",
        "\n",
        "# ==== cargar + aplicar ====\n",
        "_user_cfg = load_user_config(CONFIG_PATH)\n",
        "ACTIVE_CONFIG = deep_update(DEFAULT_CONFIG, _user_cfg or {})\n",
        "apply_config(ACTIVE_CONFIG)\n",
        "\n",
        "print(\"Config aplicada:\")\n",
        "print(\"- output_root:\", OUTPUT_ROOT)\n",
        "print(\"- device:\", DEVICE, \"| epochs:\", EPOCHS, \"| batch_size:\", BATCH_SIZE, \"| lr:\", LR)\n",
        "print(\"- model:\", MODEL_CFG)\n",
        "print(\"- threshold:\", {\"use_mean_std\": USE_MEAN_STD, \"k_std\": K_STD, \"percentile\": THRESHOLD_BY_PERCENTILE})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9102acce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Opcional) Guardar plantilla de config si no existe\n",
        "CFG_DIR = CONFIG_PATH.parent\n",
        "CFG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "if not CONFIG_PATH.exists():\n",
        "    with open(CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(DEFAULT_CONFIG, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Plantilla creada en:\", CONFIG_PATH)\n",
        "else:\n",
        "    print(\"Usando config en:\", CONFIG_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßæ Celda 2 ‚Äî Dataset y DataLoaders\n",
        "\n",
        "- `MemmapDataset` abre el `.dat` **sin cargar todo a RAM** y devuelve tensores `[C, T]` para `Conv1d` de PyTorch.  \n",
        "- Entrenamos con **normales**; validaci√≥n y test combinan normales y an√≥malos para evaluaci√≥n de reconstrucci√≥n/anomal√≠a.\n",
        "- Cambia tama√±os de *batch* en `BATCH_SIZE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üßæ CELDA 2 ‚Äî DATASET + DATALOADERS\n",
        "# ========================================\n",
        "\n",
        "class MemmapDataset(Dataset):\n",
        "    def __init__(self, x_memmap, indices):\n",
        "        self.x = x_memmap\n",
        "        self.indices = np.array(indices, dtype=np.int64)\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    def __getitem__(self, i):\n",
        "        idx = int(self.indices[i])\n",
        "        arr = self.x[idx]          # [T, C]\n",
        "        arr = np.transpose(arr, (1,0)).copy() # [C, T] y writable\n",
        "        return torch.from_numpy(arr).float()\n",
        "\n",
        "X_norm_mm = open_memmap_known_TC(X_NORM_MM_DAT, T, C, mode=\"r\")\n",
        "X_anom_mm = np.load(X_ANOM_MM_NPY) if X_ANOM_MM_NPY.exists() else np.zeros((0,T,C),dtype=np.float32)\n",
        "\n",
        "idx_norm_train = np.load(IDX_NORM_TRAIN)\n",
        "idx_norm_val   = np.load(IDX_NORM_VAL)\n",
        "idx_norm_test  = np.load(IDX_NORM_TEST)\n",
        "idx_anom_val   = np.load(IDX_ANOM_VAL) if IDX_ANOM_VAL.exists() else np.zeros((0,),dtype=np.int64)\n",
        "idx_anom_test  = np.load(IDX_ANOM_TEST) if IDX_ANOM_TEST.exists() else np.zeros((0,),dtype=np.int64)\n",
        "\n",
        "ds_train = MemmapDataset(X_norm_mm, idx_norm_train)\n",
        "ds_val_n = MemmapDataset(X_norm_mm, idx_norm_val)\n",
        "ds_test_n= MemmapDataset(X_norm_mm, idx_norm_test)\n",
        "\n",
        "if len(X_anom_mm):\n",
        "    class NpyDataset(Dataset):\n",
        "        def __init__(self, x_npy, indices):\n",
        "            self.x = x_npy\n",
        "            self.indices = np.array(indices, dtype=np.int64)\n",
        "        def __len__(self):\n",
        "            return len(self.indices)\n",
        "        def __getitem__(self, i):\n",
        "            idx = int(self.indices[i])\n",
        "            arr = self.x[idx]\n",
        "            arr = np.transpose(arr, (1,0)).copy()\n",
        "            return torch.from_numpy(arr).float()\n",
        "    ds_val_a  = NpyDataset(X_anom_mm, idx_anom_val) if len(idx_anom_val)>0 else None\n",
        "    ds_test_a = NpyDataset(X_anom_mm, idx_anom_test) if len(idx_anom_test)>0 else None\n",
        "else:\n",
        "    ds_val_a = ds_test_a = None\n",
        "\n",
        "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=False)\n",
        "dl_val_n = DataLoader(ds_val_n, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "dl_test_n= DataLoader(ds_test_n, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "dl_val_a  = DataLoader(ds_val_a,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0) if ds_val_a else None\n",
        "dl_test_a = DataLoader(ds_test_a, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) if ds_test_a else None\n",
        "\n",
        "print(\"Train (norm):\", len(ds_train), \"| Val norm:\", len(ds_val_n), \"| Test norm:\", len(ds_test_n))\n",
        "print(\"Val anom:\", 0 if dl_val_a is None else len(ds_val_a), \"| Test anom:\", 0 if dl_test_a is None else len(ds_test_a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Celda 3 ‚Äî Modelo Autoencoder 1D CNN\n",
        "\n",
        "Arquitectura **encoder‚Äìdecoder** inspirada en la tabla provista. Ajustable v√≠a `MODEL_CFG`:\n",
        "\n",
        "- **Encoder**: Conv1d + LeakyReLU + MaxPool (reduce temporal).  \n",
        "- **Decoder**: Upsample (recupera longitud) + Conv1d + activaciones.  \n",
        "- **Salida**: `sigmoid` (supone entrada min‚Äìmax ‚àà [0,1]).  \n",
        "- **Cropping**: si la longitud no calza (por *pool/upsample*), se recorta al tama√±o original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üß† CELDA 3 ‚Äî DEFINICI√ìN DEL MODELO\n",
        "# ========================================\n",
        "\n",
        "class Cropping1D(nn.Module):\n",
        "    def __init__(self, target_len: int):\n",
        "        super().__init__()\n",
        "        self.target_len = target_len\n",
        "    def forward(self, x):\n",
        "        Tprime = x.shape[-1]\n",
        "        if Tprime == self.target_len:\n",
        "            return x\n",
        "        if Tprime > self.target_len:\n",
        "            start = (Tprime - self.target_len) // 2\n",
        "            end = start + self.target_len\n",
        "            return x[..., start:end]\n",
        "        else:\n",
        "            pad = self.target_len - Tprime\n",
        "            left = pad // 2\n",
        "            right = pad - left\n",
        "            return nn.functional.pad(x, (left, right), mode=\"reflect\")\n",
        "\n",
        "class AE1DCNN(nn.Module):\n",
        "    def __init__(self, cfg: Dict, in_len: int):\n",
        "        super().__init__()\n",
        "        ch_in  = cfg[\"in_channels\"]\n",
        "        base   = cfg[\"base_filters\"]\n",
        "        leak   = cfg[\"leak\"]\n",
        "        k1,k2,k3,k4 = cfg[\"kernels\"]\n",
        "        act = nn.LeakyReLU(leak, inplace=True)\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv1d(ch_in, base*2, kernel_size=k1, padding=k1//2), act,\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(base*2, base, kernel_size=k2, padding=k2//2), act,\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(base, base, kernel_size=k3, padding=k3//2), act,\n",
        "            nn.Conv1d(base, base, kernel_size=k4, padding=k4//2), act,\n",
        "        )\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
        "            nn.Conv1d(base, base*2, kernel_size=k3, padding=k3//2), act,\n",
        "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
        "            nn.Conv1d(base*2, base, kernel_size=k2, padding=k2//2), act,\n",
        "            nn.Conv1d(base, ch_in, kernel_size=k1, padding=k1//2),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.crop = Cropping1D(in_len)\n",
        "    def forward(self, x):\n",
        "        z = self.enc(x)\n",
        "        y = self.dec(z)\n",
        "        return self.crop(y)\n",
        "\n",
        "model = AE1DCNN(MODEL_CFG, in_len=T).to(DEVICE)\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(model)\n",
        "print(f\"Total params: {n_params/1e6:.3f} M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12f2262",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== MLflow: usar la BD un directorio arriba (../mlflow.db) y artefactos fijos ====\n",
        "from pathlib import Path\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# 1) Construimos rutas absolutas hacia el directorio padre del notebook\n",
        "PARENT_DIR = Path.cwd().parent.resolve()                  # <- ../ (absoluto)\n",
        "TRACKING_DB = (PARENT_DIR / \"mlflow.db\").resolve()        # ../mlflow.db\n",
        "ARTIF_ROOT  = (PARENT_DIR / \"mlflow_artifacts\").resolve() # ../mlflow_artifacts/\n",
        "ARTIF_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2) Fijamos el tracking URI apuntando a la BD del directorio padre\n",
        "#    (OJO: en Windows hay que usar file:/// y paths estilo POSIX)\n",
        "mlflow.set_tracking_uri(f\"sqlite:///{TRACKING_DB.as_posix()}\")\n",
        "\n",
        "# 3) Creamos/obtenemos el experimento con artifact_location expl√≠cito en ../mlflow_artifacts\n",
        "client = MlflowClient()\n",
        "EXP_NAME = \"ae1d\"\n",
        "exp = client.get_experiment_by_name(EXP_NAME)\n",
        "if exp is None:\n",
        "    EXP_ID = client.create_experiment(EXP_NAME, artifact_location=ARTIF_ROOT.as_uri())\n",
        "else:\n",
        "    EXP_ID = exp.experiment_id\n",
        "\n",
        "# 4) Si qued√≥ alg√∫n run abierto por errores previos de notebook, lo cerramos\n",
        "if mlflow.active_run() is not None:\n",
        "    print(\"Cerrando run previo:\", mlflow.active_run().info.run_id)\n",
        "    mlflow.end_run()\n",
        "\n",
        "print(\">>> Tracking URI:\", mlflow.get_tracking_uri())\n",
        "print(\">>> Experiment ID:\", EXP_ID)\n",
        "print(\">>> Artifact root:\", ARTIF_ROOT.as_uri())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è Celda 4 ‚Äî Entrenamiento con **Prefect** + **MLflow**\n",
        "\n",
        "- `@task` para `train_epoch` y `eval_epoch` (devuelven p√©rdida media).  \n",
        "- `@flow` principal: inicia **MLflow run**, loguea **par√°metros**, curva de **loss**, mejor **checkpoint**, y artefactos (gr√°ficos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üèãÔ∏è CELDA 4 ‚Äî ENTRENAMIENTO con PREFECT + MLFLOW (versi√≥n robusta)\n",
        "# ========================================\n",
        "\n",
        "import time, json\n",
        "from pathlib import Path\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  # backend no interactivo para guardar figuras\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "import mlflow.pytorch as mlflow_pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from prefect import task, flow\n",
        "\n",
        "# --------- p√©rdida ---------\n",
        "def loss_fn(pred, target):\n",
        "    if LOSS_FN == \"mse\":\n",
        "        return nn.functional.mse_loss(pred, target)\n",
        "    raise NotImplementedError(f\"LOSS_FN no soportada: {LOSS_FN}\")\n",
        "\n",
        "# --------- helpers de logging ----------\n",
        "def count_params(m: torch.nn.Module):\n",
        "    total = sum(p.numel() for p in m.parameters())\n",
        "    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "    return total, trainable\n",
        "\n",
        "def _flatten_dict(d, parent_key=\"\", sep=\"__\"):\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else str(k)\n",
        "        if isinstance(v, dict):\n",
        "            items.extend(_flatten_dict(v, new_key, sep=sep).items())\n",
        "        else:\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)\n",
        "\n",
        "def collect_run_params() -> dict:\n",
        "    params = {\n",
        "        \"seed\": SEED,\n",
        "        \"device\": DEVICE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"learning_rate\": LR,\n",
        "        \"weight_decay\": WEIGHT_DECAY,\n",
        "        \"loss_fn\": LOSS_FN,\n",
        "        \"threshold\": {\n",
        "            \"use_mean_std\": USE_MEAN_STD,\n",
        "            \"k_std\": K_STD,\n",
        "            \"percentile\": THRESHOLD_BY_PERCENTILE,\n",
        "        },\n",
        "        \"model\": MODEL_CFG,\n",
        "        \"data\": {\n",
        "            \"output_root\": str(OUTPUT_ROOT.resolve()),\n",
        "            \"x_norm_mm\": str(X_NORM_MM_DAT),\n",
        "            \"x_anom_npy\": str(X_ANOM_MM_NPY),\n",
        "            \"dims_json\": str(DIMS_JSON),\n",
        "        },\n",
        "        \"dims\": {\"T\": int(T), \"C\": int(C)},\n",
        "    }\n",
        "    return params\n",
        "\n",
        "# --------- tareas Prefect ----------\n",
        "@task(name=\"train_epoch\", log_prints=True)\n",
        "def train_epoch(model: nn.Module, loader, optimizer) -> float:\n",
        "    model.train()\n",
        "    total = 0.0; n = 0\n",
        "    for xb in loader:\n",
        "        xb = xb.to(DEVICE, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        yb = model(xb)\n",
        "        loss = loss_fn(yb, xb)  # Reconstruction MSE\n",
        "        loss.backward()\n",
        "        if CLIP_GRAD is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP_GRAD)\n",
        "        optimizer.step()\n",
        "        total += loss.item() * xb.size(0)\n",
        "        n += xb.size(0)\n",
        "    return total / max(1, n)\n",
        "\n",
        "@task(name=\"eval_epoch\", log_prints=True)\n",
        "def eval_epoch(model: nn.Module, loader) -> float:\n",
        "    model.eval()\n",
        "    total = 0.0; n = 0\n",
        "    with torch.no_grad():\n",
        "        for xb in loader:\n",
        "            xb = xb.to(DEVICE, non_blocking=True)\n",
        "            yb = model(xb)\n",
        "            loss = loss_fn(yb, xb)  # Reconstruction MSE\n",
        "            total += loss.item() * xb.size(0)\n",
        "            n += xb.size(0)\n",
        "    return total / max(1, n)\n",
        "\n",
        "# --------- flow principal ----------\n",
        "@flow(name=\"train_autoencoder_1d\", log_prints=True)\n",
        "def train_flow():\n",
        "    global DEVICE\n",
        "    set_seed(SEED)\n",
        "    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "    best_path = (OUTPUT_ROOT / \"ae_best.pt\").resolve()\n",
        "    curves_path = (OUTPUT_ROOT / \"loss_curves.png\").resolve()\n",
        "    params_path = (OUTPUT_ROOT / \"params.json\").resolve()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Fallback seguro: si CUDA est√° disponible pero la GPU no soporta kernels de esta build, cambiamos a CPU\n",
        "    if DEVICE.startswith(\"cuda\"):\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_len = min(T, 512)\n",
        "                xb = torch.randn(1, MODEL_CFG[\"in_channels\"], test_len, device=DEVICE)\n",
        "                _ = model(xb)\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Problema con CUDA en este dispositivo -> usando CPU. Causa:\", e)\n",
        "            DEVICE = \"cpu\"\n",
        "            model.to(DEVICE)\n",
        "\n",
        "    with mlflow.start_run(run_name=f\"ae1d_{int(time.time())}\", experiment_id=EXP_ID) as run:\n",
        "        run_id = run.info.run_id\n",
        "        print(\"RUN:\", run_id)\n",
        "        print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
        "        print(\"Artifact URI:\", mlflow.get_artifact_uri())\n",
        "\n",
        "        # Log de par√°metros (flatten) + guardar como artifact params.json\n",
        "        params = collect_run_params()\n",
        "        flat_params = _flatten_dict(params)\n",
        "        # Solo valores primitivos admitidos por MLflow en log_params\n",
        "        mlflow.log_params({k: (v if isinstance(v, (str, int, float, bool)) else str(v)) for k, v in flat_params.items()})\n",
        "        with open(params_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(params, f, ensure_ascii=False, indent=2)\n",
        "        mlflow.log_artifact(str(params_path), artifact_path=\"config\")\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "        tr_losses, val_losses = [], []\n",
        "        best_val = float(\"inf\")\n",
        "\n",
        "        for ep in range(1, EPOCHS + 1):\n",
        "            tr = train_epoch(model, dl_train, optimizer)\n",
        "            va = eval_epoch(model, dl_val_n)\n",
        "\n",
        "            tr_losses.append(tr); val_losses.append(va)\n",
        "            mlflow.log_metrics({\"recon_mse_train\": float(tr), \"recon_mse_val\": float(va)}, step=ep)\n",
        "\n",
        "            print(f\"[{ep:03d}/{EPOCHS}] recon_mse_train={tr:.6f} | recon_mse_val={va:.6f}\")\n",
        "\n",
        "            if va < best_val:\n",
        "                best_val = va\n",
        "                torch.save(model.state_dict(), best_path)\n",
        "                assert best_path.exists()\n",
        "                mlflow.log_artifact(str(best_path), artifact_path=\"checkpoints\")\n",
        "\n",
        "        # curvas\n",
        "        plt.figure(figsize=(7, 4))\n",
        "        plt.plot(tr_losses, label=\"train MSE\")\n",
        "        plt.plot(val_losses, label=\"val MSE\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Reconstruction MSE\")\n",
        "        plt.legend(); plt.tight_layout()\n",
        "        plt.savefig(curves_path, dpi=130); plt.close()\n",
        "        assert curves_path.exists()\n",
        "        mlflow.log_artifact(str(curves_path), artifact_path=\"plots\")\n",
        "\n",
        "        # modelo\n",
        "        model.load_state_dict(torch.load(best_path, map_location=\"cpu\"))\n",
        "        model.eval()\n",
        "        mlflow_pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
        "\n",
        "        return {\n",
        "            \"best_ckpt\": str(best_path),\n",
        "            \"curves_png\": str(curves_path),\n",
        "            \"best_val\": float(best_val),\n",
        "            \"mlflow_run_id\": run_id,\n",
        "        }\n",
        "\n",
        "# ---- ejecuci√≥n sincr√≥nica del flow (local) ----\n",
        "train_artifacts = train_flow()\n",
        "print(\"Artifacts:\", train_artifacts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Celda 5 ‚Äî Evaluaci√≥n completa + Umbral de anomal√≠a\n",
        "\n",
        "- Calcula **EMA (MAE)**, **EMC (MSE)**, **RMSE**, **R¬≤** sobre **validaci√≥n** y **test** (solo reconstrucci√≥n).\n",
        "- Fija **umbral** con percentil (o Œº+K¬∑œÉ) usando errores por **registro** en validaci√≥n **normal**.\n",
        "- Aplica umbral para clasificar **an√≥malo** (error > umbral) vs **normal** (error ‚â§ umbral).\n",
        "- Construye **matriz de confusi√≥n (TP/FP/TN/FN)** y **reporte** en validaci√≥n y test.\n",
        "- Loguea todo en **MLflow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üìà CELDA 5 ‚Äî EVALUACI√ìN + MATRIZ DE CONFUSI√ìN\n",
        "# ========================================\n",
        "\n",
        "def reconstruct_errors(model, loader):\n",
        "    model.eval(); errs = []; xs_all = []; ys_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb in loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = model(xb)\n",
        "            mse = torch.mean((yb - xb)**2, dim=(1,2)).detach().cpu().numpy()\n",
        "            errs.append(mse)\n",
        "            xs_all.append(xb.detach().cpu().numpy())\n",
        "            ys_all.append(yb.detach().cpu().numpy())\n",
        "    return np.concatenate(errs), np.concatenate(xs_all), np.concatenate(ys_all)\n",
        "\n",
        "def basic_regression_metrics(x_true, x_pred):\n",
        "    a = x_true.reshape(-1); b = x_pred.reshape(-1)\n",
        "    mae = mean_absolute_error(a, b)\n",
        "    mse = mean_squared_error(a, b)\n",
        "    rmse = math.sqrt(mse)\n",
        "    r2 = r2_score(a, b)\n",
        "    return dict(mae=mae, mse=mse, rmse=rmse, r2=r2)\n",
        "\n",
        "def pick_threshold(errs_norm_val):\n",
        "    if USE_MEAN_STD:\n",
        "        mu = float(np.mean(errs_norm_val)); sd = float(np.std(errs_norm_val))\n",
        "        thr = mu + K_STD*sd; how = f\"mean+{K_STD}*std\"\n",
        "    else:\n",
        "        thr = float(np.percentile(errs_norm_val, THRESHOLD_BY_PERCENTILE))\n",
        "        how = f\"p{THRESHOLD_BY_PERCENTILE}\"\n",
        "    return thr, how\n",
        "\n",
        "best_path = (OUTPUT_ROOT / \"ae_best.pt\").resolve()\n",
        "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
        "\n",
        "with mlflow.start_run(run_name=\"eval\", experiment_id=EXP_ID):\n",
        "    val_err_n, val_xn, val_yn = reconstruct_errors(model, dl_val_n)\n",
        "    reg_val = basic_regression_metrics(val_xn, val_yn)\n",
        "    thr, how = pick_threshold(val_err_n)\n",
        "    if dl_val_a is not None:\n",
        "        val_err_a, val_xa, val_ya = reconstruct_errors(model, dl_val_a)\n",
        "        y_true = np.concatenate([np.zeros_like(val_err_n), np.ones_like(val_err_a)])\n",
        "        y_pred = np.concatenate([val_err_n > thr, val_err_a > thr]).astype(int)\n",
        "    else:\n",
        "        y_true = np.zeros_like(val_err_n)\n",
        "        y_pred = (val_err_n > thr).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    report = classification_report(y_true, y_pred, target_names=[\"normal\",\"anomalo\"], digits=4)\n",
        "    mlflow.log_metrics({f\"val_{k}\": v for k,v in reg_val.items()})\n",
        "    mlflow.log_param(\"threshold_how\", how)\n",
        "    mlflow.log_param(\"threshold_value\", thr)\n",
        "    cm_df = pd.DataFrame(cm, index=[\"Real:Normal\",\"Real:Anomalo\"], columns=[\"Pred:Normal\",\"Pred:Anomalo\"])\n",
        "    cm_path = OUTPUT_ROOT / \"cm_val.csv\"; cm_df.to_csv(cm_path)\n",
        "    with open(OUTPUT_ROOT / \"report_val.txt\",\"w\") as f: f.write(report)\n",
        "    mlflow.log_artifact(str(cm_path), artifact_path=\"eval_val\")\n",
        "    mlflow.log_artifact(str(OUTPUT_ROOT / \"report_val.txt\"), artifact_path=\"eval_val\")\n",
        "\n",
        "    test_err_n, test_xn, test_yn = reconstruct_errors(model, dl_test_n)\n",
        "    reg_test = basic_regression_metrics(test_xn, test_yn)\n",
        "    if dl_test_a is not None:\n",
        "        test_err_a, test_xa, test_ya = reconstruct_errors(model, dl_test_a)\n",
        "        y_true_t = np.concatenate([np.zeros_like(test_err_n), np.ones_like(test_err_a)])\n",
        "        y_pred_t = np.concatenate([test_err_n > thr, test_err_a > thr]).astype(int)\n",
        "    else:\n",
        "        y_true_t = np.zeros_like(test_err_n)\n",
        "        y_pred_t = (test_err_n > thr).astype(int)\n",
        "    cm_t = confusion_matrix(y_true_t, y_pred_t, labels=[0,1])\n",
        "    report_t = classification_report(y_true_t, y_pred_t, target_names=[\"normal\",\"anomalo\"], digits=4)\n",
        "    mlflow.log_metrics({f\"test_{k}\": v for k,v in reg_test.items()})\n",
        "    cm_t_df = pd.DataFrame(cm_t, index=[\"Real:Normal\",\"Real:Anomalo\"], columns=[\"Pred:Normal\",\"Pred:Anomalo\"])\n",
        "    cm_t_path = OUTPUT_ROOT / \"cm_test.csv\"; cm_t_df.to_csv(cm_t_path)\n",
        "    with open(OUTPUT_ROOT / \"report_test.txt\",\"w\") as f: f.write(report_t)\n",
        "    mlflow.log_artifact(str(cm_t_path), artifact_path=\"eval_test\")\n",
        "    mlflow.log_artifact(str(OUTPUT_ROOT / \"report_test.txt\"), artifact_path=\"eval_test\")\n",
        "\n",
        "    if test_xn.shape[0] > 0:\n",
        "        ex_in  = test_xn[0]; ex_out = test_yn[0]\n",
        "        leads = [\"II\",\"V1\",\"V5\"]; t = np.arange(ex_in.shape[1]) / 500.0\n",
        "        for i, ld in enumerate(leads):\n",
        "            plt.figure(figsize=(10,3))\n",
        "            plt.plot(t, ex_in[i], label=\"input\")\n",
        "            plt.plot(t, ex_out[i], label=\"recon\", alpha=0.85)\n",
        "            plt.title(f\"Reconstrucci√≥n Test ‚Äî {ld}\")\n",
        "            plt.xlabel(\"s\"); plt.tight_layout(); plt.legend()\n",
        "            pth = OUTPUT_ROOT / f\"recon_{ld}_test.png\"\n",
        "            plt.savefig(pth, dpi=130); plt.close()\n",
        "            mlflow.log_artifact(str(pth), artifact_path=\"recon_examples\")\n",
        "\n",
        "print(\"Evaluaci√≥n completada. Ver artefactos en MLflow.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed13534",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# üìà CELDA 5b ‚Äî EVALUACI√ìN (mejorada) + MATRICES DE CONFUSI√ìN LEGIBLES\n",
        "# ========================================\n",
        "\n",
        "def reconstruct_errors(model, loader):\n",
        "    model.eval(); errs = []; xs_all = []; ys_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb in loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = model(xb)\n",
        "            mse = torch.mean((yb - xb)**2, dim=(1,2)).detach().cpu().numpy()\n",
        "            errs.append(mse)\n",
        "            xs_all.append(xb.detach().cpu().numpy())\n",
        "            ys_all.append(yb.detach().cpu().numpy())\n",
        "    return np.concatenate(errs), np.concatenate(xs_all), np.concatenate(ys_all)\n",
        "\n",
        "def basic_regression_metrics(x_true, x_pred):\n",
        "    a = x_true.reshape(-1); b = x_pred.reshape(-1)\n",
        "    mae = mean_absolute_error(a, b)\n",
        "    mse = mean_squared_error(a, b)\n",
        "    rmse = math.sqrt(mse)\n",
        "    r2 = r2_score(a, b)\n",
        "    return dict(mae=mae, mse=mse, rmse=rmse, r2=r2)\n",
        "\n",
        "def pick_threshold(errs_norm_val):\n",
        "    if USE_MEAN_STD:\n",
        "        mu = float(np.mean(errs_norm_val)); sd = float(np.std(errs_norm_val))\n",
        "        thr = mu + K_STD*sd; how = f\"mean+{K_STD}*std\"\n",
        "    else:\n",
        "        thr = float(np.percentile(errs_norm_val, THRESHOLD_BY_PERCENTILE))\n",
        "        how = f\"p{THRESHOLD_BY_PERCENTILE}\"\n",
        "    return thr, how\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title, path_png, normalize=True):\n",
        "    import numpy as _np\n",
        "    fig, ax = plt.subplots(figsize=(5,4))\n",
        "    data = cm.astype(float)\n",
        "    if normalize:\n",
        "        row_sums = data.sum(axis=1, keepdims=True)\n",
        "        row_sums[row_sums == 0] = 1.0\n",
        "        data = data / row_sums\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \"d\"\n",
        "    im = ax.imshow(data, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=_np.arange(cm.shape[1]), yticks=_np.arange(cm.shape[0]),\n",
        "           xticklabels=[f\"Pred:{l}\" for l in labels], yticklabels=[f\"Real:{l}\" for l in labels],\n",
        "           ylabel=\"Real\", xlabel=\"Predicci√≥n\", title=title)\n",
        "    thresh = data.max() / 2.0 if data.size else 0.5\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(data[i, j], fmt), ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if data[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path_png, dpi=140)\n",
        "    plt.close(fig)\n",
        "\n",
        "best_path = (OUTPUT_ROOT / \"ae_best.pt\").resolve()\n",
        "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
        "\n",
        "with mlflow.start_run(run_name=\"eval_plus\", experiment_id=EXP_ID):\n",
        "    # --- Validaci√≥n ---\n",
        "    val_err_n, val_xn, val_yn = reconstruct_errors(model, dl_val_n)\n",
        "    reg_val = basic_regression_metrics(val_xn, val_yn)\n",
        "    thr, how = pick_threshold(val_err_n)\n",
        "\n",
        "    if dl_val_a is not None:\n",
        "        val_err_a, val_xa, val_ya = reconstruct_errors(model, dl_val_a)\n",
        "        y_true_val = np.concatenate([np.zeros_like(val_err_n), np.ones_like(val_err_a)])\n",
        "        y_score_val = np.concatenate([val_err_n, val_err_a])\n",
        "        y_pred_val = (y_score_val > thr).astype(int)\n",
        "    else:\n",
        "        y_true_val = np.zeros_like(val_err_n)\n",
        "        y_score_val = val_err_n\n",
        "        y_pred_val = (val_err_n > thr).astype(int)\n",
        "\n",
        "    cm_val = confusion_matrix(y_true_val, y_pred_val, labels=[0,1])\n",
        "    acc_val = accuracy_score(y_true_val, y_pred_val)\n",
        "    prec_val = precision_score(y_true_val, y_pred_val, zero_division=0)\n",
        "    rec_val = recall_score(y_true_val, y_pred_val, zero_division=0)\n",
        "    f1_val = f1_score(y_true_val, y_pred_val, zero_division=0)\n",
        "    balacc_val = balanced_accuracy_score(y_true_val, y_pred_val)\n",
        "    tn, fp, fn, tp = cm_val.ravel() if cm_val.size == 4 else (0,0,0,0)\n",
        "    spec_val = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    try:\n",
        "        auroc_val = roc_auc_score(y_true_val, y_score_val)\n",
        "    except Exception:\n",
        "        auroc_val = float(\"nan\")\n",
        "    try:\n",
        "        auprc_val = average_precision_score(y_true_val, y_score_val)\n",
        "    except Exception:\n",
        "        auprc_val = float(\"nan\")\n",
        "\n",
        "    mlflow.log_param(\"threshold_how\", how)\n",
        "    mlflow.log_param(\"threshold_value\", thr)\n",
        "    mlflow.log_metrics({\n",
        "        **{f\"val_{k}\": v for k, v in reg_val.items()},\n",
        "        \"val_accuracy\": acc_val,\n",
        "        \"val_precision\": prec_val,\n",
        "        \"val_recall\": rec_val,\n",
        "        \"val_f1\": f1_val,\n",
        "        \"val_balanced_accuracy\": balacc_val,\n",
        "        \"val_specificity\": spec_val,\n",
        "        \"val_auroc\": auroc_val,\n",
        "        \"val_auprc\": auprc_val,\n",
        "    })\n",
        "\n",
        "    cm_val_df = pd.DataFrame(cm_val, index=[\"Real:Normal\",\"Real:Anomalo\"], columns=[\"Pred:Normal\",\"Pred:Anomalo\"])\n",
        "    cm_val_csv = OUTPUT_ROOT / \"cm_val.csv\"; cm_val_df.to_csv(cm_val_csv)\n",
        "    with open(OUTPUT_ROOT / \"report_val.txt\",\"w\") as f:\n",
        "        f.write(classification_report(y_true_val, y_pred_val, target_names=[\"normal\",\"anomalo\"], digits=4))\n",
        "    cm_val_png = OUTPUT_ROOT / \"cm_val.png\"\n",
        "    plot_confusion_matrix(cm_val, [\"Normal\",\"Anomalo\"], \"Matriz de confusi√≥n (Val)\", cm_val_png, normalize=True)\n",
        "    mlflow.log_artifact(str(cm_val_csv), artifact_path=\"eval_val\")\n",
        "    mlflow.log_artifact(str(OUTPUT_ROOT / \"report_val.txt\"), artifact_path=\"eval_val\")\n",
        "    mlflow.log_artifact(str(cm_val_png), artifact_path=\"eval_val\")\n",
        "\n",
        "    # --- Test ---\n",
        "    test_err_n, test_xn, test_yn = reconstruct_errors(model, dl_test_n)\n",
        "    reg_test = basic_regression_metrics(test_xn, test_yn)\n",
        "    if dl_test_a is not None:\n",
        "        test_err_a, test_xa, test_ya = reconstruct_errors(model, dl_test_a)\n",
        "        y_true_t = np.concatenate([np.zeros_like(test_err_n), np.ones_like(test_err_a)])\n",
        "        y_score_t = np.concatenate([test_err_n, test_err_a])\n",
        "        y_pred_t = (y_score_t > thr).astype(int)\n",
        "    else:\n",
        "        y_true_t = np.zeros_like(test_err_n)\n",
        "        y_score_t = test_err_n\n",
        "        y_pred_t = (test_err_n > thr).astype(int)\n",
        "\n",
        "    cm_t = confusion_matrix(y_true_t, y_pred_t, labels=[0,1])\n",
        "    acc_t = accuracy_score(y_true_t, y_pred_t)\n",
        "    prec_t = precision_score(y_true_t, y_pred_t, zero_division=0)\n",
        "    rec_t = recall_score(y_true_t, y_pred_t, zero_division=0)\n",
        "    f1_t = f1_score(y_true_t, y_pred_t, zero_division=0)\n",
        "    balacc_t = balanced_accuracy_score(y_true_t, y_pred_t)\n",
        "    tn, fp, fn, tp = cm_t.ravel() if cm_t.size == 4 else (0,0,0,0)\n",
        "    spec_t = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    try:\n",
        "        auroc_t = roc_auc_score(y_true_t, y_score_t)\n",
        "    except Exception:\n",
        "        auroc_t = float(\"nan\")\n",
        "    try:\n",
        "        auprc_t = average_precision_score(y_true_t, y_score_t)\n",
        "    except Exception:\n",
        "        auprc_t = float(\"nan\")\n",
        "\n",
        "    mlflow.log_metrics({\n",
        "        **{f\"test_{k}\": v for k, v in reg_test.items()},\n",
        "        \"test_accuracy\": acc_t,\n",
        "        \"test_precision\": prec_t,\n",
        "        \"test_recall\": rec_t,\n",
        "        \"test_f1\": f1_t,\n",
        "        \"test_balanced_accuracy\": balacc_t,\n",
        "        \"test_specificity\": spec_t,\n",
        "        \"test_auroc\": auroc_t,\n",
        "        \"test_auprc\": auprc_t,\n",
        "    })\n",
        "\n",
        "    cm_t_df = pd.DataFrame(cm_t, index=[\"Real:Normal\",\"Real:Anomalo\"], columns=[\"Pred:Normal\",\"Pred:Anomalo\"])\n",
        "    cm_t_csv = OUTPUT_ROOT / \"cm_test.csv\"; cm_t_df.to_csv(cm_t_csv)\n",
        "    with open(OUTPUT_ROOT / \"report_test.txt\",\"w\") as f:\n",
        "        f.write(classification_report(y_true_t, y_pred_t, target_names=[\"normal\",\"anomalo\"], digits=4))\n",
        "    cm_t_png = OUTPUT_ROOT / \"cm_test.png\"\n",
        "    plot_confusion_matrix(cm_t, [\"Normal\",\"Anomalo\"], \"Matriz de confusi√≥n (Test)\", cm_t_png, normalize=True)\n",
        "    mlflow.log_artifact(str(cm_t_csv), artifact_path=\"eval_test\")\n",
        "    mlflow.log_artifact(str(OUTPUT_ROOT / \"report_test.txt\"), artifact_path=\"eval_test\")\n",
        "    mlflow.log_artifact(str(cm_t_png), artifact_path=\"eval_test\")\n",
        "\n",
        "    # --- Ejemplos de reconstrucci√≥n ---\n",
        "    if test_xn.shape[0] > 0:\n",
        "        ex_in  = test_xn[0]; ex_out = test_yn[0]\n",
        "        leads = [\"II\",\"V1\",\"V5\"]; t = np.arange(ex_in.shape[1]) / 500.0\n",
        "        for i, ld in enumerate(leads):\n",
        "            plt.figure(figsize=(10,3))\n",
        "            plt.plot(t, ex_in[i], label=\"input\")\n",
        "            plt.plot(t, ex_out[i], label=\"recon\", alpha=0.85)\n",
        "            plt.title(f\"Reconstrucci√≥n Test ‚Äî {ld}\")\n",
        "            plt.xlabel(\"s\"); plt.tight_layout(); plt.legend()\n",
        "            pth = OUTPUT_ROOT / f\"recon_{ld}_test.png\"\n",
        "            plt.savefig(pth, dpi=130); plt.close()\n",
        "            mlflow.log_artifact(str(pth), artifact_path=\"recon_examples\")\n",
        "\n",
        "print(\"Evaluaci√≥n mejorada completada. Ver artefactos en MLflow.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úçÔ∏è ¬øD√≥nde cambiar par√°metros?\n",
        "\n",
        "- **Rutas y archivos**: Celda **1** (`OUTPUT_ROOT`, nombres `.dat/.npy`).  \n",
        "- **Hiperpar√°metros**: Celda **1** (`EPOCHS`, `BATCH_SIZE`, `LR`, `WEIGHT_DECAY`, `SEED`).  \n",
        "- **Modelo**: Celda **1** (`MODEL_CFG`: `base_filters`, `kernels`, `leak`, etc.).  \n",
        "- **P√©rdida**: Celda **4** (`LOSS_FN=\"mse\"`).  \n",
        "- **Umbral**: Celda **1** (`THRESHOLD_BY_PERCENTILE`, `USE_MEAN_STD`, `K_STD`).  \n",
        "- **MLflow**: Celda **1** (`MLFLOW_TRACKING_URI`, `EXPERIMENT_NAME`).  \n",
        "- **Prefect**: El *flow* y *tasks* est√°n en la **Celda 4**; agrega m√°s tareas seg√∫n necesites."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7a4111",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "\n",
        "dev = torch.device(\"cuda:0\")\n",
        "m = nn.Conv1d(3, 16, kernel_size=7, padding=3).to(dev)\n",
        "x = torch.randn(4, 3, 2500, device=dev)\n",
        "y = m(x)\n",
        "(y.pow(2).mean()).backward()\n",
        "print(\"Conv1d forward/backward en\", dev, \"OK ‚úÖ\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
