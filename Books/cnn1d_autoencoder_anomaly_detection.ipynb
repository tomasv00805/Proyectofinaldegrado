{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü´Ä CNN1D Autoencoder para Detecci√≥n de Anomal√≠as en ECG\n",
        "\n",
        "Este notebook implementa un **Autoencoder 1D CNN** para detecci√≥n de anomal√≠as en se√±ales ECG mediante **entrenamiento no supervisado**.\n",
        "\n",
        "**Caracter√≠sticas principales:**\n",
        "- Arquitectura CNN pura: CNN1D encoder + CNN1D decoder (ConvTranspose1d o Upsampling)\n",
        "- Entrenamiento no supervisado: solo con ejemplos normales\n",
        "- Detecci√≥n de anomal√≠as mediante error de reconstrucci√≥n\n",
        "- Selecci√≥n autom√°tica de umbral de anomal√≠a\n",
        "- Evaluaci√≥n con m√©tricas de clasificaci√≥n (precision, recall, f1, etc.)\n",
        "- Datos preprocesados desde `Datos_no_supervisados/tensors_200hz` (archivos .pt)\n",
        "- Integraci√≥n con MLflow para tracking de experimentos\n",
        "- Orquestaci√≥n con Prefect 2.x\n",
        "- Soporte autom√°tico para GPU (RTX 5080 compatible)\n",
        "\n",
        "> ‚ö†Ô∏è **IMPORTANTE EN WINDOWS:** Ejecuta la celda de **Setup DLLs CUDA** (celda 2) **ANTES** de la celda de imports. Esto es necesario para que PyTorch pueda cargar las DLLs de CUDA correctamente.\n",
        "\n",
        "> ‚ñ∂Ô∏è **Instrucciones:** \n",
        "> 1. Ejecuta la celda de **Setup DLLs CUDA** primero\n",
        "> 2. Configura los par√°metros en la secci√≥n de **CONFIGURACI√ìN GENERAL**\n",
        "> 3. Ajusta la ruta `DATA_DIR` a tu carpeta de datos (debe apuntar a `Datos_no_supervisados/tensors_200hz`)\n",
        "> 4. Ejecuta todas las dem√°s celdas en orden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã √çndice\n",
        "\n",
        "1. **Setup CUDA y dependencias** - Configuraci√≥n de DLLs y librer√≠as\n",
        "2. **Configuraci√≥n general** - Imports, semillas, dispositivo, hiperpar√°metros\n",
        "3. **Carga y preparaci√≥n de datos** - Funciones para cargar desde `tensors_200hz` (filtrar normales para train)\n",
        "4. **Definici√≥n del modelo Autoencoder CNN1D** - Arquitectura encoder-decoder CNN\n",
        "5. **Funciones de entrenamiento y evaluaci√≥n** - Loops de entrenamiento y c√°lculo de error de reconstrucci√≥n\n",
        "6. **Integraci√≥n con MLflow** - Configuraci√≥n y logging\n",
        "7. **Orquestaci√≥n con Prefect** - Flujo principal con Prefect\n",
        "8. **Selecci√≥n de umbral de anomal√≠a** - Calcular umbral √≥ptimo\n",
        "9. **Evaluaci√≥n final** - Evaluar en validaci√≥n y test con umbral\n",
        "10. **Guardado de modelo** - Exportar modelo y umbral\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. ‚öôÔ∏è Setup CUDA y Dependencias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: c:\\Python311\\python.exe\n",
            "Working dir: S:\\Proyecto final\\Books\n",
            "DLL directories a√±adidos:\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\n",
            "  - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp\n",
            "‚è≥ Instalando mlflow>=2.16 ...\n",
            "‚è≥ Instalando prefect>=3 ...\n",
            "‚è≥ Instalando scikit-learn ...\n",
            "‚úî matplotlib ya instalado\n",
            "‚úî pandas ya instalado\n",
            "‚úî numpy ya instalado\n",
            "‚úî seaborn ya instalado\n",
            "‚úî ipywidgets ya instalado\n",
            "\n",
            "Torch info:\n",
            "  - torch_version: 2.10.0.dev20251124+cu128\n",
            "  - cuda_version: 12.8\n",
            "  - cuda_available: True\n",
            "GPU detectada: NVIDIA GeForce RTX 5080 | SM 120\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# üîß Setup RTX 5080 ‚Äî dependencias + CUDA DLL\n",
        "# Ejecuta una sola vez (o tras actualizar drivers/librer√≠as)\n",
        "# ========================================\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from textwrap import dedent\n",
        "\n",
        "print(f\"Python: {sys.executable}\")\n",
        "print(f\"Working dir: {Path.cwd().resolve()}\")\n",
        "\n",
        "# Rutas candidatas para DLLs de CUDA\n",
        "CUDA_CANDIDATES = [\n",
        "    os.environ.get(\"CUDA_PATH\"),\n",
        "    os.environ.get(\"CUDA_PATH_V12_8\"),\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\",\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\",\n",
        "    r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\libnvvp\",\n",
        "    r\"C:\\Program Files\\NVIDIA\\CUDNN\",\n",
        "]\n",
        "\n",
        "# A√±adir rutas DLL en Windows (necesario antes de importar torch)\n",
        "added = []\n",
        "if hasattr(os, \"add_dll_directory\"):\n",
        "    for candidate in CUDA_CANDIDATES:\n",
        "        if not candidate:\n",
        "            continue\n",
        "        path = Path(candidate)\n",
        "        if path.is_dir():\n",
        "            try:\n",
        "                os.add_dll_directory(str(path))\n",
        "                added.append(str(path))\n",
        "            except (FileNotFoundError, OSError):\n",
        "                pass\n",
        "\n",
        "if added:\n",
        "    print(\"DLL directories a√±adidos:\")\n",
        "    for path in added:\n",
        "        print(f\"  - {path}\")\n",
        "\n",
        "# Instalar dependencias base si no est√°n instaladas\n",
        "BASE_PACKAGES = [\n",
        "    \"mlflow>=2.16\",\n",
        "    \"prefect>=3\",\n",
        "    \"scikit-learn\",\n",
        "    \"matplotlib\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"seaborn\",\n",
        "    \"ipywidgets\",\n",
        "]\n",
        "\n",
        "def pip_install(spec: str) -> None:\n",
        "    module_name = spec.split(\"==\")[0].split(\"[\")[0].replace(\"-\", \"_\")\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        print(f\"‚úî {spec} ya instalado\")\n",
        "    except Exception:\n",
        "        print(f\"‚è≥ Instalando {spec} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", spec])\n",
        "\n",
        "for pkg in BASE_PACKAGES:\n",
        "    pip_install(pkg)\n",
        "\n",
        "# Comando para instalar PyTorch nightly con CUDA 12.8 (para RTX 5080)\n",
        "TORCH_INSTALL_CMD = [\n",
        "    sys.executable,\n",
        "    \"-m\",\n",
        "    \"pip\",\n",
        "    \"install\",\n",
        "    \"--upgrade\",\n",
        "    \"--pre\",\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"torchaudio\",\n",
        "    \"--index-url\",\n",
        "    \"https://download.pytorch.org/whl/nightly/cu128\",\n",
        "]\n",
        "\n",
        "def ensure_torch_cuda() -> \"tuple[object | None, dict]\":\n",
        "    \"\"\"Importa torch, o instala la nightly cu128 si hace falta.\"\"\"\n",
        "    info: dict[str, str | float | bool] = {}\n",
        "    try:\n",
        "        import torch  # type: ignore\n",
        "        info[\"torch_version\"] = getattr(torch, \"__version__\", \"desconocida\")\n",
        "        info[\"cuda_version\"] = getattr(getattr(torch, \"version\", object()), \"cuda\", \"desconocida\")\n",
        "        info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "        if \"cu128\" not in info[\"torch_version\"] and not str(info[\"cuda_version\"]).startswith(\"12.8\"):\n",
        "            raise RuntimeError(\n",
        "                f\"Build {info['torch_version']} no es cu128. Se reinstalar√° la nightly para RTX 5080.\"\n",
        "            )\n",
        "        return torch, info\n",
        "    except Exception as err:\n",
        "        print(\"‚ö†Ô∏è Torch no usable todav√≠a:\", err)\n",
        "        print(\"   Desinstalando PyTorch corrupto...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
        "        print(\"   Instalando nightly cu128 desde PyTorch (puede tardar).\")\n",
        "        subprocess.check_call(TORCH_INSTALL_CMD)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚ö†Ô∏è IMPORTANTE: PyTorch fue reinstalado.\")\n",
        "        print(\"   DEBES REINICIAR EL KERNEL DE JUPYTER ahora:\")\n",
        "        print(\"   Kernel ‚Üí Restart Kernel\")\n",
        "        print(\"   Luego ejecuta esta celda de nuevo.\")\n",
        "        print(\"=\"*60)\n",
        "        import importlib\n",
        "        import time\n",
        "        time.sleep(2)\n",
        "        importlib.invalidate_caches()\n",
        "        try:\n",
        "            import torch  # type: ignore\n",
        "            info[\"torch_version\"] = getattr(torch, \"__version__\", \"desconocida\")\n",
        "            info[\"cuda_version\"] = getattr(getattr(torch, \"version\", object()), \"cuda\", \"desconocida\")\n",
        "            info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "            return torch, info\n",
        "        except Exception as e2:\n",
        "            print(f\"\\n‚ùå No se pudo importar PyTorch despu√©s de reinstalar: {e2}\")\n",
        "            print(\"   Por favor, REINICIA EL KERNEL y ejecuta esta celda de nuevo.\")\n",
        "            raise RuntimeError(\"Reinicia el kernel de Jupyter y ejecuta esta celda de nuevo.\") from e2\n",
        "\n",
        "# Intentar importar/instalar PyTorch\n",
        "torch, torch_info = ensure_torch_cuda()\n",
        "\n",
        "print(\"\\nTorch info:\")\n",
        "for k, v in torch_info.items():\n",
        "    print(f\"  - {k}: {v}\")\n",
        "\n",
        "if torch_info.get(\"cuda_available\"):\n",
        "    try:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        cc = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU detectada: {gpu_name} | SM {cc.major}{cc.minor}\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è CUDA disponible pero no se pudo consultar GPU:\", e)\n",
        "else:\n",
        "    print(dedent(\n",
        "        \"\"\"\n",
        "        ‚ö†Ô∏è CUDA sigue inactiva. Revisa drivers / reinicia kernel tras la instalaci√≥n.\n",
        "        Si el problema contin√∫a, ejecuta manualmente:\n",
        "          pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
        "        \"\"\"\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Todos los imports completados\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Imports y dependencias\n",
        "# ========================================\n",
        "# ‚ö†Ô∏è IMPORTANTE: Ejecuta la celda anterior (Setup DLLs) antes de esta celda\n",
        "# torch ya est√° importado en la celda anterior\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch ya est√° importado en la celda anterior, solo importamos los subm√≥dulos\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        ")\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from prefect import task, flow\n",
        "from prefect.tasks import NO_CACHE\n",
        "\n",
        "# Instalar seaborn si no est√° disponible (para las visualizaciones)\n",
        "try:\n",
        "    import seaborn as sns\n",
        "except ImportError:\n",
        "    print(\"‚è≥ Instalando seaborn...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"])\n",
        "    import seaborn as sns\n",
        "    print(\"‚úì seaborn instalado\")\n",
        "\n",
        "print(\"‚úì Todos los imports completados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. ‚öôÔ∏è Configuraci√≥n General\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Configuraci√≥n cargada:\n",
            "{\n",
            "  \"DATA_DIR\": \"..\\\\data\\\\Datos_no_supervisados\\\\tensors_200hz\",\n",
            "  \"EXPERIMENT_NAME\": \"ecg_cnn_autoencoder\",\n",
            "  \"RUN_NAME\": \"cnn_ae_ecg_v1\",\n",
            "  \"OUTPUT_DIR\": \"outputs\",\n",
            "  \"N_CHANNELS\": 3,\n",
            "  \"SEQ_LEN\": 2000,\n",
            "  \"enc_out_channels\": [\n",
            "    16,\n",
            "    32,\n",
            "    64\n",
            "  ],\n",
            "  \"enc_kernel_sizes\": [\n",
            "    7,\n",
            "    5,\n",
            "    3\n",
            "  ],\n",
            "  \"enc_pool_sizes\": [\n",
            "    2,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"USE_BATCHNORM\": true,\n",
            "  \"CNN_ACTIVATION\": \"relu\",\n",
            "  \"dec_out_channels\": [\n",
            "    32,\n",
            "    16,\n",
            "    3\n",
            "  ],\n",
            "  \"dec_kernel_sizes\": [\n",
            "    5,\n",
            "    7,\n",
            "    7\n",
            "  ],\n",
            "  \"dec_upsample_sizes\": [\n",
            "    2,\n",
            "    2,\n",
            "    1\n",
            "  ],\n",
            "  \"LATENT_CHANNELS\": 64,\n",
            "  \"BATCH_SIZE\": 64,\n",
            "  \"LEARNING_RATE\": 0.001,\n",
            "  \"NUM_EPOCHS\": 50,\n",
            "  \"WEIGHT_DECAY\": 1e-05,\n",
            "  \"THRESHOLD_METHOD\": \"percentile\",\n",
            "  \"THRESHOLD_PERCENTILE\": 95,\n",
            "  \"SEED\": 42,\n",
            "  \"USE_CUDA\": true,\n",
            "  \"ENABLE_CUDNN_BENCHMARK\": true,\n",
            "  \"MLFLOW_TRACKING_URI\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# CONFIGURACI√ìN GENERAL\n",
        "# ========================================\n",
        "\n",
        "# --- Rutas y nombres ---\n",
        "DATA_DIR = Path(\"../data/Datos_no_supervisados/tensors_200hz\")  # TODO: cambiar por la carpeta donde est√°n los datos\n",
        "EXPERIMENT_NAME = \"ecg_cnn_autoencoder\"\n",
        "RUN_NAME = \"cnn_ae_ecg_v1\"\n",
        "OUTPUT_DIR = Path(\"./outputs\")                 # Directorio para guardar artefactos\n",
        "\n",
        "# --- Datos de entrada ---\n",
        "N_CHANNELS = 3           # cantidad de derivaciones / canales ECG\n",
        "SEQ_LEN = 2000           # TODO: timesteps por ejemplo (ej: 10 s a 200 Hz => 2000)\n",
        "\n",
        "# --- Arquitectura CNN Encoder ---\n",
        "# Cada entrada define una capa Conv1d:\n",
        "# - enc_out_channels[i]: filtros de la capa i\n",
        "# - enc_kernel_sizes[i]: tama√±o de kernel de la capa i\n",
        "# - enc_pool_sizes[i]: tama√±o del MaxPool1d posterior (si se usa)\n",
        "enc_out_channels = [16, 32, 64]   # TODO: ajustar filtros por capa\n",
        "enc_kernel_sizes = [7, 5, 3]      # TODO: ajustar tama√±os de kernel\n",
        "enc_pool_sizes = [2, 2, 2]        # TODO: ajustar factor de pooling por capa (o None si no se usa)\n",
        "\n",
        "USE_BATCHNORM = True              # aplicar BatchNorm1d despu√©s de cada conv\n",
        "CNN_ACTIVATION = \"relu\"           # usar ReLU\n",
        "\n",
        "# --- Arquitectura CNN Decoder ---\n",
        "# Intentar espejo del encoder (se puede usar ConvTranspose1d o upsampling + Conv1d).\n",
        "dec_out_channels = [32, 16, N_CHANNELS]   # TODO: espejo del encoder hacia N_CHANNELS\n",
        "dec_kernel_sizes = [5, 7, 7]             # TODO: tama√±os de kernel para decoder\n",
        "dec_upsample_sizes = [2, 2, 1]           # factores de upsampling (√∫ltimo puede ser 1)\n",
        "\n",
        "# --- Representaci√≥n intermedia ---\n",
        "LATENT_CHANNELS = 64      # canales en la capa m√°s profunda (coincide normalmente con enc_out_channels[-1])\n",
        "\n",
        "# --- Entrenamiento ---\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 50\n",
        "WEIGHT_DECAY = 1e-5       # regularizaci√≥n L2 (0.0 si no se quiere)\n",
        "\n",
        "# --- Umbral de anomal√≠a ---\n",
        "THRESHOLD_METHOD = \"percentile\"   # p.ej. \"percentile\" o \"mean_std\"\n",
        "THRESHOLD_PERCENTILE = 95         # si se usa m√©todo percentil, ej. 95 o 99\n",
        "\n",
        "# --- Otros ---\n",
        "SEED = 42\n",
        "USE_CUDA = True             # si hay GPU disponible, usarla\n",
        "ENABLE_CUDNN_BENCHMARK = True\n",
        "\n",
        "# --- MLflow ---\n",
        "MLFLOW_TRACKING_URI = None  # None = usa el directorio local (sqlite:///mlflow.db)\n",
        "\n",
        "# Crear directorio de salida\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Diccionario de configuraci√≥n (para pasar a funciones)\n",
        "CONFIG = {\n",
        "    \"DATA_DIR\": DATA_DIR,\n",
        "    \"EXPERIMENT_NAME\": EXPERIMENT_NAME,\n",
        "    \"RUN_NAME\": RUN_NAME,\n",
        "    \"OUTPUT_DIR\": OUTPUT_DIR,\n",
        "    \"N_CHANNELS\": N_CHANNELS,\n",
        "    \"SEQ_LEN\": SEQ_LEN,\n",
        "    \"enc_out_channels\": enc_out_channels,\n",
        "    \"enc_kernel_sizes\": enc_kernel_sizes,\n",
        "    \"enc_pool_sizes\": enc_pool_sizes,\n",
        "    \"USE_BATCHNORM\": USE_BATCHNORM,\n",
        "    \"CNN_ACTIVATION\": CNN_ACTIVATION,\n",
        "    \"dec_out_channels\": dec_out_channels,\n",
        "    \"dec_kernel_sizes\": dec_kernel_sizes,\n",
        "    \"dec_upsample_sizes\": dec_upsample_sizes,\n",
        "    \"LATENT_CHANNELS\": LATENT_CHANNELS,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"LEARNING_RATE\": LEARNING_RATE,\n",
        "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
        "    \"WEIGHT_DECAY\": WEIGHT_DECAY,\n",
        "    \"THRESHOLD_METHOD\": THRESHOLD_METHOD,\n",
        "    \"THRESHOLD_PERCENTILE\": THRESHOLD_PERCENTILE,\n",
        "    \"SEED\": SEED,\n",
        "    \"USE_CUDA\": USE_CUDA,\n",
        "    \"ENABLE_CUDNN_BENCHMARK\": ENABLE_CUDNN_BENCHMARK,\n",
        "    \"MLFLOW_TRACKING_URI\": MLFLOW_TRACKING_URI,\n",
        "}\n",
        "\n",
        "print(\"‚úì Configuraci√≥n cargada:\")\n",
        "print(json.dumps({k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()}, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì cuDNN Benchmark: Habilitado\n",
            "‚úì Semilla fijada: 42\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Configuraci√≥n de semillas aleatorias y optimizaciones GPU\n",
        "# ========================================\n",
        "def set_seed_everywhere(seed: int = 42, enable_cudnn_benchmark: bool = True) -> None:\n",
        "    \"\"\"Fija semillas para reproducibilidad y optimiza GPU.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.benchmark = enable_cudnn_benchmark\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"‚úì cuDNN Benchmark: {'Habilitado' if enable_cudnn_benchmark else 'Deshabilitado'}\")\n",
        "\n",
        "set_seed_everywhere(SEED, enable_cudnn_benchmark=CONFIG.get(\"ENABLE_CUDNN_BENCHMARK\", True))\n",
        "print(f\"‚úì Semilla fijada: {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì GPU detectada: NVIDIA GeForce RTX 5080\n",
            "  CUDA Version: 12.8\n",
            "  PyTorch Version: 2.10.0.dev20251124+cu128\n",
            "Dispositivo seleccionado: cuda\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Configuraci√≥n de dispositivo (GPU/CPU)\n",
        "# ========================================\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"Detecta y configura el dispositivo (GPU si est√° disponible).\"\"\"\n",
        "    if USE_CUDA and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"‚úì GPU detectada: {gpu_name}\")\n",
        "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"  PyTorch Version: {torch.__version__}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"‚ö† GPU no disponible, usando CPU\")\n",
        "    return device\n",
        "\n",
        "DEVICE = get_device()\n",
        "print(f\"Dispositivo seleccionado: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. üìÇ Carga y Preparaci√≥n de Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Funci√≥n para cargar datos desde tensors_200hz (archivos .pt)\n",
        "# IMPORTANTE: Para entrenamiento solo usamos ejemplos normales (y == 0)\n",
        "# ========================================\n",
        "def load_tensor_data(\n",
        "    data_dir: Path,\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Carga los datos desde archivos .pt en tensors_200hz.\n",
        "    \n",
        "    Para entrenamiento: solo ejemplos normales (y == 0)\n",
        "    Para validaci√≥n y test: todos los ejemplos (normales y an√≥malos)\n",
        "    \n",
        "    Args:\n",
        "        data_dir: Ruta a la carpeta tensors_200hz\n",
        "        \n",
        "    Returns:\n",
        "        Tuple con (X_train_normals, y_train_normals, X_val, y_val, X_test, y_test)\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"üìÇ CARGANDO DATOS DESDE tensors_200hz\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Directorio: {data_dir.resolve()}\")\n",
        "    \n",
        "    # Cargar tensors\n",
        "    print(\"\\n‚è≥ Cargando tensors desde disco...\")\n",
        "    X_train = torch.load(data_dir / \"X_train.pt\", map_location='cpu')\n",
        "    y_train = torch.load(data_dir / \"y_train.pt\", map_location='cpu')\n",
        "    X_val = torch.load(data_dir / \"X_val.pt\", map_location='cpu')\n",
        "    y_val = torch.load(data_dir / \"y_val.pt\", map_location='cpu')\n",
        "    X_test = torch.load(data_dir / \"X_test.pt\", map_location='cpu')\n",
        "    y_test = torch.load(data_dir / \"y_test.pt\", map_location='cpu')\n",
        "    \n",
        "    # Filtrar solo normales para entrenamiento (y == 0)\n",
        "    print(\"\\nüîç Filtrando datos de entrenamiento (solo normales)...\")\n",
        "    normal_mask = (y_train == 0)\n",
        "    X_train_normals = X_train[normal_mask]\n",
        "    y_train_normals = y_train[normal_mask]\n",
        "    \n",
        "    print(f\"\\n‚úì Datos cargados:\")\n",
        "    print(f\"  X_train (normales): {X_train_normals.shape} | y_train: {y_train_normals.shape} (todos normales: {(y_train_normals==0).sum().item()})\")\n",
        "    print(f\"  X_val:   {X_val.shape} | y_val:   {y_val.shape} (normales: {(y_val==0).sum().item()}, an√≥malos: {(y_val==1).sum().item()})\")\n",
        "    print(f\"  X_test:  {X_test.shape} | y_test:  {y_test.shape} (normales: {(y_test==0).sum().item()}, an√≥malos: {(y_test==1).sum().item()})\")\n",
        "    \n",
        "    # Verificar que las features coincidan con CONFIG\n",
        "    if X_train_normals.shape[-1] != CONFIG[\"N_CHANNELS\"]:\n",
        "        print(f\"‚ö†Ô∏è ADVERTENCIA: X_train tiene {X_train_normals.shape[-1]} canales, pero N_CHANNELS={CONFIG['N_CHANNELS']}\")\n",
        "        print(f\"   Ajustando N_CHANNELS a {X_train_normals.shape[-1]}\")\n",
        "        CONFIG[\"N_CHANNELS\"] = X_train_normals.shape[-1]\n",
        "    \n",
        "    # Verificar SEQ_LEN\n",
        "    if len(X_train_normals.shape) >= 2 and X_train_normals.shape[1] != CONFIG[\"SEQ_LEN\"]:\n",
        "        print(f\"‚ö†Ô∏è ADVERTENCIA: X_train tiene {X_train_normals.shape[1]} timesteps, pero SEQ_LEN={CONFIG['SEQ_LEN']}\")\n",
        "        print(f\"   Ajustando SEQ_LEN a {X_train_normals.shape[1]}\")\n",
        "        CONFIG[\"SEQ_LEN\"] = X_train_normals.shape[1]\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return X_train_normals, y_train_normals, X_val, y_val, X_test, y_test\n",
        "\n",
        "\n",
        "def create_dataloaders_from_tensors(\n",
        "    X_train: torch.Tensor,\n",
        "    y_train: torch.Tensor,\n",
        "    X_val: torch.Tensor,\n",
        "    y_val: torch.Tensor,\n",
        "    X_test: torch.Tensor,\n",
        "    y_test: torch.Tensor,\n",
        "    batch_size: int,\n",
        "    shuffle_train: bool = True,\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Crea DataLoaders desde tensors.\n",
        "    \n",
        "    Returns:\n",
        "        Tuple con (train_loader, val_loader, test_loader)\n",
        "    \"\"\"\n",
        "    # Crear datasets\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    val_dataset = TensorDataset(X_val, y_val)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    \n",
        "    # Crear dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_train,\n",
        "        num_workers=0,  # 0 para Windows\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úì DataLoaders creados:\")\n",
        "    print(f\"  Train: {len(train_loader)} batches ({len(train_dataset)} muestras)\")\n",
        "    print(f\"  Val:   {len(val_loader)} batches ({len(val_dataset)} muestras)\")\n",
        "    print(f\"  Test:  {len(test_loader)} batches ({len(test_dataset)} muestras)\")\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. üß† Definici√≥n del Modelo Autoencoder CNN1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Clase Autoencoder CNN1D\n",
        "# ========================================\n",
        "class CNN1D_Autoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder 1D CNN para reconstrucci√≥n de series temporales ECG.\n",
        "    \n",
        "    Arquitectura:\n",
        "    - Encoder: CNN1D con pooling\n",
        "    - Decoder: CNN1D con upsampling (ConvTranspose1d o Upsample + Conv1d)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        n_channels: int,\n",
        "        seq_len: int,\n",
        "        enc_out_channels: List[int],\n",
        "        enc_kernel_sizes: List[int],\n",
        "        enc_pool_sizes: List[int],\n",
        "        dec_out_channels: List[int],\n",
        "        dec_kernel_sizes: List[int],\n",
        "        dec_upsample_sizes: List[int],\n",
        "        use_batchnorm: bool = True,\n",
        "        cnn_activation: str = \"relu\",\n",
        "        latent_channels: int = 64,\n",
        "    ):\n",
        "        super(CNN1D_Autoencoder, self).__init__()\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.seq_len = seq_len\n",
        "        self.enc_out_channels = enc_out_channels\n",
        "        self.dec_out_channels = dec_out_channels\n",
        "        self.num_enc_layers = len(enc_out_channels)\n",
        "        self.num_dec_layers = len(dec_out_channels)\n",
        "        self.latent_channels = latent_channels\n",
        "        \n",
        "        # ========================================\n",
        "        # Encoder: CNN1D\n",
        "        # ========================================\n",
        "        encoder_layers = []\n",
        "        in_channels = n_channels\n",
        "        \n",
        "        for i in range(self.num_enc_layers):\n",
        "            # Conv1d\n",
        "            encoder_layers.append(\n",
        "                nn.Conv1d(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=enc_out_channels[i],\n",
        "                    kernel_size=enc_kernel_sizes[i],\n",
        "                    padding=(enc_kernel_sizes[i] - 1) // 2,  # padding 'same'\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            # BatchNorm (si est√° habilitado)\n",
        "            if use_batchnorm:\n",
        "                encoder_layers.append(nn.BatchNorm1d(enc_out_channels[i]))\n",
        "            \n",
        "            # Activaci√≥n\n",
        "            if cnn_activation.lower() == \"relu\":\n",
        "                encoder_layers.append(nn.ReLU())\n",
        "            elif cnn_activation.lower() == \"leakyrelu\":\n",
        "                encoder_layers.append(nn.LeakyReLU(0.1))\n",
        "            else:\n",
        "                raise ValueError(f\"Activaci√≥n {cnn_activation} no soportada\")\n",
        "            \n",
        "            # MaxPool (si est√° definido)\n",
        "            if enc_pool_sizes[i] is not None and enc_pool_sizes[i] > 1:\n",
        "                encoder_layers.append(nn.MaxPool1d(kernel_size=enc_pool_sizes[i]))\n",
        "            \n",
        "            in_channels = enc_out_channels[i]\n",
        "        \n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        \n",
        "        # Calcular tama√±o de salida del encoder despu√©s del pooling\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, n_channels, seq_len)\n",
        "            encoder_output = self.encoder(dummy_input)\n",
        "            # encoder_output shape: (batch, out_channels, seq_len_reduced)\n",
        "            self.encoded_seq_len = encoder_output.shape[2]\n",
        "            self.encoded_channels = encoder_output.shape[1]\n",
        "        \n",
        "        # Asegurar que el √∫ltimo canal del encoder coincide con latent_channels\n",
        "        if self.encoded_channels != latent_channels:\n",
        "            # Agregar una capa de proyecci√≥n\n",
        "            self.latent_projection = nn.Conv1d(\n",
        "                in_channels=self.encoded_channels,\n",
        "                out_channels=latent_channels,\n",
        "                kernel_size=1,\n",
        "            )\n",
        "            self.encoded_channels = latent_channels\n",
        "        else:\n",
        "            self.latent_projection = nn.Identity()\n",
        "        \n",
        "        # ========================================\n",
        "        # Decoder: CNN1D\n",
        "        # ========================================\n",
        "        decoder_layers = []\n",
        "        decoder_in_channels = latent_channels\n",
        "        \n",
        "        for i in range(self.num_dec_layers):\n",
        "            # Upsampling (si est√° definido)\n",
        "            if dec_upsample_sizes[i] is not None and dec_upsample_sizes[i] > 1:\n",
        "                # Opci√≥n 1: ConvTranspose1d (m√°s com√∫n)\n",
        "                decoder_layers.append(\n",
        "                    nn.ConvTranspose1d(\n",
        "                        in_channels=decoder_in_channels,\n",
        "                        out_channels=decoder_in_channels,\n",
        "                        kernel_size=dec_upsample_sizes[i],\n",
        "                        stride=dec_upsample_sizes[i],\n",
        "                        padding=0,\n",
        "                        output_padding=0,\n",
        "                    )\n",
        "                )\n",
        "            \n",
        "            # Conv1d\n",
        "            decoder_layers.append(\n",
        "                nn.Conv1d(\n",
        "                    in_channels=decoder_in_channels,\n",
        "                    out_channels=dec_out_channels[i],\n",
        "                    kernel_size=dec_kernel_sizes[i],\n",
        "                    padding=(dec_kernel_sizes[i] - 1) // 2,  # padding 'same'\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            # BatchNorm (si est√° habilitado)\n",
        "            if use_batchnorm and i < self.num_dec_layers - 1:  # No BatchNorm en la √∫ltima capa\n",
        "                decoder_layers.append(nn.BatchNorm1d(dec_out_channels[i]))\n",
        "            \n",
        "            # Activaci√≥n (tanh en la √∫ltima capa para normalizar salida)\n",
        "            if i == self.num_dec_layers - 1:\n",
        "                decoder_layers.append(nn.Tanh())\n",
        "            else:\n",
        "                if cnn_activation.lower() == \"relu\":\n",
        "                    decoder_layers.append(nn.ReLU())\n",
        "                elif cnn_activation.lower() == \"leakyrelu\":\n",
        "                    decoder_layers.append(nn.LeakyReLU(0.1))\n",
        "            \n",
        "            decoder_in_channels = dec_out_channels[i]\n",
        "        \n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "        \n",
        "        # Ajustar tama√±o final si es necesario\n",
        "        with torch.no_grad():\n",
        "            dummy_latent = torch.zeros(1, latent_channels, self.encoded_seq_len)\n",
        "            decoder_output = self.decoder(dummy_latent)\n",
        "            if decoder_output.shape[2] != seq_len:\n",
        "                # Agregar capa de ajuste final\n",
        "                final_scale = seq_len / decoder_output.shape[2]\n",
        "                if abs(final_scale - 1.0) > 0.01:\n",
        "                    self.final_adjust = nn.Upsample(size=seq_len, mode='linear', align_corners=False)\n",
        "                else:\n",
        "                    self.final_adjust = nn.Identity()\n",
        "            else:\n",
        "                self.final_adjust = nn.Identity()\n",
        "        \n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encoder: x -> representaci√≥n latente\n",
        "        \n",
        "        Args:\n",
        "            x: Tensor de forma (batch_size, seq_len, n_channels) o (batch_size, n_channels, seq_len)\n",
        "        \n",
        "        Returns:\n",
        "            Tensor de forma (batch_size, latent_channels, encoded_seq_len)\n",
        "        \"\"\"\n",
        "        # Asegurar que x tiene forma (batch_size, n_channels, seq_len) para Conv1d\n",
        "        if len(x.shape) == 3 and x.shape[1] == self.seq_len and x.shape[2] == self.n_channels:\n",
        "            # Forma (batch, seq_len, channels) -> transponer a (batch, channels, seq_len)\n",
        "            x = x.transpose(1, 2)\n",
        "        \n",
        "        # Encoder CNN1D\n",
        "        encoded = self.encoder(x)  # (batch, encoded_channels, encoded_seq_len)\n",
        "        encoded = self.latent_projection(encoded)  # (batch, latent_channels, encoded_seq_len)\n",
        "        \n",
        "        return encoded\n",
        "    \n",
        "    def decode(self, latent: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Decoder: representaci√≥n latente -> reconstrucci√≥n\n",
        "        \n",
        "        Args:\n",
        "            latent: Tensor de forma (batch_size, latent_channels, encoded_seq_len)\n",
        "        \n",
        "        Returns:\n",
        "            Tensor de forma (batch_size, n_channels, seq_len)\n",
        "        \"\"\"\n",
        "        # Decoder CNN1D\n",
        "        decoded = self.decoder(latent)  # (batch, n_channels, seq_len_approx)\n",
        "        decoded = self.final_adjust(decoded)  # Ajustar a seq_len exacto\n",
        "        \n",
        "        return decoded\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass completo: encode -> decode\n",
        "        \n",
        "        Args:\n",
        "            x: Tensor de forma (batch_size, seq_len, n_channels) o (batch_size, n_channels, seq_len)\n",
        "        \n",
        "        Returns:\n",
        "            Tensor reconstruido de forma (batch_size, seq_len, n_channels)\n",
        "        \"\"\"\n",
        "        # Asegurar formato (batch, channels, seq_len) para el encoder\n",
        "        original_shape = x.shape\n",
        "        if len(original_shape) == 3 and original_shape[1] == self.seq_len and original_shape[2] == self.n_channels:\n",
        "            x = x.transpose(1, 2)  # (batch, channels, seq_len)\n",
        "        \n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)  # (batch, channels, seq_len)\n",
        "        \n",
        "        # Transponer de vuelta a (batch, seq_len, channels)\n",
        "        reconstructed = reconstructed.transpose(1, 2)\n",
        "        \n",
        "        return reconstructed\n",
        "    \n",
        "    def get_reconstruction_error(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calcula el error de reconstrucci√≥n (MSE) para cada muestra.\n",
        "        \n",
        "        Args:\n",
        "            x: Tensor de forma (batch_size, seq_len, n_channels)\n",
        "        \n",
        "        Returns:\n",
        "            Tensor de forma (batch_size,) con el error de reconstrucci√≥n por muestra\n",
        "        \"\"\"\n",
        "        reconstructed = self.forward(x)\n",
        "        # Calcular MSE por muestra\n",
        "        mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))  # (batch_size,)\n",
        "        return mse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Instanciar modelo\n",
        "# ========================================\n",
        "def create_model(config: Dict) -> CNN1D_Autoencoder:\n",
        "    \"\"\"Crea e instancia el modelo Autoencoder CNN1D.\"\"\"\n",
        "    model = CNN1D_Autoencoder(\n",
        "        n_channels=config[\"N_CHANNELS\"],\n",
        "        seq_len=config[\"SEQ_LEN\"],\n",
        "        enc_out_channels=config[\"enc_out_channels\"],\n",
        "        enc_kernel_sizes=config[\"enc_kernel_sizes\"],\n",
        "        enc_pool_sizes=config[\"enc_pool_sizes\"],\n",
        "        dec_out_channels=config[\"dec_out_channels\"],\n",
        "        dec_kernel_sizes=config[\"dec_kernel_sizes\"],\n",
        "        dec_upsample_sizes=config[\"dec_upsample_sizes\"],\n",
        "        use_batchnorm=config[\"USE_BATCHNORM\"],\n",
        "        cnn_activation=config[\"CNN_ACTIVATION\"],\n",
        "        latent_channels=config[\"LATENT_CHANNELS\"],\n",
        "    )\n",
        "    \n",
        "    # Contar par√°metros\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    print(f\"‚úì Modelo creado:\")\n",
        "    print(f\"  Par√°metros totales: {total_params:,} ({total_params / 1e6:.2f}M)\")\n",
        "    print(f\"  Par√°metros entrenables: {trainable_params:,}\")\n",
        "    print(f\"  Encoded shape: (batch, {model.encoded_channels}, {model.encoded_seq_len})\")\n",
        "    print(f\"  Latent channels: {config['LATENT_CHANNELS']}\")\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. üèãÔ∏è Funciones de Entrenamiento y Evaluaci√≥n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. üìä Integraci√≥n con MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Funci√≥n de entrenamiento por √©poca\n",
        "# ========================================\n",
        "def train_one_epoch(\n",
        "    model: CNN1D_Autoencoder,\n",
        "    train_loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Entrena el modelo por una √©poca (reconstrucci√≥n).\n",
        "    \n",
        "    Returns:\n",
        "        loss_promedio\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_x, _ in train_loader:  # Ignorar labels en entrenamiento no supervisado\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        \n",
        "        # Forward pass: reconstrucci√≥n\n",
        "        reconstructed = model(batch_x)\n",
        "        \n",
        "        # Calcular p√©rdida (MSE entre original y reconstruido)\n",
        "        loss = criterion(reconstructed, batch_x)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Acumular m√©tricas\n",
        "        total_loss += loss.item() * batch_x.size(0)\n",
        "        total += batch_x.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / total if total > 0 else 0.0\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Funci√≥n de evaluaci√≥n (reconstrucci√≥n)\n",
        "# ========================================\n",
        "def evaluate_reconstruction(\n",
        "    model: CNN1D_Autoencoder,\n",
        "    dataloader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> Tuple[float, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Eval√∫a el modelo en un dataloader (reconstrucci√≥n).\n",
        "    \n",
        "    Returns:\n",
        "        Tupla con (loss_promedio, errores_reconstrucci√≥n)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total = 0\n",
        "    \n",
        "    all_errors = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, _ in dataloader:\n",
        "            batch_x = batch_x.to(device, non_blocking=True)\n",
        "            \n",
        "            # Forward pass: reconstrucci√≥n\n",
        "            reconstructed = model(batch_x)\n",
        "            loss = criterion(reconstructed, batch_x)\n",
        "            \n",
        "            # Calcular error de reconstrucci√≥n por muestra\n",
        "            errors = model.get_reconstruction_error(batch_x)\n",
        "            all_errors.append(errors.cpu().numpy())\n",
        "            \n",
        "            # Acumular m√©tricas\n",
        "            total_loss += loss.item() * batch_x.size(0)\n",
        "            total += batch_x.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / total if total > 0 else 0.0\n",
        "    all_errors = np.concatenate(all_errors)\n",
        "    \n",
        "    return avg_loss, all_errors\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Funci√≥n para calcular m√©tricas de clasificaci√≥n desde errores de reconstrucci√≥n\n",
        "# ========================================\n",
        "def compute_metrics_from_errors(\n",
        "    reconstruction_errors: np.ndarray,\n",
        "    y_true: np.ndarray,\n",
        "    threshold: float,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas de clasificaci√≥n usando errores de reconstrucci√≥n y un umbral.\n",
        "    \n",
        "    Args:\n",
        "        reconstruction_errors: Array con errores de reconstrucci√≥n (1D)\n",
        "        y_true: Array con etiquetas verdaderas (0=normal, 1=an√≥malo)\n",
        "        threshold: Umbral para clasificar anomal√≠as\n",
        "    \n",
        "    Returns:\n",
        "        Diccionario con m√©tricas\n",
        "    \"\"\"\n",
        "    # Predicciones: error > threshold => an√≥malo (1)\n",
        "    y_pred = (reconstruction_errors > threshold).astype(int)\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    \n",
        "    # Matriz de confusi√≥n\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    if cm.size == 4:\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        specificity = tn / max(1, tn + fp)  # TNR\n",
        "        sensitivity = tp / max(1, tp + fn)   # TPR\n",
        "    else:\n",
        "        specificity = 0.0\n",
        "        sensitivity = 0.0\n",
        "    \n",
        "    # ROC AUC (opcional, requiere probabilidades)\n",
        "    try:\n",
        "        # Usar errores normalizados como \"probabilidades\"\n",
        "        errors_normalized = (reconstruction_errors - reconstruction_errors.min()) / (reconstruction_errors.max() - reconstruction_errors.min() + 1e-8)\n",
        "        roc_auc = roc_auc_score(y_true, errors_normalized)\n",
        "    except:\n",
        "        roc_auc = 0.0\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"specificity\": specificity,\n",
        "        \"sensitivity\": sensitivity,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Configuraci√≥n de MLflow\n",
        "# ========================================\n",
        "def setup_mlflow(config: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Configura MLflow y crea/obtiene el experimento.\n",
        "    \n",
        "    Returns:\n",
        "        ID del experimento\n",
        "    \"\"\"\n",
        "    # Configurar tracking URI\n",
        "    if config.get(\"MLFLOW_TRACKING_URI\") is not None:\n",
        "        mlflow.set_tracking_uri(config[\"MLFLOW_TRACKING_URI\"])\n",
        "    else:\n",
        "        # Usar sqlite en el directorio padre\n",
        "        PARENT_DIR = Path.cwd().parent.resolve()\n",
        "        TRACKING_DB = (PARENT_DIR / \"mlflow.db\").resolve()\n",
        "        mlflow.set_tracking_uri(f\"sqlite:///{TRACKING_DB.as_posix()}\")\n",
        "        print(f\"‚úì MLflow tracking URI: sqlite:///{TRACKING_DB.as_posix()}\")\n",
        "    \n",
        "    # Crear o obtener experimento\n",
        "    experiment_name = config[\"EXPERIMENT_NAME\"]\n",
        "    \n",
        "    try:\n",
        "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "        if experiment is None:\n",
        "            # Crear directorio de artefactos\n",
        "            PARENT_DIR = Path.cwd().parent.resolve()\n",
        "            ARTIFACT_ROOT = (PARENT_DIR / \"mlflow_artifacts\").resolve()\n",
        "            ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "            experiment_id = mlflow.create_experiment(experiment_name, artifact_location=ARTIFACT_ROOT.as_uri())\n",
        "            print(f\"‚úì Experimento MLflow creado: {experiment_name} (ID: {experiment_id})\")\n",
        "            print(f\"  Artifact root: {ARTIFACT_ROOT.as_uri()}\")\n",
        "        else:\n",
        "            experiment_id = experiment.experiment_id\n",
        "            print(f\"‚úì Experimento MLflow existente: {experiment_name} (ID: {experiment_id})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Error al configurar MLflow: {e}\")\n",
        "        experiment_id = mlflow.set_experiment(experiment_name)\n",
        "    \n",
        "    return experiment_id\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Funci√≥n para guardar matriz de confusi√≥n\n",
        "# ========================================\n",
        "def save_confusion_matrix(\n",
        "    cm: np.ndarray,\n",
        "    output_dir: Path,\n",
        "    tag: str,\n",
        ") -> Tuple[Path, Path]:\n",
        "    \"\"\"\n",
        "    Guarda la matriz de confusi√≥n como PNG y CSV.\n",
        "    \n",
        "    Returns:\n",
        "        Tupla con rutas (png_path, csv_path)\n",
        "    \"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Guardar como CSV\n",
        "    csv_path = output_dir / f\"confusion_matrix_{tag}.csv\"\n",
        "    df_cm = pd.DataFrame(cm, index=[\"Normal\", \"An√≥malo\"], columns=[\"Normal\", \"An√≥malo\"])\n",
        "    df_cm.to_csv(csv_path)\n",
        "    \n",
        "    # Guardar como PNG\n",
        "    png_path = output_dir / f\"confusion_matrix_{tag}.png\"\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=[\"Normal\", \"An√≥malo\"],\n",
        "                yticklabels=[\"Normal\", \"An√≥malo\"])\n",
        "    ax.set_xlabel(\"Predicci√≥n\")\n",
        "    ax.set_ylabel(\"Real\")\n",
        "    ax.set_title(f\"Matriz de Confusi√≥n - {tag}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    return png_path, csv_path\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Funci√≥n para guardar curvas de entrenamiento\n",
        "# ========================================\n",
        "def save_training_curves(\n",
        "    train_losses: List[float],\n",
        "    val_losses: List[float],\n",
        "    output_dir: Path,\n",
        ") -> Path:\n",
        "    \"\"\"Guarda las curvas de entrenamiento.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    ax.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
        "    ax.plot(epochs, val_losses, 'r-', label='Val Loss', linewidth=2)\n",
        "    ax.set_xlabel('√âpoca')\n",
        "    ax.set_ylabel('Loss (MSE)')\n",
        "    ax.set_title('Curvas de Entrenamiento - Autoencoder CNN1D')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    curves_path = output_dir / \"training_curves.png\"\n",
        "    plt.savefig(curves_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    return curves_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Funci√≥n para seleccionar umbral de anomal√≠a\n",
        "# ========================================\n",
        "def select_threshold(\n",
        "    reconstruction_errors: np.ndarray,\n",
        "    method: str = \"percentile\",\n",
        "    percentile: float = 95.0,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Selecciona un umbral de anomal√≠a basado en errores de reconstrucci√≥n.\n",
        "    \n",
        "    Args:\n",
        "        reconstruction_errors: Array con errores de reconstrucci√≥n\n",
        "        method: M√©todo para seleccionar umbral (\"percentile\" o \"mean_std\")\n",
        "        percentile: Percentil a usar si method=\"percentile\"\n",
        "    \n",
        "    Returns:\n",
        "        Umbral seleccionado\n",
        "    \"\"\"\n",
        "    if method == \"percentile\":\n",
        "        threshold = np.percentile(reconstruction_errors, percentile)\n",
        "        print(f\"‚úì Umbral seleccionado (percentil {percentile}): {threshold:.6f}\")\n",
        "    elif method == \"mean_std\":\n",
        "        mean = np.mean(reconstruction_errors)\n",
        "        std = np.std(reconstruction_errors)\n",
        "        threshold = mean + 2 * std  # 2 desviaciones est√°ndar\n",
        "        print(f\"‚úì Umbral seleccionado (mean + 2*std): {threshold:.6f}\")\n",
        "    else:\n",
        "        raise ValueError(f\"M√©todo {method} no soportado\")\n",
        "    \n",
        "    return threshold\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Tarea Prefect: Cargar datos\n",
        "# ========================================\n",
        "@task(name=\"load_data\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_load_data(config: Dict) -> Tuple[DataLoader, DataLoader, DataLoader, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Tarea Prefect para cargar datos.\"\"\"\n",
        "    print(\"üìÇ Cargando datos...\")\n",
        "    X_train_normals, y_train_normals, X_val, y_val, X_test, y_test = load_tensor_data(config[\"DATA_DIR\"])\n",
        "    \n",
        "    train_loader, val_loader, test_loader = create_dataloaders_from_tensors(\n",
        "        X_train_normals, y_train_normals, X_val, y_val, X_test, y_test,\n",
        "        batch_size=config[\"BATCH_SIZE\"],\n",
        "        shuffle_train=True,\n",
        "    )\n",
        "    \n",
        "    return train_loader, val_loader, test_loader, y_val, y_test\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Tarea Prefect: Entrenar modelo\n",
        "# ========================================\n",
        "@task(name=\"train_model\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_train_model(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    config: Dict,\n",
        "    experiment_id: str,\n",
        ") -> Tuple[CNN1D_Autoencoder, List[float], List[float], np.ndarray]:\n",
        "    \"\"\"Tarea Prefect para entrenar el modelo.\"\"\"\n",
        "    print(\"üß† Creando modelo...\")\n",
        "    model = create_model(config)\n",
        "    model = model.to(device)\n",
        "    print(f\"  ‚úì Modelo en {device}\")\n",
        "    \n",
        "    # Optimizador y criterio\n",
        "    print(f\"  üîÑ Inicializando optimizador y criterio...\")\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config[\"LEARNING_RATE\"],\n",
        "        weight_decay=config[\"WEIGHT_DECAY\"],\n",
        "    )\n",
        "    criterion = nn.MSELoss()\n",
        "    print(f\"  ‚úì Optimizador y criterio listos\")\n",
        "    \n",
        "    # Listas para tracking\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    \n",
        "    # Iniciar run de MLflow\n",
        "    print(f\"  üîÑ Iniciando run de MLflow...\")\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=config[\"RUN_NAME\"]):\n",
        "        print(f\"  ‚úì Run de MLflow iniciado\")\n",
        "        \n",
        "        # Log hiperpar√°metros\n",
        "        print(f\"  üîÑ Loggeando hiperpar√°metros en MLflow...\")\n",
        "        mlflow.log_params({\n",
        "            \"n_channels\": config[\"N_CHANNELS\"],\n",
        "            \"seq_len\": config[\"SEQ_LEN\"],\n",
        "            \"enc_out_channels\": str(config[\"enc_out_channels\"]),\n",
        "            \"enc_kernel_sizes\": str(config[\"enc_kernel_sizes\"]),\n",
        "            \"enc_pool_sizes\": str(config[\"enc_pool_sizes\"]),\n",
        "            \"dec_out_channels\": str(config[\"dec_out_channels\"]),\n",
        "            \"dec_kernel_sizes\": str(config[\"dec_kernel_sizes\"]),\n",
        "            \"dec_upsample_sizes\": str(config[\"dec_upsample_sizes\"]),\n",
        "            \"use_batchnorm\": config[\"USE_BATCHNORM\"],\n",
        "            \"cnn_activation\": config[\"CNN_ACTIVATION\"],\n",
        "            \"latent_channels\": config[\"LATENT_CHANNELS\"],\n",
        "            \"batch_size\": config[\"BATCH_SIZE\"],\n",
        "            \"learning_rate\": config[\"LEARNING_RATE\"],\n",
        "            \"num_epochs\": config[\"NUM_EPOCHS\"],\n",
        "            \"weight_decay\": config[\"WEIGHT_DECAY\"],\n",
        "            \"threshold_method\": config[\"THRESHOLD_METHOD\"],\n",
        "            \"threshold_percentile\": config[\"THRESHOLD_PERCENTILE\"],\n",
        "            \"seed\": config[\"SEED\"],\n",
        "        })\n",
        "        print(f\"  ‚úì Hiperpar√°metros loggeados\")\n",
        "        \n",
        "        # Loop de entrenamiento\n",
        "        print(f\"\\nüöÄ Iniciando loop de entrenamiento ({config['NUM_EPOCHS']} √©pocas)...\\n\")\n",
        "        for epoch in range(1, config[\"NUM_EPOCHS\"] + 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"üìÖ √âPOCA {epoch}/{config['NUM_EPOCHS']}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            # Entrenar\n",
        "            print(f\"  üèãÔ∏è Entrenando...\")\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "            train_losses.append(train_loss)\n",
        "            print(f\"  ‚úì Entrenamiento completado: Loss={train_loss:.6f}\")\n",
        "            \n",
        "            # Validar\n",
        "            print(f\"  üìä Validando...\")\n",
        "            val_loss, val_errors = evaluate_reconstruction(model, val_loader, criterion, device)\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"  ‚úì Validaci√≥n completada: Loss={val_loss:.6f}\")\n",
        "            \n",
        "            # Log m√©tricas en MLflow (incluyendo error de reconstrucci√≥n promedio)\n",
        "            avg_reconstruction_error = np.mean(val_errors)\n",
        "            mlflow.log_metrics({\n",
        "                \"train_loss\": train_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_reconstruction_error\": avg_reconstruction_error,\n",
        "            }, step=epoch)\n",
        "            \n",
        "            # Guardar mejor modelo\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model_state = model.state_dict().copy()\n",
        "                print(f\"  ‚≠ê Nuevo mejor modelo (val_loss={val_loss:.6f})\")\n",
        "            \n",
        "            # Print progreso\n",
        "            if epoch % 5 == 0 or epoch == 1:\n",
        "                print(\n",
        "                    f\"Epoch {epoch:03d}/{config['NUM_EPOCHS']} | \"\n",
        "                    f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Recon Error: {avg_reconstruction_error:.6f}\"\n",
        "                )\n",
        "        \n",
        "        # Cargar mejor modelo\n",
        "        if best_model_state is not None:\n",
        "            model.load_state_dict(best_model_state)\n",
        "            print(f\"\\n‚úì Mejor modelo cargado (val_loss={best_val_loss:.6f})\")\n",
        "        \n",
        "        # Guardar curvas de entrenamiento\n",
        "        curves_path = save_training_curves(train_losses, val_losses, config[\"OUTPUT_DIR\"])\n",
        "        mlflow.log_artifact(str(curves_path))\n",
        "        \n",
        "        # Guardar modelo\n",
        "        mlflow.pytorch.log_model(model, \"model\")\n",
        "        \n",
        "        print(f\"‚úì Entrenamiento completado. Mejor val_loss: {best_val_loss:.6f}\")\n",
        "    \n",
        "    return model, train_losses, val_losses, val_errors\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Tarea Prefect: Seleccionar umbral\n",
        "# ========================================\n",
        "@task(name=\"select_threshold\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_select_threshold(\n",
        "    val_errors: np.ndarray,\n",
        "    config: Dict,\n",
        "    experiment_id: str,\n",
        ") -> float:\n",
        "    \"\"\"Tarea Prefect para seleccionar umbral.\"\"\"\n",
        "    print(\"üîç Seleccionando umbral de anomal√≠a...\")\n",
        "    threshold = select_threshold(\n",
        "        val_errors,\n",
        "        method=config[\"THRESHOLD_METHOD\"],\n",
        "        percentile=config[\"THRESHOLD_PERCENTILE\"],\n",
        "    )\n",
        "    \n",
        "    # Log en MLflow\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=config[\"RUN_NAME\"]):\n",
        "        mlflow.log_param(\"selected_threshold\", threshold)\n",
        "        mlflow.log_metric(\"threshold_value\", threshold)\n",
        "    \n",
        "    return threshold\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Tarea Prefect: Evaluar en validaci√≥n y test\n",
        "# ========================================\n",
        "@task(name=\"evaluate_final\", log_prints=True, cache_policy=NO_CACHE)\n",
        "def task_evaluate_final(\n",
        "    model: CNN1D_Autoencoder,\n",
        "    val_loader: DataLoader,\n",
        "    test_loader: DataLoader,\n",
        "    y_val: torch.Tensor,\n",
        "    y_test: torch.Tensor,\n",
        "    threshold: float,\n",
        "    device: torch.device,\n",
        "    config: Dict,\n",
        "    experiment_id: str,\n",
        ") -> Dict:\n",
        "    \"\"\"Tarea Prefect para evaluar en validaci√≥n y test.\"\"\"\n",
        "    print(\"üìä Evaluando en validaci√≥n y test...\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    # Evaluar en validaci√≥n\n",
        "    print(\"  üìä Evaluando en validaci√≥n...\")\n",
        "    val_loss, val_errors = evaluate_reconstruction(model, val_loader, criterion, device)\n",
        "    val_metrics = compute_metrics_from_errors(val_errors, y_val.numpy(), threshold)\n",
        "    \n",
        "    # Evaluar en test\n",
        "    print(\"  üìä Evaluando en test...\")\n",
        "    test_loss, test_errors = evaluate_reconstruction(model, test_loader, criterion, device)\n",
        "    test_metrics = compute_metrics_from_errors(test_errors, y_test.numpy(), threshold)\n",
        "    \n",
        "    # Guardar matrices de confusi√≥n\n",
        "    cm_val_path, _ = save_confusion_matrix(val_metrics[\"confusion_matrix\"], config[\"OUTPUT_DIR\"], \"val\")\n",
        "    cm_test_path, _ = save_confusion_matrix(test_metrics[\"confusion_matrix\"], config[\"OUTPUT_DIR\"], \"test\")\n",
        "    \n",
        "    # Log en MLflow\n",
        "    with mlflow.start_run(experiment_id=experiment_id, run_name=config[\"RUN_NAME\"]):\n",
        "        # M√©tricas de validaci√≥n\n",
        "        mlflow.log_metrics({\n",
        "            \"val_final_loss\": val_loss,\n",
        "            \"val_final_reconstruction_error\": np.mean(val_errors),\n",
        "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "            \"val_precision\": val_metrics[\"precision\"],\n",
        "            \"val_recall\": val_metrics[\"recall\"],\n",
        "            \"val_f1\": val_metrics[\"f1\"],\n",
        "            \"val_specificity\": val_metrics[\"specificity\"],\n",
        "            \"val_sensitivity\": val_metrics[\"sensitivity\"],\n",
        "            \"val_roc_auc\": val_metrics[\"roc_auc\"],\n",
        "        })\n",
        "        \n",
        "        # M√©tricas de test\n",
        "        mlflow.log_metrics({\n",
        "            \"test_final_loss\": test_loss,\n",
        "            \"test_final_reconstruction_error\": np.mean(test_errors),\n",
        "            \"test_accuracy\": test_metrics[\"accuracy\"],\n",
        "            \"test_precision\": test_metrics[\"precision\"],\n",
        "            \"test_recall\": test_metrics[\"recall\"],\n",
        "            \"test_f1\": test_metrics[\"f1\"],\n",
        "            \"test_specificity\": test_metrics[\"specificity\"],\n",
        "            \"test_sensitivity\": test_metrics[\"sensitivity\"],\n",
        "            \"test_roc_auc\": test_metrics[\"roc_auc\"],\n",
        "        })\n",
        "        \n",
        "        # Artefactos\n",
        "        mlflow.log_artifact(str(cm_val_path))\n",
        "        mlflow.log_artifact(str(cm_test_path))\n",
        "    \n",
        "    print(f\"\\n‚úì Evaluaci√≥n completada:\")\n",
        "    print(f\"  Validaci√≥n - Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
        "    print(f\"  Test - Acc: {test_metrics['accuracy']:.4f}, F1: {test_metrics['f1']:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        \"val_metrics\": val_metrics,\n",
        "        \"test_metrics\": test_metrics,\n",
        "        \"val_errors\": val_errors,\n",
        "        \"test_errors\": test_errors,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üöÄ EJECUTANDO FLUJO COMPLETO DE ENTRENAMIENTO\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:prefect:Starting temporary server on http://127.0.0.1:8759\n",
            "See https://docs.prefect.io/v3/concepts/server#how-to-guides for more information on running a dedicated Prefect server.\n",
            "INFO:prefect.flow_runs:Beginning flow run 'hopeful-lizard' for flow 'cnn1d_autoencoder_anomaly_detection_flow'\n",
            "INFO:prefect.flow_runs:üöÄ Iniciando flujo de entrenamiento Autoencoder CNN1D...\n",
            "INFO:prefect.flow_runs:Experimento MLflow: ecg_cnn_autoencoder\n",
            "INFO:prefect.flow_runs:‚úì MLflow tracking URI: sqlite:///S:/Proyecto final/mlflow.db\n",
            "2025/11/25 16:30:25 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/11/25 16:30:25 INFO mlflow.store.db.utils: Updating database tables\n",
            "2025-11-25 16:30:25 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "2025-11-25 16:30:25 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "2025-11-25 16:30:26 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "2025-11-25 16:30:26 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "2025-11-25 16:30:26 INFO  [prefect.flow_runs] ‚úì Experimento MLflow creado: ecg_cnn_autoencoder (ID: 10)\n",
            "2025-11-25 16:30:26 INFO  [prefect.flow_runs]   Artifact root: file:///S:/Proyecto%20final/mlflow_artifacts\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] üìÇ Cargando datos...\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] üìÇ CARGANDO DATOS DESDE tensors_200hz\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] Directorio: S:\\Proyecto final\\data\\Datos_no_supervisados\\tensors_200hz\n",
            "2025-11-25 16:30:26 INFO  [prefect.task_runs] \n",
            "‚è≥ Cargando tensors desde disco...\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs] \n",
            "üîç Filtrando datos de entrenamiento (solo normales)...\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs] \n",
            "‚úì Datos cargados:\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs]   X_train (normales): torch.Size([94733, 2000, 3]) | y_train: torch.Size([94733]) (todos normales: 94733)\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs]   X_val:   torch.Size([78301, 2000, 3]) | y_val:   torch.Size([78301]) (normales: 49300, an√≥malos: 29001)\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs]   X_test:  torch.Size([78302, 2000, 3]) | y_test:  torch.Size([78302]) (normales: 49302, an√≥malos: 29000)\n",
            "2025-11-25 16:30:30 INFO  [prefect.task_runs] ======================================================================\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs] \n",
            "‚úì DataLoaders creados:\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Train: 1481 batches (94733 muestras)\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Val:   1224 batches (78301 muestras)\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Test:  1224 batches (78302 muestras)\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs] üß† Creando modelo...\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs] ‚úì Modelo creado:\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Par√°metros totales: 34,019 (0.03M)\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Par√°metros entrenables: 34,019\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Encoded shape: (batch, 64, 250)\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   Latent channels: 64\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   ‚úì Modelo en cuda\n",
            "2025-11-25 16:30:31 INFO  [prefect.task_runs]   üîÑ Inicializando optimizador y criterio...\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   ‚úì Optimizador y criterio listos\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   üîÑ Iniciando run de MLflow...\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   ‚úì Run de MLflow iniciado\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   üîÑ Loggeando hiperpar√°metros en MLflow...\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   ‚úì Hiperpar√°metros loggeados\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs] \n",
            "üöÄ Iniciando loop de entrenamiento (50 √©pocas)...\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs] üìÖ √âPOCA 1/50\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:30:36 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:30:47 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.002172\n",
            "2025-11-25 16:30:47 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.001418\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.001418)\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs] Epoch 001/50 | Train Loss: 0.002172 | Val Loss: 0.001418 | Val Recon Error: 0.001418\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs] üìÖ √âPOCA 2/50\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:30:51 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:31:00 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000817\n",
            "2025-11-25 16:31:00 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000704\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000704)\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs] üìÖ √âPOCA 3/50\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:31:05 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:31:13 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000694\n",
            "2025-11-25 16:31:13 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:31:17 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000918\n",
            "2025-11-25 16:31:17 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:31:17 INFO  [prefect.task_runs] üìÖ √âPOCA 4/50\n",
            "2025-11-25 16:31:17 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:31:17 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:31:25 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000616\n",
            "2025-11-25 16:31:25 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000567\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000567)\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs] üìÖ √âPOCA 5/50\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:31:30 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:31:38 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000567\n",
            "2025-11-25 16:31:38 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000535\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000535)\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs] Epoch 005/50 | Train Loss: 0.000567 | Val Loss: 0.000535 | Val Recon Error: 0.000535\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs] üìÖ √âPOCA 6/50\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:31:43 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:31:51 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000534\n",
            "2025-11-25 16:31:51 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:31:55 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000567\n",
            "2025-11-25 16:31:55 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:31:55 INFO  [prefect.task_runs] üìÖ √âPOCA 7/50\n",
            "2025-11-25 16:31:55 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:31:55 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:32:03 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000510\n",
            "2025-11-25 16:32:03 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:32:08 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000601\n",
            "2025-11-25 16:32:08 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:32:08 INFO  [prefect.task_runs] üìÖ √âPOCA 8/50\n",
            "2025-11-25 16:32:08 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:32:08 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:32:16 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000467\n",
            "2025-11-25 16:32:16 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000523\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000523)\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs] üìÖ √âPOCA 9/50\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:32:21 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:32:29 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000451\n",
            "2025-11-25 16:32:29 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000367\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000367)\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs] üìÖ √âPOCA 10/50\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:32:34 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:32:42 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000414\n",
            "2025-11-25 16:32:42 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000452\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs] Epoch 010/50 | Train Loss: 0.000414 | Val Loss: 0.000452 | Val Recon Error: 0.000452\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs] üìÖ √âPOCA 11/50\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:32:47 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:32:55 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000407\n",
            "2025-11-25 16:32:55 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000348\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000348)\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs] üìÖ √âPOCA 12/50\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:33:00 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:33:08 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000379\n",
            "2025-11-25 16:33:08 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:33:13 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000544\n",
            "2025-11-25 16:33:13 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:33:13 INFO  [prefect.task_runs] üìÖ √âPOCA 13/50\n",
            "2025-11-25 16:33:13 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:33:13 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:33:22 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000360\n",
            "2025-11-25 16:33:22 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000298\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000298)\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs] üìÖ √âPOCA 14/50\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:33:27 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:33:36 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000342\n",
            "2025-11-25 16:33:36 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:33:41 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000321\n",
            "2025-11-25 16:33:41 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:33:41 INFO  [prefect.task_runs] üìÖ √âPOCA 15/50\n",
            "2025-11-25 16:33:41 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:33:41 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:33:49 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000336\n",
            "2025-11-25 16:33:49 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000316\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs] Epoch 015/50 | Train Loss: 0.000336 | Val Loss: 0.000316 | Val Recon Error: 0.000316\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs] üìÖ √âPOCA 16/50\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:33:54 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:34:03 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000318\n",
            "2025-11-25 16:34:03 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000278\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000278)\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs] üìÖ √âPOCA 17/50\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:34:07 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:34:16 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000299\n",
            "2025-11-25 16:34:16 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:34:20 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000350\n",
            "2025-11-25 16:34:20 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:34:20 INFO  [prefect.task_runs] üìÖ √âPOCA 18/50\n",
            "2025-11-25 16:34:20 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:34:20 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:34:28 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000283\n",
            "2025-11-25 16:34:28 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:34:33 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000350\n",
            "2025-11-25 16:34:33 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:34:33 INFO  [prefect.task_runs] üìÖ √âPOCA 19/50\n",
            "2025-11-25 16:34:33 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:34:33 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:34:41 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000277\n",
            "2025-11-25 16:34:41 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000262\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000262)\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs] üìÖ √âPOCA 20/50\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:34:46 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:34:55 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000266\n",
            "2025-11-25 16:34:55 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000313\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs] Epoch 020/50 | Train Loss: 0.000266 | Val Loss: 0.000313 | Val Recon Error: 0.000313\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs] üìÖ √âPOCA 21/50\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:35:00 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:35:08 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000254\n",
            "2025-11-25 16:35:08 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:35:13 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000318\n",
            "2025-11-25 16:35:13 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:35:13 INFO  [prefect.task_runs] üìÖ √âPOCA 22/50\n",
            "2025-11-25 16:35:13 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:35:13 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:35:21 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000244\n",
            "2025-11-25 16:35:21 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000226\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000226)\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs] üìÖ √âPOCA 23/50\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:35:26 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:35:34 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000229\n",
            "2025-11-25 16:35:34 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:35:39 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000329\n",
            "2025-11-25 16:35:39 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:35:39 INFO  [prefect.task_runs] üìÖ √âPOCA 24/50\n",
            "2025-11-25 16:35:39 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:35:39 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:35:48 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000223\n",
            "2025-11-25 16:35:48 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:35:52 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000274\n",
            "2025-11-25 16:35:52 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:35:52 INFO  [prefect.task_runs] üìÖ √âPOCA 25/50\n",
            "2025-11-25 16:35:52 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:35:52 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:36:01 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000215\n",
            "2025-11-25 16:36:01 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000163\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs]   ‚≠ê Nuevo mejor modelo (val_loss=0.000163)\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs] Epoch 025/50 | Train Loss: 0.000215 | Val Loss: 0.000163 | Val Recon Error: 0.000163\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs] üìÖ √âPOCA 26/50\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:36:06 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:36:14 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000211\n",
            "2025-11-25 16:36:14 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:36:19 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000224\n",
            "2025-11-25 16:36:19 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:36:19 INFO  [prefect.task_runs] üìÖ √âPOCA 27/50\n",
            "2025-11-25 16:36:19 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:36:19 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:36:28 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000198\n",
            "2025-11-25 16:36:28 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:36:32 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000331\n",
            "2025-11-25 16:36:32 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:36:32 INFO  [prefect.task_runs] üìÖ √âPOCA 28/50\n",
            "2025-11-25 16:36:32 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:36:32 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:36:41 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000208\n",
            "2025-11-25 16:36:41 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:36:46 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000486\n",
            "2025-11-25 16:36:46 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:36:46 INFO  [prefect.task_runs] üìÖ √âPOCA 29/50\n",
            "2025-11-25 16:36:46 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:36:46 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:36:54 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000195\n",
            "2025-11-25 16:36:54 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:36:59 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000289\n",
            "2025-11-25 16:36:59 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:36:59 INFO  [prefect.task_runs] üìÖ √âPOCA 30/50\n",
            "2025-11-25 16:36:59 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:36:59 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:37:07 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000192\n",
            "2025-11-25 16:37:07 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000304\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs] Epoch 030/50 | Train Loss: 0.000192 | Val Loss: 0.000304 | Val Recon Error: 0.000304\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs] üìÖ √âPOCA 31/50\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:37:12 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:37:21 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000196\n",
            "2025-11-25 16:37:21 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:37:25 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000656\n",
            "2025-11-25 16:37:25 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:37:25 INFO  [prefect.task_runs] üìÖ √âPOCA 32/50\n",
            "2025-11-25 16:37:25 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:37:25 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:37:34 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000187\n",
            "2025-11-25 16:37:34 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:37:39 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000264\n",
            "2025-11-25 16:37:39 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:37:39 INFO  [prefect.task_runs] üìÖ √âPOCA 33/50\n",
            "2025-11-25 16:37:39 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:37:39 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:37:47 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000188\n",
            "2025-11-25 16:37:47 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:37:52 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000521\n",
            "2025-11-25 16:37:52 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:37:52 INFO  [prefect.task_runs] üìÖ √âPOCA 34/50\n",
            "2025-11-25 16:37:52 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:37:52 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:38:00 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000187\n",
            "2025-11-25 16:38:00 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:38:05 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000212\n",
            "2025-11-25 16:38:05 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:38:05 INFO  [prefect.task_runs] üìÖ √âPOCA 35/50\n",
            "2025-11-25 16:38:05 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:38:05 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:38:13 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000182\n",
            "2025-11-25 16:38:13 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000252\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs] Epoch 035/50 | Train Loss: 0.000182 | Val Loss: 0.000252 | Val Recon Error: 0.000252\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs] üìÖ √âPOCA 36/50\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:38:18 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:38:26 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000183\n",
            "2025-11-25 16:38:26 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:38:31 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000195\n",
            "2025-11-25 16:38:31 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:38:31 INFO  [prefect.task_runs] üìÖ √âPOCA 37/50\n",
            "2025-11-25 16:38:31 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:38:31 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:38:40 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000183\n",
            "2025-11-25 16:38:40 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:38:44 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000304\n",
            "2025-11-25 16:38:44 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:38:44 INFO  [prefect.task_runs] üìÖ √âPOCA 38/50\n",
            "2025-11-25 16:38:44 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:38:44 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:38:53 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000179\n",
            "2025-11-25 16:38:53 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:38:57 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000331\n",
            "2025-11-25 16:38:57 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:38:57 INFO  [prefect.task_runs] üìÖ √âPOCA 39/50\n",
            "2025-11-25 16:38:57 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:38:57 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:39:06 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000182\n",
            "2025-11-25 16:39:06 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:39:10 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000221\n",
            "2025-11-25 16:39:10 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:39:10 INFO  [prefect.task_runs] üìÖ √âPOCA 40/50\n",
            "2025-11-25 16:39:10 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:39:10 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:39:19 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000176\n",
            "2025-11-25 16:39:19 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000296\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs] Epoch 040/50 | Train Loss: 0.000176 | Val Loss: 0.000296 | Val Recon Error: 0.000296\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs] üìÖ √âPOCA 41/50\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:39:24 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:39:32 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000179\n",
            "2025-11-25 16:39:32 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:39:37 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000326\n",
            "2025-11-25 16:39:37 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:39:37 INFO  [prefect.task_runs] üìÖ √âPOCA 42/50\n",
            "2025-11-25 16:39:37 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:39:37 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:39:45 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000171\n",
            "2025-11-25 16:39:45 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:39:50 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000302\n",
            "2025-11-25 16:39:50 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:39:50 INFO  [prefect.task_runs] üìÖ √âPOCA 43/50\n",
            "2025-11-25 16:39:50 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:39:50 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:39:58 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000170\n",
            "2025-11-25 16:39:58 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:40:03 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000281\n",
            "2025-11-25 16:40:03 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:40:03 INFO  [prefect.task_runs] üìÖ √âPOCA 44/50\n",
            "2025-11-25 16:40:03 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:40:03 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:40:11 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000171\n",
            "2025-11-25 16:40:11 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:40:16 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000277\n",
            "2025-11-25 16:40:16 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:40:16 INFO  [prefect.task_runs] üìÖ √âPOCA 45/50\n",
            "2025-11-25 16:40:16 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:40:16 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:40:25 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000175\n",
            "2025-11-25 16:40:25 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000269\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs] Epoch 045/50 | Train Loss: 0.000175 | Val Loss: 0.000269 | Val Recon Error: 0.000269\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs] üìÖ √âPOCA 46/50\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:40:29 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:40:38 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000170\n",
            "2025-11-25 16:40:38 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:40:43 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000247\n",
            "2025-11-25 16:40:43 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:40:43 INFO  [prefect.task_runs] üìÖ √âPOCA 47/50\n",
            "2025-11-25 16:40:43 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:40:43 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:40:51 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000172\n",
            "2025-11-25 16:40:51 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:40:56 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000181\n",
            "2025-11-25 16:40:56 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:40:56 INFO  [prefect.task_runs] üìÖ √âPOCA 48/50\n",
            "2025-11-25 16:40:56 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:40:56 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:41:04 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000173\n",
            "2025-11-25 16:41:04 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:41:08 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000239\n",
            "2025-11-25 16:41:08 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:41:08 INFO  [prefect.task_runs] üìÖ √âPOCA 49/50\n",
            "2025-11-25 16:41:08 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:41:08 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:41:17 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000173\n",
            "2025-11-25 16:41:17 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:41:22 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000818\n",
            "2025-11-25 16:41:22 INFO  [prefect.task_runs] \n",
            "============================================================\n",
            "2025-11-25 16:41:22 INFO  [prefect.task_runs] üìÖ √âPOCA 50/50\n",
            "2025-11-25 16:41:22 INFO  [prefect.task_runs] ============================================================\n",
            "2025-11-25 16:41:22 INFO  [prefect.task_runs]   üèãÔ∏è Entrenando...\n",
            "2025-11-25 16:41:30 INFO  [prefect.task_runs]   ‚úì Entrenamiento completado: Loss=0.000172\n",
            "2025-11-25 16:41:30 INFO  [prefect.task_runs]   üìä Validando...\n",
            "2025-11-25 16:41:35 INFO  [prefect.task_runs]   ‚úì Validaci√≥n completada: Loss=0.000382\n",
            "2025-11-25 16:41:35 INFO  [prefect.task_runs] Epoch 050/50 | Train Loss: 0.000172 | Val Loss: 0.000382 | Val Recon Error: 0.000382\n",
            "2025-11-25 16:41:35 INFO  [prefect.task_runs] \n",
            "‚úì Mejor modelo cargado (val_loss=0.000163)\n",
            "2025/11/25 16:41:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/11/25 16:41:35 WARNING mlflow.utils.requirements_utils: Found torch version (2.10.0.dev20251124+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.10.0.dev20251124' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/11/25 16:41:47 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\tomas\\AppData\\Local\\Temp\\tmpexsu7uey\\model\\data, flavor: pytorch). Fall back to return ['torch==2.10.0.dev20251124', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
            "2025/11/25 16:41:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] ‚úì Entrenamiento completado. Mejor val_loss: 0.000163\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] üîç Seleccionando umbral de anomal√≠a...\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] ‚úì Umbral seleccionado (percentil 95): 0.000541\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs] üìä Evaluando en validaci√≥n y test...\n",
            "2025-11-25 16:41:47 INFO  [prefect.task_runs]   üìä Evaluando en validaci√≥n...\n",
            "2025-11-25 16:41:52 INFO  [prefect.task_runs]   üìä Evaluando en test...\n",
            "2025-11-25 16:41:57 INFO  [prefect.task_runs] \n",
            "‚úì Evaluaci√≥n completada:\n",
            "2025-11-25 16:41:57 INFO  [prefect.task_runs]   Validaci√≥n - Acc: 0.6328, F1: 0.1265\n",
            "2025-11-25 16:41:57 INFO  [prefect.task_runs]   Test - Acc: 0.6334, F1: 0.1286\n",
            "2025-11-25 16:41:57 INFO  [prefect.task_runs] Finished in state Completed()\n",
            "2025-11-25 16:41:57 INFO  [prefect.flow_runs] \n",
            "‚úì Modelo guardado en: outputs\\autoencoder_model.pt\n",
            "2025-11-25 16:41:57 INFO  [prefect.flow_runs] \n",
            "‚úÖ Flujo completado exitosamente!\n",
            "2025-11-25 16:41:57 INFO  [prefect.flow_runs] \n",
            "Revisa MLflow para ver todos los artefactos y m√©tricas.\n",
            "2025-11-25 16:41:57 INFO  [prefect.flow_runs] Finished in state Completed()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "‚úÖ ENTRENAMIENTO Y EVALUACI√ìN COMPLETADOS\n",
            "================================================================================\n",
            "\n",
            "üìä Resumen de resultados:\n",
            "  Umbral seleccionado: 0.000541\n",
            "  Validaci√≥n - Acc: 0.6328, F1: 0.1265\n",
            "  Test - Acc: 0.6334, F1: 0.1286\n",
            "\n",
            "üìÅ Artefactos guardados en: outputs\n",
            "üìä Revisa MLflow para m√°s detalles: mlflow ui\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Flujo principal de Prefect\n",
        "# ========================================\n",
        "@flow(name=\"cnn1d_autoencoder_anomaly_detection_flow\", log_prints=True)\n",
        "def main_flow(config: Dict, device: torch.device):\n",
        "    \"\"\"\n",
        "    Flujo principal de Prefect que orquesta todo el proceso:\n",
        "    1. Cargar datos\n",
        "    2. Entrenar modelo\n",
        "    3. Seleccionar umbral\n",
        "    4. Evaluar en validaci√≥n y test\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Iniciando flujo de entrenamiento Autoencoder CNN1D...\")\n",
        "    print(f\"Experimento MLflow: {config['EXPERIMENT_NAME']}\")\n",
        "    \n",
        "    # Configurar MLflow\n",
        "    experiment_id = setup_mlflow(config)\n",
        "    \n",
        "    # 1. Cargar datos\n",
        "    train_loader, val_loader, test_loader, y_val, y_test = task_load_data(config)\n",
        "    \n",
        "    # 2. Entrenar modelo\n",
        "    model, train_losses, val_losses, val_errors = task_train_model(\n",
        "        train_loader, val_loader, device, config, experiment_id\n",
        "    )\n",
        "    \n",
        "    # 3. Seleccionar umbral\n",
        "    threshold = task_select_threshold(val_errors, config, experiment_id)\n",
        "    \n",
        "    # 4. Evaluar en validaci√≥n y test\n",
        "    results = task_evaluate_final(\n",
        "        model, val_loader, test_loader, y_val, y_test,\n",
        "        threshold, device, config, experiment_id\n",
        "    )\n",
        "    \n",
        "    # Guardar modelo y umbral\n",
        "    model_path = config[\"OUTPUT_DIR\"] / \"autoencoder_model.pt\"\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'config': config,\n",
        "        'threshold': threshold,\n",
        "    }, model_path)\n",
        "    print(f\"\\n‚úì Modelo guardado en: {model_path}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Flujo completado exitosamente!\")\n",
        "    print(f\"\\nRevisa MLflow para ver todos los artefactos y m√©tricas.\")\n",
        "    \n",
        "    return model, threshold, results\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Ejecutar flujo completo\n",
        "# ========================================\n",
        "if __name__ == \"__main__\" or True:  # Ejecutar en notebook\n",
        "    print(\"=\"*80)\n",
        "    print(\"üöÄ EJECUTANDO FLUJO COMPLETO DE ENTRENAMIENTO\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Ejecutar flujo\n",
        "    model, threshold, results = main_flow(CONFIG, DEVICE)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ ENTRENAMIENTO Y EVALUACI√ìN COMPLETADOS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nüìä Resumen de resultados:\")\n",
        "    print(f\"  Umbral seleccionado: {threshold:.6f}\")\n",
        "    print(f\"  Validaci√≥n - Acc: {results['val_metrics']['accuracy']:.4f}, F1: {results['val_metrics']['f1']:.4f}\")\n",
        "    print(f\"  Test - Acc: {results['test_metrics']['accuracy']:.4f}, F1: {results['test_metrics']['f1']:.4f}\")\n",
        "    print(f\"\\nüìÅ Artefactos guardados en: {CONFIG['OUTPUT_DIR']}\")\n",
        "    print(f\"üìä Revisa MLflow para m√°s detalles: mlflow ui\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
