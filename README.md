# ğŸ«€ Proyecto Final de Grado - AnÃ¡lisis de ECG con Deep Learning

Sistema completo para el anÃ¡lisis de seÃ±ales ECG utilizando modelos de deep learning para la detecciÃ³n de anomalÃ­as. El proyecto incluye procesamiento de datos, entrenamiento de mÃºltiples arquitecturas (CNN1D, LSTM, Transformer), despliegue en AWS SageMaker, y un frontend React para interactuar con el modelo.

## ğŸ“‹ CaracterÃ­sticas Principales

- **Procesamiento de seÃ±ales ECG**: Filtrado, normalizaciÃ³n, downsampling, selecciÃ³n de leads
- **MÃºltiples arquitecturas de modelos**: CNN1D, CNN1D+LSTM, CNN1D+Transformer, Autoencoders
- **Datos supervisados y no supervisados**: Pipelines completos para ambos enfoques
- **Despliegue en producciÃ³n**: AWS SageMaker Serverless + Lambda + API Gateway
- **Frontend interactivo**: AplicaciÃ³n React + Vite para demo y pruebas
- **Tracking de experimentos**: IntegraciÃ³n con MLflow
- **AnÃ¡lisis comparativo**: ComparaciÃ³n de costos computacionales entre modelos

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- **Python 3.8+** para el backend/ML
- **Node.js 18+** para el frontend
- **CUDA 12.8+** (opcional, para aceleraciÃ³n GPU)
- **Cuenta AWS** (para despliegue en producciÃ³n)
- **Git**

### InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/tomasv00805/Proyectofinaldegrado.git
cd Proyectofinaldegrado
```

2. **Configurar entorno Python:**
```bash
# Crear entorno virtual
python -m venv venv

# Activar (Windows)
venv\Scripts\activate
# Activar (Linux/Mac)
source venv/bin/activate

# Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt
```

3. **Instalar PyTorch con CUDA (opcional):**
```bash
# CUDA 12.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128

# Solo CPU
pip install torch torchvision
```

4. **Configurar frontend:**
```bash
cd Frontend
npm install
cp .env.example .env
# Editar .env y agregar tu URL de API Gateway
```

## ğŸ“ Estructura del Proyecto

```
Proyectofinaldegrado/
â”œâ”€â”€ Books/                          # Scripts y notebooks de ML
â”‚   â”œâ”€â”€ build_supervised_ecg_dataset.py      # Pipeline datos supervisados
â”‚   â”œâ”€â”€ build_unsupervised_ecg_dataset.ipynb  # Pipeline datos no supervisados
â”‚   â”œâ”€â”€ cnn1d_classification_supervised.ipynb
â”‚   â”œâ”€â”€ cnn1d_lstm_classification_supervised.ipynb
â”‚   â”œâ”€â”€ cnn1d_transformer_classification_supervised.ipynb
â”‚   â”œâ”€â”€ cnn1d_autoencoder_anomaly_detection.ipynb
â”‚   â”œâ”€â”€ lstm_autoencoder_pipeline.ipynb
â”‚   â”œâ”€â”€ deploy_sagemaker_serverless.ipynb    # Despliegue en AWS
â”‚   â”œâ”€â”€ evaluation_threshold_tuning.py       # EvaluaciÃ³n de modelos
â”‚   â”œâ”€â”€ ecg_preprocessing.py                 # Funciones de preprocesamiento
â”‚   â”œâ”€â”€ models/                              # Metadatos de modelos
â”‚   â”œâ”€â”€ sagemaker_models/                    # Modelos para SageMaker
â”‚   â”œâ”€â”€ DOCUMENTACION_*.md                   # DocumentaciÃ³n tÃ©cnica
â”‚   â””â”€â”€ README_NOTEBOOKS.md                  # GuÃ­a de notebooks
â”‚
â”œâ”€â”€ Frontend/                       # AplicaciÃ³n web React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                 # Componente principal
â”‚   â”‚   â”œâ”€â”€ ECGVisualization.jsx    # VisualizaciÃ³n de seÃ±ales ECG
â”‚   â”‚   â”œâ”€â”€ api/client.js           # Cliente API Gateway
â”‚   â”‚   â””â”€â”€ data/ecg_samples.json   # Ejemplos de ECG para demo
â”‚   â”œâ”€â”€ lambda_function.py          # FunciÃ³n Lambda para AWS
â”‚   â”œâ”€â”€ generate_ecg_samples.py     # Generar ejemplos de ECG
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ README.md                   # DocumentaciÃ³n del frontend
â”‚
â”œâ”€â”€ config/                         # Configuraciones
â”‚   â””â”€â”€ ae1d_config.json           # ConfiguraciÃ³n autoencoder
â”‚
â”œâ”€â”€ data/                           # Datos procesados (no en repo)
â”‚   â”œâ”€â”€ Datos_supervisados/        # Datasets supervisados
â”‚   â””â”€â”€ Datos_no_supervisados/     # Datasets no supervisados
â”‚
â”œâ”€â”€ requirements.txt                # Dependencias Python
â””â”€â”€ README.md                       # Este archivo
```

## ğŸ”§ Uso

### 1. Preparar los Datos

**Descargar datasets:**
- PTB-XL: https://physionet.org/content/ptb-xl/1.0.3/
- MIMIC-IV-ECG: https://physionet.org/content/mimic-iv-ecg-diagnostic/1.0/

**Colocar en el directorio raÃ­z:**
```
ptb-xl-a-large-publicly-available-electrocardiogram-dataset-1.0.3/
mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/
```

**Procesar datos supervisados:**
```bash
cd Books
python build_supervised_ecg_dataset.py
# O usar el notebook interactivo:
jupyter notebook build_supervised_ecg_dataset.ipynb
```

**Procesar datos no supervisados:**
```bash
jupyter notebook build_unsupervised_ecg_dataset.ipynb
```

### 2. Entrenar Modelos

**ClasificaciÃ³n Supervisada:**
- `cnn1d_classification_supervised.ipynb` - CNN1D puro
- `cnn1d_lstm_classification_supervised.ipynb` - CNN1D + LSTM
- `cnn1d_transformer_classification_supervised.ipynb` - CNN1D + Transformer

**DetecciÃ³n de AnomalÃ­as (No Supervisado):**
- `cnn1d_autoencoder_anomaly_detection.ipynb` - Autoencoder CNN1D
- `lstm_autoencoder_pipeline.ipynb` - Autoencoder LSTM

**Comparar modelos:**
```bash
jupyter notebook compare_models_computational_cost.ipynb
```

### 3. Evaluar Modelos

```bash
python Books/evaluation_threshold_tuning.py
```

### 4. Desplegar en AWS

Ver la guÃ­a completa en `Books/deploy_sagemaker_serverless.ipynb` o `Books/DOCUMENTACION_DESPLIEGUE_SAGEMAKER.md`

**Pasos principales:**
1. Preparar modelo para SageMaker
2. Crear endpoint serverless en SageMaker
3. Configurar Lambda function
4. Crear API Gateway HTTP API
5. Configurar CORS

### 5. Usar el Frontend

```bash
cd Frontend
npm install
npm run dev
```

Abre `http://localhost:5173` en tu navegador.

**Configurar API Gateway:**
1. Crea `.env` desde `.env.example`
2. Agrega tu URL de API Gateway: `VITE_API_URL=https://tu-api.execute-api.us-east-1.amazonaws.com`
3. Reinicia el servidor de desarrollo

Ver `Frontend/README.md` para mÃ¡s detalles.

## ğŸ“Š Arquitecturas de Modelos

### ClasificaciÃ³n Supervisada

1. **CNN1D**: Red convolucional 1D pura
2. **CNN1D + LSTM**: ConvoluciÃ³n seguida de capas LSTM
3. **CNN1D + Transformer**: ConvoluciÃ³n con atenciÃ³n Transformer

### DetecciÃ³n de AnomalÃ­as (No Supervisado)

1. **Autoencoder CNN1D**: Encoder-decoder convolucional
2. **Autoencoder LSTM**: Encoder-decoder con LSTM

### Formato de Entrada
- **Forma**: `[batch_size, 2000, 3]`
  - 2000 muestras temporales (10 segundos a 200 Hz)
  - 3 canales (I, II, III)
- **Frecuencia**: 200 Hz
- **DuraciÃ³n**: 10 segundos

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend/ML
- **PyTorch**: Deep learning
- **NumPy, Pandas**: ManipulaciÃ³n de datos
- **SciPy, WFDB**: Procesamiento de seÃ±ales ECG
- **Scikit-learn**: MÃ©tricas y validaciÃ³n
- **MLflow**: Tracking de experimentos
- **Prefect**: OrquestaciÃ³n de pipelines

### Frontend
- **React 18**: Framework UI
- **Vite**: Build tool y dev server
- **JavaScript/JSX**: Lenguaje principal

### Despliegue
- **AWS SageMaker**: Servicio de ML
- **AWS Lambda**: FunciÃ³n serverless
- **API Gateway**: API HTTP
- **IAM**: GestiÃ³n de permisos

## ğŸ“š DocumentaciÃ³n

### DocumentaciÃ³n General
- `Books/DOCUMENTACION_GENERAL.md` - VisiÃ³n general del proyecto
- `Books/README.md` - GuÃ­a del backend/ML
- `Books/README_NOTEBOOKS.md` - DescripciÃ³n de todos los notebooks

### DocumentaciÃ³n de Datos
- `Books/Documentacion Datos Supervisados.md` - Pipeline de datos supervisados
- `Books/DOCUMENTACION_DATOS_NO_SUPERVISADOS_DOWNSAMPLING.md` - Datos no supervisados

### DocumentaciÃ³n de Entrenamiento
- `Books/DOCUMENTACION_ENTRENAMIENTO.md` - Proceso de entrenamiento

### DocumentaciÃ³n de Despliegue
- `Books/DOCUMENTACION_DESPLIEGUE_SAGEMAKER.md` - GuÃ­a completa de despliegue
- `Frontend/README.md` - DocumentaciÃ³n del frontend
- `Frontend/DOCUMENTACION_COMPLETA.md` - DocumentaciÃ³n tÃ©cnica del frontend

## ğŸ” Seguridad

- âœ… **Sin credenciales expuestas**: Las credenciales AWS se manejan mediante IAM roles
- âœ… **API Gateway como proxy**: Todas las peticiones pasan por API Gateway
- âœ… **CORS configurado**: Control de acceso desde el frontend
- âœ… **Variables de entorno**: ConfiguraciÃ³n sensible en `.env` (no en repo)

## ğŸ“ Notas Importantes

- Los **datasets originales** y **modelos entrenados** no estÃ¡n en el repositorio (tamaÃ±o)
- Los datos procesados se guardan en `data/`
- Los artefactos de MLflow se guardan en `mlflow_artifacts/` y `mlflow.db`
- Para usar GPU, asegÃºrate de tener drivers NVIDIA y CUDA instalados
- El frontend requiere configuraciÃ³n de API Gateway para funcionar (ver `Frontend/README.md`)

## ğŸ“Š Resultados y MÃ©tricas

Los modelos se evalÃºan con:
- Accuracy, Precision, Recall, F1-Score
- ROC-AUC, PR-AUC
- Matrices de confusiÃ³n
- AnÃ¡lisis de costos computacionales

Ver `Books/computational_cost_comparison/` para comparaciones detalladas.

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico. Para sugerencias o mejoras, por favor abre un issue en el repositorio.

## ğŸ“„ Licencia

Este proyecto utiliza datasets pÃºblicos (PTB-XL y MIMIC-IV-ECG) que tienen sus propias licencias. Consulta los archivos LICENSE en cada directorio de dataset.

## ğŸ‘¤ Autor

**Tomas V00805**

## ğŸ“§ Contacto

Para preguntas sobre el proyecto, abre un issue en GitHub.

---

**Nota**: Este proyecto requiere acceso a los datasets PTB-XL y MIMIC-IV-ECG, que deben descargarse por separado desde PhysioNet (requiere registro y aceptaciÃ³n de tÃ©rminos de uso).
